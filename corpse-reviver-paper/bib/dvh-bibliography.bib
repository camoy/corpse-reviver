@InProceedings{Hammer2015Incremental,
  author =       "Matthew A. Hammer and Joshua Dunfield and Kyle Headley
                 and Nicholas Labich and Jeffrey S. Foster and Michael
                 Hicks and David Van Horn",
  booktitle =    "OOPSLA 2015 Proceedings of the 2015 ACM SIGPLAN
                 International Conference on Object-Oriented
                 Programming, Systems, Languages, and Applications",
  citeulike-article-id = "14609814",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2814305",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2858965.2814305",
  date-added =   "2018-07-01 04:39:55",
  month =        oct,
  number =       "10",
  priority =     "2",
  publisher =    "ACM",
  title =        "Incremental Computation with Names",
  volume =       "50",
  x-abstract =   "Over the past thirty years, there has been significant
                 progress in developing general-purpose, language-based
                 approaches to incremental computation, which aims to
                 efficiently update the result of a computation when an
                 input is changed. A key design challenge in such
                 approaches is how to provide efficient incremental
                 support for a broad range of programs. In this paper,
                 we argue that first-class names are a critical
                 linguistic feature for efficient incremental
                 computation. Names identify computations to be reused
                 across differing runs of a program, and making them
                 first class gives programmers a high level of control
                 over reuse. We demonstrate the benefits of names by
                 presenting Nominal Adapton, an {ML}-like language for
                 incremental computation with names. We describe how to
                 use Nominal Adapton to efficiently incrementalize
                 several standard programming patterns---including maps,
                 folds, and unfolds---and show how to build efficient,
                 incremental probabilistic trees and tries. Since
                 Nominal Adapton's implementation is subtle, we
                 formalize it as a core calculus and prove it is
                 from-scratch consistent, meaning it always produces the
                 same answer as simply re-running the computation.
                 Finally, we demonstrate that Nominal Adapton can
                 provide large speedups over both from-scratch
                 computation and Adapton, a previous state-of-the-art
                 incremental computation system.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2858965.2814305",
  x-issn =       "0362-1340",
  x-url =        "http://dx.doi.org/10.1145/2858965.2814305",
  xpages =       "748--766",
  year =         "2015",
}

@InCollection{Jagannathan1995Effective,
  author =       "Suresh Jagannathan and Andrew Wright",
  booktitle =    "Static Analysis",
  citeulike-article-id = "14288879",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/3-540-60360-3\_41",
  citeulike-linkout-1 = "http://link.springer.com/chapter/10.1007/3-540-60360-3\_41",
  date-added =   "2017-02-27 22:52:35",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "Effective flow analysis for avoiding run-time checks",
  volume =       "983",
  x-doi =        "10.1007/3-540-60360-3\_41",
  x-editor =     "Mycroft, Alan",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/3-540-60360-3\_41",
  xpages =       "207--224",
  year =         "1995",
}

@Article{Nguy7877n2015Relatively,
  author =       "Ph\'{u}c C. Nguy\&\#7877;n and David Van Horn",
  citeulike-article-id = "13837947",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2737924.2737971",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2813885.2737971",
  date-added =   "2015-11-13 23:15:45",
  journal =      "SIGPLAN Not.",
  month =        jun,
  number =       "6",
  priority =     "2",
  publisher =    "ACM",
  title =        "Relatively Complete Counterexamples for Higher-order
                 Programs",
  volume =       "50",
  x-abstract =   "In this paper, we study the problem of generating
                 inputs to a higher-order program causing it to error.
                 We first approach the problem in the setting of {PCF},
                 a typed, core functional language and contribute the
                 first relatively complete method for constructing
                 counterexamples for {PCF} programs. The method is
                 relatively complete with respect to a first-order
                 solver over the base types of {PCF}. In practice, this
                 means an {SMT} solver can be used for the effective,
                 automated generation of higher-order counterexamples
                 for a large class of programs. We achieve this result
                 by employing a novel form of symbolic execution for
                 higher-order programs. The remarkable aspect of this
                 symbolic execution is that even though symbolic
                 higher-order inputs and values are considered, the path
                 condition remains a first-order formula. Our handling
                 of symbolic function application enables the
                 reconstruction of higher-order counterexamples from
                 this first-order formula. After establishing our main
                 theoretical results, we sketch how to apply the
                 approach to untyped, higher-order, stateful languages
                 with first-class contracts and show how counterexample
                 generation can be used to detect contract violations in
                 this setting. To validate our approach, we implement a
                 tool generating counterexamples for erroneous modules
                 written in Racket.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2813885.2737971",
  x-issn =       "0362-1340",
  x-url =        "http://dx.doi.org/10.1145/2813885.2737971",
  xpages =       "446--456",
  year =         "2015",
}

@InProceedings{Das2002ESP,
  author =       "Manuvir Das and Sorin Lerner and Mark Seigle",
  booktitle =    "Proceedings of the ACM SIGPLAN 2002 Conference on
                 Programming Language Design and Implementation",
  citeulike-article-id = "3048734",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=512538",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/512529.512538",
  date-added =   "2015-07-18 22:23:58",
  location =     "Berlin, Germany",
  month =        may,
  priority =     "2",
  publisher =    "ACM",
  title =        "{ESP}: Path-sensitive Program Verification in
                 Polynomial Time",
  x-abstract =   "In this paper, we present a new algorithm for partial
                 program verification that runs in polynomial time and
                 space. We are interested in checking that a program
                 satisfies a given temporal safety property. Our insight
                 is that by accurately modeling only those branches in a
                 program for which the property-related behavior differs
                 along the arms of the branch, we can design an
                 algorithm that is accurate enough to verify the program
                 with respect to the given property, without paying the
                 potentially exponential cost of full path-sensitive
                 {analysis.We} have implemented this {"}property
                 simulation{"} algorithm as part of a partial
                 verification tool called {ESP}. We present the results
                 of applying {ESP} to the problem of verifying the file
                 {I/O} behavior of a version of the {GNU} C compiler
                 (gcc, 140,000 {LOC}). We are able to prove that all of
                 the 646 calls to .fprintf in the source code of gcc are
                 guaranteed to print to valid, open files. Our results
                 show that property simulation scales to large programs
                 and is accurate enough to verify meaningful
                 properties.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/512529.512538",
  x-isbn =       "1-58113-463-0",
  x-issn =       "0362-1340",
  x-series =     "PLDI '02",
  x-url =        "http://dx.doi.org/10.1145/512529.512538",
  xpages =       "57--68",
  year =         "2002",
}

@InProceedings{Vazou2014Refinement,
  author =       "Niki Vazou and Eric L. Seidel and Ranjit Jhala and
                 Dimitrios Vytiniotis and Simon P. Jones",
  booktitle =    "Proceedings of the 19th ACM SIGPLAN International
                 Conference on Functional Programming",
  citeulike-article-id = "13674748",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2628161",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2692915.2628161",
  date-added =   "2015-07-16 20:25:01",
  month =        aug,
  priority =     "2",
  publisher =    "ACM",
  title =        "Refinement Types for {H}askell",
  x-abstract =   "{SMT}-based checking of refinement types for
                 call-by-value languages is a well-studied subject.
                 Unfortunately, the classical translation of refinement
                 types to verification conditions is unsound under lazy
                 evaluation. When checking an expression, such systems
                 implicitly assume that all the free variables in the
                 expression are bound to values. This property is
                 trivially guaranteed by eager, but does not hold under
                 lazy, evaluation. Thus, to be sound and precise, a
                 refinement type system for Haskell and the
                 corresponding verification conditions must take into
                 account which subset of binders actually reduces to
                 values. We present a stratified type system that labels
                 binders as potentially diverging or not, and that
                 (circularly) uses refinement types to verify the
                 labeling. We have implemented our system in
                 {LIQUIDHASKELL} and present an experimental evaluation
                 of our approach on more than 10,000 lines of widely
                 used Haskell libraries. We show that {LIQUIDHASKELL} is
                 able to prove 96\% of all recursive functions
                 terminating, while requiring a modest 1.7 lines of
                 termination-annotations per 100 lines of code.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2692915.2628161",
  x-issn =       "0362-1340",
  x-url =        "http://dx.doi.org/10.1145/2692915.2628161",
  xpages =       "269--282",
  year =         "2014",
}

@InProceedings{Seidel2015Type,
  author =       "EricL Seidel and Niki Vazou and Ranjit Jhala",
  booktitle =    "Programming Languages and Systems",
  citeulike-article-id = "13674659",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-662-46669-8\_33",
  citeulike-linkout-1 = "http://link.springer.com/chapter/10.1007/978-3-662-46669-8\_33",
  date-added =   "2015-07-16 17:26:20",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "Type Targeted Testing",
  x-abstract =   "We present a new technique called type targeted
                 testing, which translates precise refinement types into
                 comprehensive test-suites. The key insight behind our
                 approach is that through the lens of {SMT} solvers,
                 refinement types can also be viewed as a high-level,
                 declarative, test generation technique, wherein types
                 are converted to {SMT} queries whose models can be
                 decoded into concrete program inputs. Our approach
                 enables the systematic and exhaustive testing of
                 implementations from high-level declarative
                 specifications, and furthermore, provides a gradual
                 path from testing to full verification. We have
                 implemented our approach as a Haskell testing tool
                 called {TARGET}, and present an evaluation that shows
                 how {TARGET} can be used to test a wide variety of
                 properties and how it compares against state-of-the-art
                 testing approaches.",
  x-doi =        "10.1007/978-3-662-46669-8\_33",
  x-editor =     "Vitek, Jan",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-662-46669-8\_33",
  xpages =       "812--836",
  year =         "2015",
}

@InProceedings{Johnson2014Abstracting,
  author =       "James I. Johnson and David Van{ }Horn",
  booktitle =    "Proceedings of the 10th ACM Symposium on Dynamic
                 Languages",
  citeulike-article-id = "13674648",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2661098",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2775052.2661098",
  date-added =   "2015-07-16 16:59:37",
  month =        oct,
  priority =     "2",
  publisher =    "ACM",
  title =        "Abstracting Abstract Control",
  x-abstract =   "The strength of a dynamic language is also its
                 weakness: run-time flexibility comes at the cost of
                 compile-time predictability. Many of the hallmarks of
                 dynamic languages such as closures, continuations,
                 various forms of reflection, and a lack of static types
                 make many programmers rejoice, while compiler writers,
                 tool developers, and verification engineers lament. The
                 dynamism of these features simply confounds statically
                 reasoning about programs that use them. Consequently,
                 static analyses for dynamic languages are few, far
                 between, and seldom sound. The {"}abstracting abstract
                 machines{"} ({AAM}) approach to constructing static
                 analyses has recently been proposed as a method to
                 ameliorate the difficulty of designing analyses for
                 such language features. The approach, so called because
                 it derives a function for the sound and computable
                 approximation of program behavior starting from the
                 abstract machine semantics of a language, provides a
                 viable approach to dynamic language analysis since all
                 that is required is a machine description of the
                 interpreter. The {AAM} recipe as originally described
                 produces finite state abstractions: the behavior of a
                 program is approximated as a finite state machine. Such
                 a model is inherently imprecise when it comes to
                 reasoning about the control stack of the interpreter: a
                 finite state machine cannot faithfully represent a
                 stack. Recent advances have shown that higher-order
                 programs can be approximated with pushdown systems.
                 However, such models, founded in automata theory,
                 either breakdown or require significant engineering in
                 the face of dynamic language features that inspect or
                 modify the control stack. In this paper, we tackle the
                 problem of bringing pushdown flow analysis to the
                 domain of dynamic language features. We revise the
                 abstracting abstract machines technique to target the
                 stronger computational model of pushdown systems. In
                 place of automata theory, we use only abstract machines
                 and memoization. As case studies, we show the technique
                 applies to a language with closures, garbage
                 collection, stack-inspection, and first-class
                 composable continuations.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2775052.2661098",
  x-issn =       "0362-1340",
  x-url =        "http://dx.doi.org/10.1145/2775052.2661098",
  xpages =       "11--22",
  year =         "2014",
}

@InProceedings{Chugh2012Nested,
  author =       "Ravi Chugh and Patrick M. Rondon and Ranjit Jhala",
  booktitle =    "Proceedings of the 39th Annual ACM SIGPLAN-SIGACT
                 Symposium on Principles of Programming Languages",
  citeulike-article-id = "10847232",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2103686",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2103621.2103686",
  date-added =   "2015-07-16 03:09:02",
  location =     "Philadelphia, PA, USA",
  month =        jan,
  priority =     "2",
  publisher =    "ACM",
  title =        "Nested Refinements: {A} Logic for Duck Typing",
  x-abstract =   "Programs written in dynamic languages make heavy use
                 of features --- run-time type tests, value-indexed
                 dictionaries, polymorphism, and higher-order functions
                 --- that are beyond the reach of type systems that
                 employ either purely syntactic or purely semantic
                 reasoning. We present a core calculus, System D, that
                 merges these two modes of reasoning into a single
                 powerful mechanism of nested refinement types wherein
                 the typing relation is itself a predicate in the
                 refinement logic. System D coordinates {SMT}-based
                 logical implication and syntactic subtyping to
                 automatically typecheck sophisticated dynamic language
                 programs. By coupling nested refinements with
                 {McCarthy}'s theory of finite maps, System D can
                 precisely reason about the interaction of higher-order
                 functions, polymorphism, and dictionaries. The addition
                 of type predicates to the refinement logic creates a
                 circularity that leads to unique technical challenges
                 in the metatheory, which we solve with a novel
                 stratification approach that we use to prove the
                 soundness of System D.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2103621.2103686",
  x-isbn =       "978-1-4503-1083-3",
  x-issn =       "0362-1340",
  x-series =     "POPL '12",
  x-url =        "http://dx.doi.org/10.1145/2103621.2103686",
  xpages =       "231--244",
  year =         "2012",
}

@InProceedings{Chugh2012Dependent,
  author =       "Ravi Chugh and David Herman and Ranjit Jhala",
  booktitle =    "Proceedings of the ACM International Conference on
                 Object Oriented Programming Systems Languages and
                 Applications",
  citeulike-article-id = "12619681",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2384659",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2384616.2384659",
  date-added =   "2015-07-16 03:06:32",
  location =     "Tucson, Arizona, USA",
  month =        oct,
  priority =     "2",
  publisher =    "ACM",
  title =        "Dependent Types for {JavaScript}",
  x-abstract =   "We present Dependent {JavaScript} ({DJS}), a
                 statically typed dialect of the imperative,
                 object-oriented, dynamic language. {DJS} supports the
                 particularly challenging features such as run-time
                 type-tests, higher-order functions, extensible objects,
                 prototype inheritance, and arrays through a combination
                 of nested refinement types, strong updates to the heap,
                 and heap unrolling to precisely track prototype
                 hierarchies. With our implementation of {DJS}, we
                 demonstrate that the type system is expressive enough
                 to reason about a variety of tricky idioms found in
                 small examples drawn from several sources, including
                 the popular book {JavaScript}: The Good Parts and the
                 {SunSpider} benchmark suite.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2384616.2384659",
  x-isbn =       "978-1-4503-1561-6",
  x-issn =       "0362-1340",
  x-series =     "OOPSLA '12",
  x-url =        "http://dx.doi.org/10.1145/2384616.2384659",
  xpages =       "587--606",
  year =         "2012",
}

@InProceedings{Cadar2006EXE,
  author =       "Cristian Cadar and Vijay Ganesh and Peter M. Pawlowski
                 and David L. Dill and Dawson R. Engler",
  booktitle =    "Proceedings of the 13th ACM Conference on Computer and
                 Communications Security",
  citeulike-article-id = "1438741",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1180445",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1180405.1180445",
  date-added =   "2015-07-15 20:04:25",
  location =     "Alexandria, Virginia, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "{EXE}: Automatically Generating Inputs of Death",
  x-abstract =   "This paper presents {EXE}, an effective bug-finding
                 tool that automatically generates inputs that crash
                 real code. Instead of running code on manually or
                 randomly constructed input, {EXE} runs it on symbolic
                 input initially allowed to be {"}anything.{"} As
                 checked code runs, {EXE} tracks the constraints on each
                 symbolic (i.e., input-derived) memory location. If a
                 statement uses a symbolic value, {EXE} does not run it,
                 but instead adds it as an input-constraint; all other
                 statements run as usual. If code conditionally checks a
                 symbolic expression, {EXE} forks execution,
                 constraining the expression to be true on the true
                 branch and false on the other. Because {EXE} reasons
                 about all possible values on a path, it has much more
                 power than a traditional runtime tool: (1) it can force
                 execution down any feasible program path and (2) at
                 dangerous operations (e.g., a pointer dereference), it
                 detects if the current path constraints allow any value
                 that causes a {bug.When} a path terminates or hits a
                 bug, {EXE} automatically generates a test case by
                 solving the current path constraints to find concrete
                 values using its own co-designed constraint solver,
                 {STP}. Because {EXE}'s constraints have no
                 approximations, feeding this concrete input to an
                 uninstrumented version of the checked code will cause
                 it to follow the same path and hit the same bug
                 (assuming deterministic {code).EXE} works well on real
                 code, finding bugs along with inputs that trigger them
                 in: the {BSD} and Linux packet filter implementations,
                 the udhcpd {DHCP} server, the pcre regular expression
                 library, and three Linux file systems.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1180405.1180445",
  x-isbn =       "1-59593-518-5",
  x-series =     "CCS '06",
  x-url =        "http://dx.doi.org/10.1145/1180405.1180445",
  xpages =       "322--335",
  year =         "2006",
}

@InProceedings{Nguyen2015Relatively,
  author =       "Ph\'{u}c C. Nguy{\~{}{\^{e}}}n and David Van Horn",
  booktitle =    "Proceedings of the 36th ACM SIGPLAN Conference on
                 Programming Language Design and Implementation",
  citeulike-article-id = "13671014",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2737971",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2737924.2737971",
  date-added =   "2015-07-13 22:33:58",
  location =     "Portland, OR, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "Relatively Complete Counterexamples for Higher-order
                 Programs",
  x-abstract =   "In this paper, we study the problem of generating
                 inputs to a higher-order program causing it to error.
                 We first approach the problem in the setting of {PCF},
                 a typed, core functional language and contribute the
                 first relatively complete method for constructing
                 counterexamples for {PCF} programs. The method is
                 relatively complete with respect to a first-order
                 solver over the base types of {PCF}. In practice, this
                 means an {SMT} solver can be used for the effective,
                 automated generation of higher-order counterexamples
                 for a large class of programs. We achieve this result
                 by employing a novel form of symbolic execution for
                 higher-order programs. The remarkable aspect of this
                 symbolic execution is that even though symbolic
                 higher-order inputs and values are considered, the path
                 condition remains a first-order formula. Our handling
                 of symbolic function application enables the
                 reconstruction of higher-order counterexamples from
                 this first-order formula. After establishing our main
                 theoretical results, we sketch how to apply the
                 approach to untyped, higher-order, stateful languages
                 with first-class contracts and show how counterexample
                 generation can be used to detect contract violations in
                 this setting. To validate our approach, we implement a
                 tool generating counterexamples for erroneous modules
                 written in Racket.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2737924.2737971",
  x-isbn =       "978-1-4503-3468-6",
  x-series =     "PLDI 2015",
  x-url =        "http://dx.doi.org/10.1145/2737924.2737971",
  xpages =       "446--456",
  year =         "2015",
}

@InCollection{Cousot2012Formal,
  author =       "Patrick Cousot",
  booktitle =    "NASA Formal Methods",
  citeulike-article-id = "13448916",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2260729",
  citeulike-linkout-1 = "http://dx.doi.org/10.1007/978-3-642-28891-3\_3",
  citeulike-linkout-2 = "http://link.springer.com/chapter/10.1007/978-3-642-28891-3\_3",
  date-added =   "2015-07-11 18:38:55",
  location =     "Norfolk, VA",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "Formal Verification by Abstract Interpretation",
  volume =       "7226",
  x-abstract =   "We provide a rapid overview of the theoretical
                 foundations and main applications of abstract
                 interpretation and show that it currently provides
                 scaling solutions to achieving assurance in mission-
                 and safety-critical systems through verification by
                 fully automatic, semantically sound and precise static
                 program analysis.",
  x-address =    "Berlin, Heidelberg",
  x-doi =        "10.1007/978-3-642-28891-3\_3",
  x-editor =     "Goodloe, AlwynE and Person, Suzette",
  x-isbn =       "978-3-642-28890-6",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-642-28891-3\_3",
  xpages =       "3--7",
  year =         "2012",
}

@InCollection{Blazy2013Formal,
  author =       "Sandrine Blazy and Vincent Laporte and Andr\'{e}
                 Maroneze and David Pichardie",
  booktitle =    "Static Analysis",
  citeulike-article-id = "13669499",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-642-38856-9\_18",
  citeulike-linkout-1 = "http://link.springer.com/chapter/10.1007/978-3-642-38856-9\_18",
  date-added =   "2015-07-11 04:15:34",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "Formal Verification of a {C} Value Analysis Based on
                 Abstract Interpretation",
  volume =       "7935",
  x-abstract =   "Static analyzers based on abstract interpretation are
                 complex pieces of software implementing delicate
                 algorithms. Even if static analysis techniques are well
                 understood, their implementation on real languages is
                 still error-prone. This paper presents a formal
                 verification using the Coq proof assistant: a
                 formalization of a value analysis (based on abstract
                 interpretation), and a soundness proof of the value
                 analysis. The formalization relies on generic
                 interfaces. The mechanized proof is facilitated by a
                 translation validation of a Bourdoncle fixpoint
                 iterator. The work has been integrated into the
                 {CompCert} verified C-compiler. Our verified analysis
                 directly operates over an intermediate language of the
                 compiler having the same expressiveness as C. The
                 automatic extraction of our value analysis into {OCaml}
                 yields a program with competitive results, obtained
                 from experiments on a number of benchmarks and
                 comparisons with the {Frama-C} tool.",
  x-doi =        "10.1007/978-3-642-38856-9\_18",
  x-editor =     "Logozzo, Francesco and F{\"{a}}hndrich, Manuel",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-642-38856-9\_18",
  xpages =       "324--344",
  year =         "2013",
}

@InCollection{Barthe2007Certified,
  author =       "Gilles Barthe and David Pichardie and Tamara Rezk",
  booktitle =    "Programming Languages and Systems",
  citeulike-article-id = "1760661",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-540-71316-6\_10",
  citeulike-linkout-1 = "http://link.springer.com/chapter/10.1007/978-3-540-71316-6\_10",
  date-added =   "2015-07-11 04:14:40",
  journal =      "Programming Languages and Systems",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "A Certified Lightweight Non-interference Java Bytecode
                 Verifier",
  volume =       "4421",
  x-abstract =   "Non-interference is a semantical condition on programs
                 that guarantees the absence of illicit information flow
                 throughout their execution, and that can be enforced by
                 appropriate information flow type systems. Much of
                 previous work on type systems for non-interference has
                 focused on calculi or high-level programming languages,
                 and existing type systems for low-level languages
                 typically omit objects, exceptions, and method calls,
                 and/or do not prove formally the soundness of the type
                 system. We define an information flow type system for a
                 sequential {JVM}-like language that includes classes,
                 objects, arrays, exceptions and method calls, and prove
                 that it guarantees non-interference. For increased
                 confidence, we have formalized the proof in the proof
                 assistant Coq; an additional benefit of the
                 formalization is that we have extracted from our proof
                 a certified lightweight bytecode verifier for
                 information flow. Our work provides, to our best
                 knowledge, the first sound and implemented information
                 flow type system for such an expressive fragment of the
                 {JVM}.",
  x-doi =        "10.1007/978-3-540-71316-6\_10",
  x-editor =     "De Nicola, Rocco",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-540-71316-6\_10",
  xpages =       "125--140",
  year =         "2007",
}

@InCollection{Norell2009Dependently,
  author =       "Ulf Norell",
  booktitle =    "Advanced Functional Programming",
  chapter =      "5",
  citeulike-article-id = "9638730",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-642-04652-0\_5",
  citeulike-linkout-1 = "http://www.springerlink.com/content/8x0h38858233vn26",
  citeulike-linkout-2 = "http://link.springer.com/chapter/10.1007/978-3-642-04652-0\_5",
  date-added =   "2015-07-10 19:46:18",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "Dependently Typed Programming in Agda",
  volume =       "5832",
  x-abstract =   "In {Hindley-Milner} style languages, such as Haskell
                 and {ML}, there is a clear separation between types and
                 values. In a dependently typed language the line is
                 more blurry - types can contain (depend on) arbitrary
                 values and appear as arguments and results of ordinary
                 functions.",
  x-address =    "Berlin, Heidelberg",
  x-doi =        "10.1007/978-3-642-04652-0\_5",
  x-editor =     "Koopman, Pieter and Plasmeijer, Rinus and Swierstra,
                 Doaitse",
  x-isbn =       "978-3-642-04651-3",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-642-04652-0\_5",
  xpages =       "230--266",
  year =         "2009",
}

@InCollection{Bove2009Brief,
  author =       "Ana Bove and Peter Dybjer and Ulf Norell",
  booktitle =    "Theorem Proving in Higher Order Logics",
  chapter =      "6",
  citeulike-article-id = "6053688",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-642-03359-9\_6",
  citeulike-linkout-1 = "http://www.springerlink.com/content/h12lq70470983732",
  citeulike-linkout-2 = "http://link.springer.com/chapter/10.1007/978-3-642-03359-9\_6",
  date-added =   "2015-07-10 19:35:22",
  journal =      "Theorem Proving in Higher Order Logics",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "A Brief Overview of Agda – {A} Functional Language
                 with Dependent Types",
  volume =       "5674",
  x-abstract =   "We give an overview of Agda, the latest in a series of
                 dependently typed programming languages developed in
                 Gothenburg. Agda is based on {Martin-L\"{o}f}'s
                 intuitionistic type theory but extends it with numerous
                 programming language features. It supports a wide range
                 of inductive data types, including inductive families
                 and inductive-recursive types, with associated flexible
                 pattern-matching. Unlike other proof assistants, Agda
                 is not tactic-based. Instead it has an Emacs-based
                 interface which allows programming by gradual
                 refinement of incomplete type-correct terms.",
  x-address =    "Berlin, Heidelberg",
  x-doi =        "10.1007/978-3-642-03359-9\_6",
  x-editor =     "Berghofer, Stefan and Nipkow, Tobias and Urban,
                 Christian and Wenzel, Makarius",
  x-isbn =       "978-3-642-03358-2",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-642-03359-9\_6",
  xpages =       "73--78",
  year =         "2009",
}

@InCollection{Tesson2011Program,
  author =       "Julien Tesson and Hideki Hashimoto and Zhenjiang Hu
                 and Fr\'{e}d\'{e}ric Loulergue and Masato Takeichi",
  booktitle =    "Algebraic Methodology and Software Technology",
  chapter =      "10",
  citeulike-article-id = "8823271",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-642-17796-5\_10",
  citeulike-linkout-1 = "http://www.springerlink.com/content/4777t68m32tm1606",
  citeulike-linkout-2 = "http://link.springer.com/chapter/10.1007/978-3-642-17796-5\_10",
  date-added =   "2015-07-03 17:13:24",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "Program Calculation in {C}oq",
  volume =       "6486",
  x-abstract =   "Program calculation, being a programming technique
                 that derives programs from specification by means of
                 formula manipulation, is a challenging activity. It
                 requires human insights and creativity, and needs
                 systems to help human to focus on clever parts of the
                 derivation by automating tedious ones and verifying
                 correctness of transformations. Different from many
                 existing systems, we show in this paper that Coq, a
                 popular theorem prover, provides a cheap way to
                 implement a powerful system to support program
                 calculation, which has not been recognized so far. We
                 design and implement a set of tactics for the Coq proof
                 assistant to help the user to derive programs by
                 program calculation and to write proofs in
                 calculational form. The use of these tactics is
                 demonstrated through program calculations in Coq based
                 on the theory of lists.",
  x-address =    "Berlin, Heidelberg",
  x-doi =        "10.1007/978-3-642-17796-5\_10",
  x-editor =     "Johnson, Michael and Pavlovic, Dusko",
  x-isbn =       "978-3-642-17795-8",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-642-17796-5\_10",
  xpages =       "163--179",
  year =         "2011",
}

@InProceedings{Silva2008Galculator,
  author =       "Paulo F. Silva and Jos\'{e} N. Oliveira",
  booktitle =    "Proceedings of the 10th International ACM SIGPLAN
                 Conference on Principles and Practice of Declarative
                 Programming",
  citeulike-article-id = "13664043",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1389456",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1389449.1389456",
  date-added =   "2015-07-03 14:58:49",
  location =     "Valencia, Spain",
  priority =     "2",
  publisher =    "ACM",
  title =        "`{G}alculator': Functional Prototype of a
                 {G}alois-connection Based Proof Assistant",
  x-abstract =   "Galculator is the name of the prototype of a proof
                 assistant of a special brand: it is solely based on the
                 algebra of Galois connections. When combined with the
                 pointfree transform and tactics such as the indirect
                 equality principle, Galois connections offer a very
                 powerful, generic device to tackle the complexity of
                 proofs in program verification. The paper describes the
                 architecture of the current Galculator prototype, which
                 is implemented in Haskell in order to steer types as
                 much as possible. The prospect of integrating the
                 Galculator with other proof assistants such as e.g. Coq
                 is also discussed",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1389449.1389456",
  x-isbn =       "978-1-60558-117-0",
  x-series =     "PPDP '08",
  x-url =        "http://dx.doi.org/10.1145/1389449.1389456",
  xpages =       "44--55",
  year =         "2008",
}

@InCollection{Sergey2012Calculating,
  author =       "Ilya Sergey and Jan Midtgaard and Dave Clarke",
  booktitle =    "Mathematics of Program Construction",
  citeulike-article-id = "13663401",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-642-31113-0\_8",
  citeulike-linkout-1 = "http://link.springer.com/chapter/10.1007/978-3-642-31113-0\_8",
  date-added =   "2015-07-02 21:15:19",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "Calculating Graph Algorithms for Dominance and
                 Shortest Path",
  volume =       "7342",
  x-abstract =   "We calculate two iterative, polynomial-time graph
                 algorithms from the literature: a dominance algorithm
                 and an algorithm for the single-source shortest path
                 problem. Both algorithms are calculated directly from
                 the definition of the properties by fixed-point fusion
                 of (1) a least fixed point expressing all finite paths
                 through a directed graph and (2) Galois connections
                 that capture dominance and path length. The approach
                 illustrates that reasoning in the style of fixed-point
                 calculus extends gracefully to the domain of graph
                 algorithms. We thereby bridge common practice from the
                 school of program calculation with common practice from
                 the school of static program analysis, and build a
                 novel view on iterative graph algorithms as instances
                 of abstract interpretation.",
  x-doi =        "10.1007/978-3-642-31113-0\_8",
  x-editor =     "Gibbons, Jeremy and Nogueira, Pablo",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-642-31113-0\_8",
  xpages =       "132--156",
  year =         "2012",
}

@InCollection{Cachera2010Certified,
  author =       "David Cachera and David Pichardie",
  booktitle =    "Interactive Theorem Proving",
  citeulike-article-id = "13663399",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-642-14052-5\_3",
  citeulike-linkout-1 = "http://link.springer.com/chapter/10.1007/978-3-642-14052-5\_3",
  date-added =   "2015-07-02 21:11:25",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "A Certified Denotational Abstract Interpreter",
  volume =       "6172",
  x-abstract =   "Abstract Interpretation proposes advanced techniques
                 for static analysis of programs that raise specific
                 challenges for machine-checked soundness proofs. Most
                 classical dataflow analysis techniques iterate
                 operators on lattices without infinite ascending
                 chains. In contrast, abstract interpreters are looking
                 for fixpoints in infinite lattices where widening and
                 narrowing are used for accelerating the convergence.
                 Smart iteration strategies are crucial when using such
                 accelerating operators because they directly impact the
                 precision of the analysis diagnostic. In this paper, we
                 show how we manage to program and prove correct in Coq
                 an abstract interpreter that uses iteration strategies
                 based on program syntax. A key component of the
                 formalization is the introduction of an intermediate
                 semantics based on a generic least-fixpoint operator on
                 complete lattices and allows us to decompose the
                 soundness proof in an elegant manner.",
  x-doi =        "10.1007/978-3-642-14052-5\_3",
  x-editor =     "Kaufmann, Matt and Paulson, LawrenceC",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-642-14052-5\_3",
  xpages =       "9--24",
  year =         "2010",
}

@InProceedings{Jourdan2015FormallyVerified,
  author =       "Jacques H. Jourdan and Vincent Laporte and Sandrine
                 Blazy and Xavier Leroy and David Pichardie",
  booktitle =    "Proceedings of the 42Nd Annual ACM SIGPLAN-SIGACT
                 Symposium on Principles of Programming Languages",
  citeulike-article-id = "13652376",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2676966",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2676726.2676966",
  date-added =   "2015-06-20 19:09:55",
  location =     "Mumbai, India",
  priority =     "2",
  publisher =    "ACM",
  title =        "A {Formally-Verified} {C} Static Analyzer",
  x-abstract =   "This paper reports on the design and soundness proof,
                 using the Coq proof assistant, of Verasco, a static
                 analyzer based on abstract interpretation for most of
                 the {ISO} C 1999 language (excluding recursion and
                 dynamic allocation). Verasco establishes the absence of
                 run-time errors in the analyzed programs. It enjoys a
                 modular architecture that supports the extensible
                 combination of multiple abstract domains, both
                 relational and non-relational. Verasco integrates with
                 the {CompCert} formally-verified C compiler so that not
                 only the soundness of the analysis results is
                 guaranteed with mathematical certitude, but also the
                 fact that these guarantees carry over to the compiled
                 code.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2676726.2676966",
  x-isbn =       "978-1-4503-3300-9",
  x-series =     "POPL '15",
  x-url =        "http://dx.doi.org/10.1145/2676726.2676966",
  xpages =       "247--259",
  year =         "2015",
}

@InProceedings{Cousot2014Galois,
  author =       "Patrick` Cousot and Radhia Cousot",
  booktitle =    "Proceedings of the 41st ACM SIGPLAN-SIGACT Symposium
                 on Principles of Programming Languages",
  citeulike-article-id = "13652375",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2537850",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2535838.2537850",
  date-added =   "2015-06-20 19:09:37",
  location =     "San Diego, California, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "A {G}alois Connection Calculus for Abstract
                 Interpretation",
  x-abstract =   "We introduce a Galois connection calculus for language
                 independent specification of abstract interpretations
                 used in programming language semantics, formal
                 verification, and static analysis. This Galois
                 connection calculus and its type system are typed by
                 abstract interpretation.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2535838.2537850",
  x-isbn =       "978-1-4503-2544-8",
  x-series =     "POPL '14",
  x-url =        "http://dx.doi.org/10.1145/2535838.2537850",
  xpages =       "3--4",
  year =         "2014",
}

@InCollection{Kodumal2005Banshee,
  author =       "John Kodumal and Alex Aiken",
  booktitle =    "Static Analysis",
  citeulike-article-id = "13589323",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/11547662\_16",
  citeulike-linkout-1 = "http://link.springer.com/chapter/10.1007/11547662\_16",
  date-added =   "2015-04-23 00:46:34",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "Banshee: {A} Scalable {Constraint-Based} Analysis
                 Toolkit",
  volume =       "3672",
  x-abstract =   "We introduce Banshee, a toolkit for constructing
                 constraint-based analyses. Banshee's novel features
                 include a code generator for creating customized
                 constraint resolution engines, incremental analysis
                 based on backtracking, and fast persistence. These
                 features make Banshee useful as a foundation for
                 production program analyses.",
  x-doi =        "10.1007/11547662\_16",
  x-editor =     "Hankin, Chris and Siveroni, Igor",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/11547662\_16",
  xpages =       "218--234",
  year =         "2005",
}

@InCollection{Lu2013Incremental,
  author =       "Yi Lu and Lei Shang and Xinwei Xie and Jingling Xue",
  booktitle =    "Compiler Construction",
  citeulike-article-id = "13589319",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-642-37051-9\_4",
  citeulike-linkout-1 = "http://link.springer.com/chapter/10.1007/978-3-642-37051-9\_4",
  date-added =   "2015-04-22 23:42:41",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "An Incremental Points-to Analysis with
                 {CFL}-Reachability",
  volume =       "7791",
  x-abstract =   "Developing scalable and precise points-to analyses is
                 increasingly important for analysing and optimising
                 object-oriented programs where pointers are used
                 pervasively. An incremental analysis for a program
                 updates the existing analysis information after program
                 changes to avoid reanalysing it from scratch. This can
                 be efficiently deployed in software development
                 environments where code changes are often small and
                 frequent. This paper presents an incremental approach
                 for demand-driven context-sensitive points-to analyses
                 based on {Context-Free} Language ({CFL}) reachability.
                 By tracing the {CFL}-reachable paths traversed in
                 computing points-to sets, we can precisely identify and
                 recompute on demand only the points-to sets affected by
                 the program changes made. Combined with a flexible
                 policy for controlling the granularity of traces, our
                 analysis achieves significant speedups with little
                 space overhead over reanalysis from scratch when
                 evaluated with a null dereferencing client using 14
                 Java benchmarks.",
  x-doi =        "10.1007/978-3-642-37051-9\_4",
  x-editor =     "Jhala, Ranjit and De Bosschere, Koen",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-642-37051-9\_4",
  xpages =       "61--81",
  year =         "2013",
}

@Article{Yang2014Directed,
  author =       "Guowei Yang and Suzette Person and Neha Rungta and
                 Sarfraz Khurshid",
  citeulike-article-id = "13589318",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2629536",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2629536",
  date-added =   "2015-04-22 23:37:55",
  journal =      "ACM Trans. Softw. Eng. Methodol.",
  month =        oct,
  number =       "1",
  priority =     "2",
  publisher =    "ACM",
  title =        "Directed Incremental Symbolic Execution",
  volume =       "24",
  x-abstract =   "The last few years have seen a resurgence of interest
                 in the use of symbolic execution—a program analysis
                 technique developed more than three decades ago to
                 analyze program execution paths. Scaling symbolic
                 execution to real systems remains challenging despite
                 recent algorithmic and technological advances. An
                 effective approach to address scalability is to reduce
                 the scope of the analysis. For example, in regression
                 analysis, differences between two related program
                 versions are used to guide the analysis. While such an
                 approach is intuitive, finding efficient and precise
                 ways to identify program differences, and characterize
                 their impact on how the program executes has proved
                 challenging in practice. In this article, we present
                 Directed Incremental Symbolic Execution ({DiSE}), a
                 novel technique for detecting and characterizing the
                 impact of program changes to scale symbolic execution.
                 The novelty of {DiSE} is to combine the efficiencies of
                 static analysis techniques to compute program
                 difference information with the precision of symbolic
                 execution to explore program execution paths and
                 generate path conditions affected by the differences.
                 {DiSE} complements other reduction and bounding
                 techniques for improving symbolic execution.
                 Furthermore, {DiSE} does not require analysis results
                 to be carried forward as the software evolves—only
                 the source code for two related program versions is
                 required. An experimental evaluation using our
                 implementation of {DiSE} illustrates its effectiveness
                 at detecting and characterizing the effects of program
                 changes.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2629536",
  x-issn =       "1049-331X",
  x-url =        "http://dx.doi.org/10.1145/2629536",
  year =         "2014",
}

@PhdThesis{Yang2013Enhancing,
  author =       "Guowei Yang",
  citeulike-article-id = "13589317",
  date-added =   "2015-04-22 23:30:02",
  priority =     "2",
  school =       "The University of Texas at Austin",
  title =        "Enhancing symbolic execution using memoization and
                 incremental techniques",
  year =         "2013",
}

@InProceedings{Hammer2014Adapton,
  author =       "Matthew A. Hammer and Khoo Y. Phang and Michael Hicks
                 and Jeffrey S. Foster",
  booktitle =    "Proceedings of the 35th ACM SIGPLAN Conference on
                 Programming Language Design and Implementation",
  citeulike-article-id = "13581431",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2594291.2594324",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2594291.2594324",
  date-added =   "2015-04-13 22:57:24",
  location =     "Edinburgh, United Kingdom",
  priority =     "2",
  publisher =    "ACM",
  title =        "Adapton: Composable, Demand-driven Incremental
                 Computation",
  x-abstract =   "Many researchers have proposed programming languages
                 that support incremental computation ({IC}), which
                 allows programs to be efficiently re-executed after a
                 small change to the input. However, existing
                 implementations of such languages have two important
                 drawbacks. First, recomputation is oblivious to
                 specific demands on the program output; that is, if a
                 program input changes, all dependencies will be
                 recomputed, even if an observer no longer requires
                 certain outputs. Second, programs are made incremental
                 as a unit, with little or no support for reusing
                 results outside of their original context, e.g., when
                 reordered. To address these problems, we present
                 λiccdd, a core calculus that applies a demand-driven
                 semantics to incremental computation, tracking changes
                 in a hierarchical fashion in a novel demanded
                 computation graph. λiccdd also formalizes an explicit
                 separation between inner, incremental computations and
                 outer observers. This combination ensures λiccdd
                 programs only recompute computations as demanded by
                 observers, and allows inner computations to be reused
                 more liberally. We present Adapton, an {OCaml} library
                 implementing λiccdd. We evaluated Adapton on a range
                 of benchmarks, and found that it provides reliable
                 speedups, and in many cases dramatically outperforms
                 state-of-the-art {IC} approaches.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2594291.2594324",
  x-isbn =       "978-1-4503-2784-8",
  x-series =     "PLDI '14",
  x-url =        "http://dx.doi.org/10.1145/2594291.2594324",
  xpages =       "156--166",
  year =         "2014",
}

@InProceedings{Nasre2012Exploiting,
  author =       "Rupesh Nasre",
  booktitle =    "Proceedings of the 2012 International Symposium on
                 Memory Management",
  citeulike-article-id = "13581403",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2259013",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2426642.2259013",
  date-added =   "2015-04-13 22:18:32",
  month =        jun,
  priority =     "2",
  publisher =    "ACM",
  title =        "Exploiting the Structure of the Constraint Graph for
                 Efficient Points-to Analysis",
  x-abstract =   "Points-to analysis is a key compiler analysis. Several
                 memory related optimizations use points-to information
                 to improve their effectiveness. Points-to analysis is
                 performed by building a constraint graph of pointer
                 variables and dynamically updating it to propagate more
                 and more points-to information across its subset edges.
                 So far, the structure of the constraint graph has been
                 only trivially exploited for efficient propagation of
                 information, e.g., in identifying cyclic components or
                 to propagate information in topological order. We
                 perform a careful study of its structure and propose a
                 new inclusion-based flow-insensitive context-sensitive
                 points-to analysis algorithm based on the notion of
                 dominant pointers. We also propose a new kind of
                 pointer-equivalence based on dominant pointers which
                 provides significantly more opportunities for reducing
                 the number of pointers tracked during the analysis.
                 Based on this hitherto unexplored form of
                 pointer-equivalence, we develop a new context-sensitive
                 flow insensitive points-to analysis algorithm which
                 uses incremental dominator update to efficiently
                 compute points-to information. Using a large suite of
                 programs consisting of {SPEC} 2000 benchmarks and five
                 large open source programs we show that our points-to
                 analysis is 88\% faster than {BDD}-based Lazy Cycle
                 Detection and 2× faster than Deep Propagation. We
                 argue that our approach of detecting dominator-based
                 pointer-equivalence is a key to improve points-to
                 analysis efficiency.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2426642.2259013",
  x-issn =       "0362-1340",
  x-url =        "http://dx.doi.org/10.1145/2426642.2259013",
  xpages =       "121--132",
  year =         "2012",
}

@InProceedings{Vivien2001Incrementalized,
  author =       "Fr\'{e}d\'{e}ric Vivien and Martin Rinard",
  booktitle =    "Proceedings of the ACM SIGPLAN Conference on
                 Programming Language Design and Implementation",
  citeulike-article-id = "560968",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=378795.378804",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/378795.378804",
  date-added =   "2015-04-13 22:08:37",
  location =     "Snowbird, Utah, USA",
  month =        may,
  number =       "5",
  priority =     "2",
  publisher =    "ACM",
  title =        "Incrementalized Pointer and Escape Analysis",
  volume =       "36",
  x-abstract =   "We present a new pointer and escape analysis. Instead
                 of analyzing the whole program, the algorithm
                 incrementally analyzes only those parts of the program
                 that may deliver useful results. An analysis policy
                 monitors the analysis results to direct the incremental
                 investment of analysis resources to those parts of the
                 program that offer the highest expected optimization
                 return. Our experimental results show that almost all
                 of the objects are allocated at a small number of
                 allocation sites and that an incremental analysis of a
                 small region of the program surrounding each site can
                 deliver almost all of the benefit of a whole-program
                 analysis. Our analysis policy is usually able to
                 deliver this benefit at a fraction of the whole-program
                 analysis cost.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/378795.378804",
  x-isbn =       "1-58113-414-2",
  x-issn =       "0362-1340",
  x-series =     "PLDI '01",
  x-url =        "http://dx.doi.org/10.1145/378795.378804",
  xpages =       "35--46",
  year =         "2001",
}

@InProceedings{Pugh1989Incremental,
  author =       "W. Pugh and T. Teitelbaum",
  booktitle =    "Proceedings of the 16th ACM SIGPLAN-SIGACT Symposium
                 on Principles of Programming Languages",
  citeulike-article-id = "4108114",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=75305",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/75277.75305",
  date-added =   "2015-04-13 21:53:45",
  location =     "Austin, Texas, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "Incremental Computation via Function Caching",
  x-abstract =   "An abstract is not available.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/75277.75305",
  x-isbn =       "0-89791-294-2",
  x-series =     "POPL '89",
  x-url =        "http://dx.doi.org/10.1145/75277.75305",
  xpages =       "315--328",
  year =         "1989",
}

@InProceedings{Cousot1976Static,
  author =       "P. Cousot and R. Cousot",
  booktitle =    "2nd International Symposium on Programming",
  citeulike-article-id = "801453",
  date-added =   "2015-04-13 21:50:31",
  keywords =     "static\_analysis",
  month =        apr,
  priority =     "2",
  title =        "Static Determination of Dynamic Properties of
                 Programs",
  xpages =       "106--130",
  year =         "1976",
}

@Article{DBLP:journals/corr/NguyenH15,
  archiveprefix = "arXiv",
  author =       "Ph\'{u}c C. Nguyên and David Van{ }Horn",
  citeulike-article-id = "13548719",
  citeulike-linkout-0 = "http://arxiv.org/abs/1411.3967",
  date-added =   "2015-03-14 00:37:26",
  eprint =       "1411.3967",
  journal =      "CoRR",
  priority =     "2",
  title =        "Relatively Complete Counterexamples for {Higher-Order}
                 Programs",
  volume =       "abs/1411.3967",
  x-url =        "http://arxiv.org/abs/1411.3967",
  year =         "2015",
}

@InProceedings{Gilray2013Unified,
  author =       "Thomas Gilray and Matthew Might",
  booktitle =    "Proceedings of the 2013 Workshop on Scheme and
                 Functional Programming",
  citeulike-article-id = "13545084",
  date-added =   "2015-03-09 22:57:17",
  day =          "13",
  location =     "Washington, D.C.",
  month =        nov,
  priority =     "2",
  title =        "A Unified Approach to Polyvariance in Abstract
                 Interpretations",
  year =         "2013",
}

@InProceedings{Jenkins2014Concrete,
  author =       "Maria Jenkins and Leif Andersen and Thomas Gilray and
                 Matthew Might",
  booktitle =    "Proceedings of the 2014 Workshop on Scheme and
                 Functional Programming",
  citeulike-article-id = "13545082",
  date-added =   "2015-03-09 22:50:16",
  day =          "19",
  location =     "Washington, D.C.",
  month =        nov,
  priority =     "2",
  title =        "Concrete and Abstract Interpretation: Better
                 Together",
  year =         "2014",
}

@InProceedings{Liang2013AnaDroid,
  author =       "Shuying Liang and Matthew Might and David Van Horn",
  booktitle =    "Proceedings of Tools for Automatic Program Analysis",
  citeulike-article-id = "13545079",
  date-added =   "2015-03-09 22:43:03",
  day =          "19",
  location =     "Seattle, Washington",
  month =        jun,
  priority =     "2",
  title =        "{AnaDroid}: Malware Analysis of Android with
                 {User-Supplied} Predicates",
  year =         "2013",
}

@InProceedings{Liang2013Entangled,
  author =       "Shuying Liang and Matthew Might",
  booktitle =    "Proceedings of the 2013 Workshop on Scheme and
                 Functional Programming",
  citeulike-article-id = "13545073",
  date-added =   "2015-03-09 22:35:18",
  day =          "13",
  location =     "Washington, D.C.",
  month =        nov,
  priority =     "2",
  title =        "Entangled Abstract Domains for Higher-order Programs",
  year =         "2013",
}

@InProceedings{Liang2013Sound,
  author =       "Shuying Liang and Andrew W. Keep and Matthew Might and
                 Steven Lyde and Thomas Gilray and Petey Aldous and
                 David Van Horn",
  booktitle =    "Proceedings of the Third ACM Workshop on Security and
                 Privacy in Smartphones \&\#38; Mobile Devices",
  citeulike-article-id = "13097878",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2516769",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2516760.2516769",
  date-added =   "2015-03-09 22:24:48",
  location =     "Berlin, Germany",
  priority =     "2",
  publisher =    "ACM",
  title =        "Sound and Precise Malware Analysis for Android via
                 Pushdown Reachability and Entry-point Saturation",
  x-abstract =   "Sound malware analysis of Android applications is
                 challenging. First, object-oriented programs exhibit
                 highly interprocedural, dynamically dispatched control
                 structure. Second, the Android programming paradigm
                 relies heavily on the asynchronous execution of
                 multiple entry points. Existing analysis techniques
                 focus more on the second challenge, while relying on
                 traditional analytic techniques that suffer from
                 inherent imprecision or unsoundness to solve the first.
                 We present Anadroid, a static malware analysis
                 framework for Android apps. Anadroid exploits two
                 techniques to soundly raise precision: (1) it uses a
                 pushdown system to precisely model dynamically
                 dispatched interprocedural and exception-driven
                 control-flow; (2) it uses {Entry-Point} Saturation
                 ({EPS}) to soundly approximate all possible
                 interleavings of asynchronous entry points in Android
                 applications. (It also integrates static taint-flow
                 analysis and least permissions analysis to expand the
                 class of malicious behaviors which it can catch.)
                 Anadroid provides rich user interface support for human
                 analysts which must ultimately rule on the
                 {"}maliciousness{"} of a behavior. To demonstrate the
                 effectiveness of Anadroid's malware analysis, we had
                 teams of analysts analyze a challenge suite of 52
                 Android applications released as part of the Automated
                 Program Analysis for Cybersecurity ({APAC}) {DARPA}
                 program. The first team analyzed the apps using a
                 version of Anadroid that uses traditional
                 (finite-state-machine-based) control-flow-analysis
                 found in existing malware analysis tools; the second
                 team analyzed the apps using a version of Anadroid that
                 uses our enhanced pushdown-based control-flow-analysis.
                 We measured machine analysis time, human analyst time,
                 and their accuracy in flagging malicious applications.
                 With pushdown analysis, we found statistically
                 significant (p",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2516760.2516769",
  x-isbn =       "978-1-4503-2491-5",
  x-series =     "SPSM '13",
  x-url =        "http://dx.doi.org/10.1145/2516760.2516769",
  xpages =       "21--32",
  year =         "2013",
}

@InProceedings{Liang2014Fast,
  author =       "Shuying Liang and Weibin Sun and M. Might",
  booktitle =    "Source Code Analysis and Manipulation (SCAM), 2014
                 IEEE 14th International Working Conference on",
  citeulike-article-id = "13545067",
  citeulike-linkout-0 = "http://dx.doi.org/10.1109/scam.2014.40",
  citeulike-linkout-1 = "http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6975656",
  date-added =   "2015-03-09 22:17:07",
  priority =     "2",
  publisher =    "IEEE",
  title =        "Fast Flow Analysis with Godel Hashes",
  x-doi =        "10.1109/scam.2014.40",
  x-url =        "http://dx.doi.org/10.1109/scam.2014.40",
  xpages =       "225--234",
  year =         "2014",
}

@InProceedings{Liang2014Pruning,
  author =       "Shuying Liang and Weibin Sun and Matthew Might and
                 Andrew Keep and David Van Horn",
  booktitle =    "Source Code Analysis and Manipulation (SCAM), 2014
                 IEEE 14th International Working Conference on",
  citeulike-article-id = "13545055",
  citeulike-linkout-0 = "http://dx.doi.org/10.1109/scam.2014.44",
  citeulike-linkout-1 = "http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6975660",
  date-added =   "2015-03-09 21:36:37",
  priority =     "2",
  publisher =    "IEEE",
  title =        "Pruning, Pushdown {Exception-Flow} Analysis",
  x-doi =        "10.1109/scam.2014.44",
  x-url =        "http://dx.doi.org/10.1109/scam.2014.44",
  xpages =       "265--274",
  year =         "2014",
}

@InProceedings{Lyde2014Environment,
  author =       "Steven Lyde and Matthew Might",
  booktitle =    "Workshop on Higher-Order Program Analysis",
  citeulike-article-id = "13545053",
  date-added =   "2015-03-09 21:30:28",
  day =          "18",
  location =     "Vienna, Austria",
  month =        jul,
  priority =     "2",
  title =        "Environment Unrolling",
  year =         "2014",
}

@InProceedings{Lyde2014Linear,
  author =       "Steven Lyde and Thomas Gilray and Matthew Might",
  booktitle =    "Proceedings of the 2014 Workshop on Scheme and
                 Functional Programming",
  citeulike-article-id = "13545049",
  date-added =   "2015-03-09 21:28:24",
  day =          "19",
  location =     "Washington, D.C.",
  month =        nov,
  priority =     "2",
  title =        "A Linear Encoding of Pushdown {Control-Flow}
                 Analysis",
  year =         "2014",
}

@InProceedings{Lyde2014Strong,
  author =       "Steven Lyde and Matthew Might",
  booktitle =    "Workshop on Higher-Order Program Analysis",
  citeulike-article-id = "13545045",
  date-added =   "2015-03-09 21:23:44",
  day =          "18",
  location =     "Vienna, Austria",
  month =        jul,
  priority =     "2",
  title =        "Strong Function Call",
  year =         "2014",
}

@InProceedings{Strub2012Selfcertification,
  author =       "Pierre Y. Strub and Nikhil Swamy and Cedric Fournet
                 and Juan Chen",
  booktitle =    "Proceedings of the 39th Annual ACM SIGPLAN-SIGACT
                 Symposium on Principles of Programming Languages",
  citeulike-article-id = "10847180",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2103723",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2103621.2103723",
  date-added =   "2014-11-19 15:30:59",
  location =     "Philadelphia, PA, USA",
  month =        jan,
  priority =     "2",
  publisher =    "ACM",
  title =        "Self-certification: Bootstrapping Certified
                 Typecheckers in {F}* with Coq",
  x-abstract =   "Well-established dependently-typed languages like Agda
                 and Coq provide reliable ways to build and check formal
                 proofs. Several other dependently-typed languages such
                 as Aura, {ATS}, Cayenne, Epigram, F*, F7, Fine, Guru,
                 {PCML5}, and Ur also explore reliable ways to develop
                 and verify programs. All these languages shine in their
                 own regard, but their implementations do not themselves
                 enjoy the degree of safety provided by machine-checked
                 verification. We propose a general technique called
                 self-certification that allows a typechecker for a
                 suitably expressive language to be certified for
                 correctness. We have implemented this technique for F*,
                 a dependently typed language on the .{NET} platform.
                 Self-certification involves implementing a typechecker
                 for F* in F*, while using all the conveniences F*
                 provides for the compiler-writer (e.g., partiality,
                 effects, implicit conversions, proof automation,
                 libraries). This typechecker is given a specification
                 ({in\~{}F}*) strong enough to ensure that it computes
                 valid typing derivations. We obtain a typing derivation
                 for the core typechecker by running it on itself, and
                 we export it to Coq as a type-derivation certificate.
                 By typechecking this derivation (in Coq) and applying
                 the F* metatheory (also mechanized in Coq), we conclude
                 that our type checker is correct. Once certified in
                 this manner, the F* typechecker is emancipated from
                 Coq. Self-certification leads to an efficient
                 certification scheme---we no longer depend on verifying
                 certificates in Coq---as well as a more broadly
                 applicable one. For instance, the self-certified F*
                 checker is suitable for use in adversarial settings
                 where Coq is not intended for use, such as run-time
                 certification of mobile code.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2103621.2103723",
  x-isbn =       "978-1-4503-1083-3",
  x-issn =       "0362-1340",
  x-series =     "POPL '12",
  x-url =        "http://dx.doi.org/10.1145/2103621.2103723",
  xpages =       "571--584",
  year =         "2012",
}

@InCollection{Almeida2010Certifying,
  author =       "Jos\'{e}Bacelar Almeida and Endre Bangerter and Manuel
                 Barbosa and Stephan Krenn and Ahmad-Reza Sadeghi and
                 Thomas Schneider",
  booktitle =    "Computer Security – ESORICS 2010",
  citeulike-article-id = "13433818",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-642-15497-3\_10",
  citeulike-linkout-1 = "http://link.springer.com/chapter/10.1007/978-3-642-15497-3\_10",
  date-added =   "2014-11-19 15:15:16",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "A Certifying Compiler for {Zero-Knowledge} Proofs of
                 Knowledge Based on {Σ-Protocols}",
  volume =       "6345",
  x-abstract =   "Zero-knowledge proofs of knowledge ({ZK}-{PoK}) are
                 important building blocks for numerous cryptographic
                 applications. Although {ZK}-{PoK} have a high potential
                 impact, their real world deployment is typically
                 hindered by their significant complexity compared to
                 other (non-interactive) crypto primitives. Moreover,
                 their design and implementation are time-consuming and
                 error-prone. We contribute to overcoming these
                 challenges as follows: We present a comprehensive
                 specification language and a compiler for {ZK}-{PoK}
                 protocols based on Σ-protocols. The compiler allows
                 the fully automatic translation of an abstract
                 description of a proof goal into an executable
                 implementation. Moreover, the compiler overcomes
                 various restrictions of previous approaches, e.g., it
                 supports the important class of exponentiation
                 homomorphisms with hidden-order co-domain, needed for
                 privacypreserving applications such as {DAA}. Finally,
                 our compiler is certifying, in the sense that it
                 automatically produces a formal proof of the soundness
                 of the compiled protocol for a large class of protocols
                 using the {Isabelle/HOL} theorem prover.",
  x-doi =        "10.1007/978-3-642-15497-3\_10",
  x-editor =     "Gritzalis, Dimitris and Preneel, Bart and Theoharidou,
                 Marianthi",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-642-15497-3\_10",
  xpages =       "151--167",
  year =         "2010",
}

@Article{Kobayashi2013Model,
  author =       "Naoki Kobayashi",
  citeulike-article-id = "12905860",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2487246",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2487241.2487246",
  date-added =   "2014-11-13 20:51:10",
  journal =      "J. ACM",
  month =        jun,
  number =       "3",
  priority =     "2",
  publisher =    "ACM",
  title =        "Model Checking {Higher-Order} Programs",
  volume =       "60",
  x-abstract =   "We propose a novel verification method for
                 higher-order functional programs based on higher-order
                 model checking, or more precisely, model checking of
                 higher-order recursion schemes (recursion schemes, for
                 short). The most distinguishing feature of our
                 verification method for higher-order programs is that
                 it is sound, complete, and automatic for the simply
                 typed λ-calculus with recursion and finite base types,
                 and for various program verification problems such as
                 reachability, flow analysis, and resource usage
                 verification. We first show that a variety of program
                 verification problems can be reduced to model checking
                 problems for recursion schemes, by transforming a
                 program into a recursion scheme that generates a tree
                 representing all the interesting possible event
                 sequences of the program. We then develop a new
                 type-based model-checking algorithm for recursion
                 schemes and implement a prototype recursion scheme
                 model checker. To our knowledge, this is the first
                 implementation of a recursion scheme model checker.
                 Experiments show that our model checker is reasonably
                 fast, despite the worst-case time complexity of
                 recursion scheme model checking being hyperexponential
                 in general. Altogether, the results provide a new,
                 promising approach to verification of higher-order
                 functional programs.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2487241.2487246",
  x-issn =       "0004-5411",
  x-url =        "http://dx.doi.org/10.1145/2487241.2487246",
  year =         "2013",
}

@InProceedings{yang:modelcheck,
  author =       "Junfeng Yang and Paul Twohey and Dawson Engler and
                 Madanlal Musuvathi",
  booktitle =    "Sixth Symposium on Operating Systems Design and
                 Implementation",
  citeulike-article-id = "638267",
  citeulike-linkout-0 = "https://db.usenix.org/events/osdi04/tech/yang/yang.pdf",
  date-added =   "2014-11-13 20:44:35",
  keywords =     "838-remzi, filesystems, folder40, reliability",
  organization = "USENIX",
  priority =     "2",
  title =        "Using Model Checking to Find Serious File System
                 Errors",
  x-abstract =   "This paper shows how to use model checking to find
                 serious errors in file systems. Model checking is a
                 formal verification technique tuned for finding
                 corner-case errors by comprehensively exploring the
                 state spaces defined by a system. File systems have two
                 dynamics that make them attractive for such an
                 approach. First, their errors are some of the most
                 serious, since they can destroy persistent data and
                 lead to unrecoverable corruption. Second, traditional
                 testing needs an impractical, exponential number of
                 test cases to check that the system will recover if it
                 crashes at any point during execution. Model checking
                 employs a variety of state-reducing techniques that
                 allow it to explore such vast state spaces efficiently.
                 We built a system, {FiSC}, for model checking file
                 systems. We applied it to three widely-used,
                 heavily-tested file systems: ext3, {JFS}, and
                 {ReiserFS}. We found serious bugs in all of them, 32 in
                 total. Most have led to patches within a day of
                 diagnosis. For each file system, {FiSC} found
                 demonstrable events leading to the unrecoverable
                 destruction of metadata and entire directories,
                 including the file system root directory ” /”.",
  x-url =        "https://db.usenix.org/events/osdi04/tech/yang/yang.pdf",
  xpages =       "273--288",
  year =         "2004",
}

@InProceedings{Xie2005Scalable,
  author =       "Yichen Xie and Alex Aiken",
  booktitle =    "Proceedings of the 32nd ACM SIGPLAN-SIGACT Symposium
                 on Principles of Programming Languages",
  citeulike-article-id = "952635",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1047659.1040334",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1047659.1040334",
  date-added =   "2014-11-13 20:40:26",
  month =        jan,
  priority =     "2",
  publisher =    "ACM",
  title =        "Scalable Error Detection Using Boolean
                 Satisfiability",
  x-abstract =   "We describe a software error-detection tool that
                 exploits recent advances in boolean satisfiability
                 ({SAT}) solvers. Our analysis is path sensitive,
                 precise down to the bit level, and models pointers and
                 heap data. Our approach is also highly scalable, which
                 we achieve using two techniques. First, for each
                 program function, several optimizations compress the
                 size of the boolean formulas that model the control-
                 and data-flow and the heap locations accessed by a
                 function. Second, summaries in the spirit of type
                 signatures are computed for each function, allowing
                 inter-procedural analysis without a dramatic increase
                 in the size of the boolean constraints to be
                 {solved.We} demonstrate the effectiveness of our
                 approach by constructing a lock interface inference and
                 checking tool. In an interprocedural analysis of more
                 than 23,000 lock related functions in the latest Linux
                 kernel, the checker generated 300 warnings, of which
                 179 were unique locking errors, a false positive rate
                 of only 40\%.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1047659.1040334",
  x-issn =       "0362-1340",
  x-url =        "http://dx.doi.org/10.1145/1047659.1040334",
  xpages =       "351--363",
  year =         "2005",
}

@InProceedings{Foster2002Flowsensitive,
  author =       "Jeffrey S. Foster and Tachio Terauchi and Alex Aiken",
  booktitle =    "Proceedings of the ACM SIGPLAN Conference on
                 Programming Language Design and Implementation",
  citeulike-article-id = "13427882",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=512529.512531",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/543552.512531",
  date-added =   "2014-11-13 20:36:07",
  month =        may,
  priority =     "2",
  publisher =    "ACM",
  title =        "Flow-sensitive Type Qualifiers",
  x-abstract =   "We present a system for extending standard type
                 systems with flow-sensitive type qualifiers. Users
                 annotate their programs with type qualifiers, and
                 inference checks that the annotations are correct. In
                 our system only the type qualifiers are modeled
                 flow-sensitively---the underlying standard types are
                 unchanged, which allows us to obtain an efficient
                 constraint-based inference algorithm that integrates
                 flow-insensitive alias analysis, effect inference, and
                 ideas from linear type systems to support strong
                 updates. We demonstrate the usefulness of
                 flow-sensitive type qualifiers by finding a number of
                 new locking bugs in the Linux kernel.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/543552.512531",
  x-issn =       "0362-1340",
  x-url =        "http://dx.doi.org/10.1145/543552.512531",
  xpages =       "1--12",
  year =         "2002",
}

@InProceedings{Godefroid2005DART,
  author =       "Patrice Godefroid and Nils Klarlund and Koushik Sen",
  booktitle =    "Proceedings of the 2005 ACM SIGPLAN Conference on
                 Programming Language Design and Implementation",
  citeulike-article-id = "2343518",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1064978.1065036",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1064978.1065036",
  date-added =   "2014-11-13 20:32:16",
  month =        jun,
  priority =     "2",
  publisher =    "ACM",
  title =        "{DART}: Directed Automated Random Testing",
  x-abstract =   "We present a new tool, named {DART}, for automatically
                 testing software that combines three main techniques:
                 (1) automated extraction of the interface of a program
                 with its external environment using static source-code
                 parsing; (2) automatic generation of a test driver for
                 this interface that performs random testing to simulate
                 the most general environment the program can operate
                 in; and (3) dynamic analysis of how the program behaves
                 under random testing and automatic generation of new
                 test inputs to direct systematically the execution
                 along alternative program paths. Together, these three
                 techniques constitute Directed Automated Random
                 Testing, or {DART} for short. The main strength of
                 {DART} is thus that testing can be performed completely
                 automatically on any program that compiles -- there is
                 no need to write any test driver or harness code.
                 During testing, {DART} detects standard errors such as
                 program crashes, assertion violations, and
                 non-termination. Preliminary experiments to unit test
                 several examples of C programs are very encouraging.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1064978.1065036",
  x-issn =       "0362-1340",
  x-url =        "http://dx.doi.org/10.1145/1064978.1065036",
  xpages =       "213--223",
  year =         "2005",
}

@InProceedings{Cook1978Soundness,
  author =       "Stephen A. Cook",
  booktitle =    "SIAM Journal of Computing",
  citeulike-article-id = "13427842",
  citeulike-linkout-0 = "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.258.4890",
  date-added =   "2014-11-13 19:23:32",
  priority =     "2",
  title =        "Soundness and completeness of an axiom system for
                 program verification",
  x-abstract =   "K. R. Apt pointed out to me that Theorem 3
                 (completeness) is technically false, because of a
                 problem with initializing newly declared variables. For
                 example, the formula true {begin begin new x; x:= 1
                 end; begin new x; y: = x end end} y 1 is valid
                 according to the semantics given (because the second
                 declaration of x assigns the same register to x as the
                 first), but it is not provable in Perhaps the simplest
                 way to fix this is to require all newly declared
                 variables to be initialized to some distinguished value
                 0 e D. This would involve changing the first case (that
                 of variable declaration) in the definition of Comp (A,
                 s, 3, 7r) on p. 74, so that the computation proceeds
                 with a new state s\^{a}. Here s \^{a} is the
                 same as s except for s\^{a}(X,/x) 0. To make Y (
                 complete we would slightly modify Rule 1 (Rule of
                 variable declarations) of the system Y to read x 0 \&
                 P--Y {begin D*; A * end}O-y X",
  x-url =        "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.258.4890",
  year =         "1978",
}

@Article{Scott1993Typetheoretical,
  author =       "Dana S. Scott",
  citeulike-article-id = "5444731",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=170034",
  citeulike-linkout-1 = "http://dx.doi.org/10.1016/0304-3975(93)90095-b",
  date-added =   "2014-11-13 19:16:32",
  journal =      "Theoretical Computer Science",
  month =        dec,
  number =       "1-2",
  priority =     "2",
  publisher =    "Elsevier Science Publishers Ltd.",
  title =        "A type-theoretical alternative to {ISWIM}, {CUCH},
                 {OWHY}",
  volume =       "121",
  x-address =    "Essex, UK",
  x-doi =        "10.1016/0304-3975(93)90095-b",
  x-issn =       "03043975",
  x-url =        "http://dx.doi.org/10.1016/0304-3975(93)90095-b",
  xpages =       "411--440",
  year =         "1993",
}

@InProceedings{Sergey2013Monadic,
  author =       "Ilya Sergey and Dominique Devriese and Matthew Might
                 and Jan Midtgaard and David Darais and Dave Clarke and
                 Frank Piessens",
  booktitle =    "Proceedings of the 34th ACM SIGPLAN Conference on
                 Programming Language Design and Implementation",
  citeulike-article-id = "13136834",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2491979",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2499370.2491979",
  date-added =   "2014-11-13 17:27:50",
  month =        jun,
  priority =     "2",
  publisher =    "ACM",
  title =        "Monadic Abstract Interpreters",
  x-abstract =   "Recent developments in the systematic construction of
                 abstract interpreters hinted at the possibility of a
                 broad unification of concepts in static analysis. We
                 deliver that unification by showing
                 context-sensitivity, polyvariance, flow-sensitivity,
                 reachability-pruning, heap-cloning and
                 cardinality-bounding to be independent of any
                 particular semantics. Monads become the unifying agent
                 between these concepts and between semantics. For
                 instance, by plugging the same {"}context-insensitivity
                 monad{"} into a monadically-parameterized semantics for
                 Java or for the lambda calculus, it yields the expected
                 context-insensitive analysis. To achieve this
                 unification, we develop a systematic method for
                 transforming a concrete semantics into a
                 monadically-parameterized abstract machine. Changing
                 the monad changes the behavior of the machine. By
                 changing the monad, we recover a spectrum of
                 machines---from the original concrete semantics to a
                 monovariant, flow- and context-insensitive static
                 analysis with a singly-threaded heap and weak updates.
                 The monadic parameterization also suggests an
                 abstraction over the ubiquitous monotone fixed-point
                 computation found in static analysis. This abstraction
                 makes it straightforward to instrument an analysis with
                 high-level strategies for improving precision and
                 performance, such as abstract garbage collection and
                 widening. While the paper itself runs the development
                 for continuation-passing style, our generic
                 implementation replays it for direct-style
                 lambda-calculus and Featherweight Java to support
                 generality.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2499370.2491979",
  x-issn =       "0362-1340",
  x-url =        "http://dx.doi.org/10.1145/2499370.2491979",
  xpages =       "399--410",
  year =         "2013",
}

@InProceedings{Wadler1992Essence,
  author =       "Philip Wadler",
  booktitle =    "Proceedings of the 19th ACM SIGPLAN-SIGACT Symposium
                 on Principles of Programming Languages",
  citeulike-article-id = "1360",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=143169",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/143165.143169",
  date-added =   "2014-11-13 17:01:02",
  location =     "Albuquerque, New Mexico, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "The Essence of Functional Programming",
  x-abstract =   "This paper explores the use monads to structure
                 functional programs. No prior knowledge of monads or
                 category theory is required. Monads increase the ease
                 with which programs may be modified. They can mimic the
                 effect of impure features such as exceptions, state,
                 and continuations; and also provide effects not easily
                 achieved with such features. The types of a program
                 reflect which effects occur. The first section is an
                 extended example of the use of monads. A simple
                 interpreter is modified to support various extra
                 features: error messages, state, output, and
                 non-deterministic choice. The second section describes
                 the relation between monads and the
                 continuation-passing style. The third section sketches
                 how monads are used in a compiler for Haskell that is
                 written in Haskell.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/143165.143169",
  x-isbn =       "0-89791-453-8",
  x-series =     "POPL '92",
  x-url =        "http://dx.doi.org/10.1145/143165.143169",
  xpages =       "1--14",
  year =         "1992",
}

@InProceedings{Liang1995Monad,
  author =       "Sheng Liang and Paul Hudak and Mark Jones",
  booktitle =    "Proceedings of the 22nd ACM SIGPLAN-SIGACT Symposium
                 on Principles of Programming Languages",
  citeulike-article-id = "82468",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=199528",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/199448.199528",
  date-added =   "2014-11-13 06:02:35",
  location =     "San Francisco, California, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "Monad Transformers and Modular Interpreters",
  x-abstract =   "We show how a set of building blocks can be used to
                 construct programming language interpreters, and
                 present implementations of such building blocks capable
                 of supporting many commonly known features, including
                 simple expressions, three different function call
                 mechanisms (call-by-name, call-by-value and lazy
                 evaluation), references and assignment, nondeterminism,
                 first-class continuations, and program {tracing.The}
                 underlying mechanism of our system is monad
                 transformers, a simple form of abstraction for
                 introducing a wide range of computational behaviors,
                 such as state, {I/O}, continuations, and
                 {exceptions.Our} work is significant in the following
                 respects. First, we have succeeded in designing a fully
                 modular interpreter based on monad transformers that
                 incudes features missing from Steele's, Espinosa's, and
                 Wadler's earlier efforts. Second, we have found new
                 ways to lift monad operations through monad
                 transformers, in particular difficult cases not
                 achieved in Moggi's original work. Third, we have
                 demonstrated that interactions between features are
                 reflected in liftings and that semantics can be changed
                 by reordering monad transformers. Finally, we have
                 implemented our interpreter in Gofer, whose constructor
                 classes provide just the added power over Haskell's
                 type classes to allow precise and convenient expression
                 of our ideas. This implementation includes a method for
                 constructing extensible unions and a form of subtyping
                 that is interesting in its own right.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/199448.199528",
  x-isbn =       "0-89791-692-1",
  x-series =     "POPL '95",
  x-url =        "http://dx.doi.org/10.1145/199448.199528",
  xpages =       "333--343",
  year =         "1995",
}

@InProceedings{Kastrinis2013Hybrid,
  author =       "George Kastrinis and Yannis Smaragdakis",
  booktitle =    "Proceedings of the 34th ACM SIGPLAN Conference on
                 Programming Language Design and Implementation",
  citeulike-article-id = "12437335",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2462191",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2462156.2462191",
  date-added =   "2014-11-13 05:18:07",
  location =     "Seattle, Washington, USA",
  month =        jun,
  priority =     "2",
  publisher =    "ACM",
  title =        "Hybrid Context-sensitivity for Points-to Analysis",
  x-abstract =   "Context-sensitive points-to analysis is valuable for
                 achieving high precision with good performance. The
                 standard flavors of context-sensitivity are
                 call-site-sensitivity ({kCFA}) and object-sensitivity.
                 Combining both flavors of context-sensitivity increases
                 precision but at an infeasibly high cost. We show that
                 a selective combination of call-site- and
                 object-sensitivity for Java points-to analysis is
                 highly profitable. Namely, by keeping a combined
                 context only when analyzing selected language features,
                 we can closely approximate the precision of an analysis
                 that keeps both contexts at all times. In terms of
                 speed, the selective combination of both kinds of
                 context not only vastly outperforms non-selective
                 combinations but is also faster than a mere
                 object-sensitive analysis. This result holds for a
                 large array of analyses (e.g., 1-object-sensitive,
                 2-object-sensitive with a context-sensitive heap,
                 type-sensitive) establishing a new set of
                 performance/precision sweet spots.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2462156.2462191",
  x-isbn =       "978-1-4503-2014-6",
  x-issn =       "0362-1340",
  x-series =     "PLDI '13",
  x-url =        "http://dx.doi.org/10.1145/2462156.2462191",
  xpages =       "423--434",
  year =         "2013",
}

@PhdThesis{Andersen1994Program,
  author =       "Lars O. Andersen",
  citeulike-article-id = "4924529",
  citeulike-linkout-0 = "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.109.6502",
  date-added =   "2014-11-13 05:00:51",
  priority =     "2",
  school =       "DIKU, University of Copenhagen",
  title =        "Program Analysis and Specialization for the {C}
                 Programming Language",
  x-abstract =   "Software engineers are faced with a dilemma. They want
                 to write general and wellstructured programs that are
                 flexible and easy to maintain. On the other hand,
                 generality has a price: efficiency. A specialized
                 program solving a particular problem is often
                 significantly faster than a general program. However,
                 the development of specialized software is
                 time-consuming, and is likely to exceed the production
                 of today\^{a}s programmers. New techniques are required
                 to solve this so-called software crisis. Partial
                 evaluation is a program specialization technique that
                 reconciles the benefits of generality with efficiency.
                 This thesis presents an automatic partial evaluator for
                 the Ansi C programming language. The content of this
                 thesis is analysis and transformation of C programs. We
                 develop several analyses that support the
                 transformation of a program into its generating
                 extension. A generating extension is a program that
                 produces specialized programs when executed on parts of
                 the input. The thesis contains the following main
                 results.",
  x-url =        "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.109.6502",
  year =         "1994",
}

@InProceedings{Chase1990Analysis,
  author =       "David R. Chase and Mark Wegman and F. Kenneth Zadeck",
  booktitle =    "Proceedings of the ACM SIGPLAN 1990 Conference on
                 Programming Language Design and Implementation",
  citeulike-article-id = "741317",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=93585",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/93542.93585",
  date-added =   "2014-11-13 03:58:43",
  location =     "White Plains, New York, United States",
  month =        jun,
  priority =     "2",
  publisher =    "ACM",
  title =        "Analysis of Pointers and Structures",
  x-abstract =   "An abstract is not available.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/93542.93585",
  x-isbn =       "0-89791-364-7",
  x-issn =       "0362-1340",
  x-series =     "PLDI '90",
  x-url =        "http://dx.doi.org/10.1145/93542.93585",
  xpages =       "296--310",
  year =         "1990",
}

@Article{Midtgaard2012Controlflow,
  author =       "Jan Midtgaard",
  citeulike-article-id = "12591221",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2187671.2187672",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2187671.2187672",
  date-added =   "2014-11-13 03:09:34",
  journal =      "ACM Comput. Surv.",
  month =        jun,
  number =       "3",
  priority =     "2",
  publisher =    "ACM",
  title =        "Control-flow Analysis of Functional Programs",
  volume =       "44",
  x-abstract =   "We present a survey of control-flow analysis of
                 functional programs, which has been the subject of
                 extensive investigation throughout the past 30 years.
                 Analyses of the control flow of functional programs
                 have been formulated in multiple settings and have led
                 to many different approximations, starting with the
                 seminal works of Jones, Shivers, and Sestoft. In this
                 article, we survey control-flow analysis of functional
                 programs by structuring the multitude of formulations
                 and approximations and comparing them.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2187671.2187672",
  x-issn =       "0360-0300",
  x-url =        "http://dx.doi.org/10.1145/2187671.2187672",
  year =         "2012",
}

@InProceedings{Smaragdakis2011Pick,
  author =       "Yannis Smaragdakis and Martin Bravenboer and Ondrej
                 Lhot\'{a}k",
  booktitle =    "Proceedings of the 38th Annual ACM SIGPLAN-SIGACT
                 Symposium on Principles of Programming Languages",
  citeulike-article-id = "9533212",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1926390",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1925844.1926390",
  date-added =   "2014-11-12 23:27:22",
  location =     "Austin, Texas, USA",
  month =        jan,
  priority =     "2",
  publisher =    "ACM",
  title =        "Pick Your Contexts Well: Understanding
                 Object-sensitivity",
  x-abstract =   "Object-sensitivity has emerged as an excellent context
                 abstraction for points-to analysis in object-oriented
                 languages. Despite its practical success, however,
                 object-sensitivity is poorly understood. For instance,
                 for a context depth of 2 or higher, past scalable
                 implementations deviate significantly from the original
                 definition of an object-sensitive analysis. The reason
                 is that the analysis has many degrees of freedom,
                 relating to which context elements are picked at every
                 method call and object creation. We offer a clean model
                 for the analysis design space, and discuss a formal and
                 informal understanding of object-sensitivity and of how
                 to create good object-sensitive analyses. The results
                 are surprising in their extent. We find that past
                 implementations have made a sub-optimal choice of
                 contexts, to the severe detriment of precision and
                 performance. We define a {"}full-object-sensitive{"}
                 analysis that results in significantly higher
                 precision, and often performance, for the exact same
                 context depth. We also introduce {"}type-sensitivity{"}
                 as an explicit approximation of object-sensitivity that
                 preserves high context quality at substantially reduced
                 cost. A type-sensitive points-to analysis makes an
                 unconventional use of types as context: the context
                 types are not dynamic types of objects involved in the
                 analysis, but instead upper bounds on the dynamic types
                 of their allocator objects. Our results expose the
                 influence of context choice on the quality of points-to
                 analysis and demonstrate type-sensitivity to be an idea
                 with major impact: It decisively advances the
                 state-of-the-art with a spectrum of analyses that
                 simultaneously enjoy speed (several times faster than
                 an analogous object-sensitive analysis), scalability
                 (comparable to analyses with much less
                 context-sensitivity), and precision (comparable to the
                 best object-sensitive analysis with the same context
                 depth).",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1925844.1926390",
  x-isbn =       "978-1-4503-0490-0",
  x-issn =       "0362-1340",
  x-series =     "POPL '11",
  x-url =        "http://dx.doi.org/10.1145/1925844.1926390",
  xpages =       "17--30",
  year =         "2011",
}

@Article{Milanova2005Parameterized,
  author =       "Ana Milanova and Atanas Rountev and Barbara G. Ryder",
  citeulike-article-id = "3429127",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1044834.1044835",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1044834.1044835",
  date-added =   "2014-11-12 22:59:11",
  journal =      "ACM Trans. Softw. Eng. Methodol.",
  month =        jan,
  number =       "1",
  priority =     "2",
  publisher =    "ACM",
  title =        "Parameterized Object Sensitivity for Points-to
                 Analysis for {J}ava",
  volume =       "14",
  x-abstract =   "The goal of points-to analysis for Java is to
                 determine the set of objects pointed to by a reference
                 variable or a reference object field. We present object
                 sensitivity, a new form of context sensitivity for
                 flow-insensitive points-to analysis for Java. The key
                 idea of our approach is to analyze a method separately
                 for each of the object names that represent run-time
                 objects on which this method may be invoked. To ensure
                 flexibility and practicality, we propose a
                 parameterization framework that allows analysis
                 designers to control the tradeoffs between cost and
                 precision in the object-sensitive
                 {analysis.Side}-effect analysis determines the memory
                 locations that may be modified by the execution of a
                 program statement. Def-use analysis identifies pairs of
                 statements that set the value of a memory location and
                 subsequently use that value. The information computed
                 by such analyses has a wide variety of uses in
                 compilers and software tools. This work proposes new
                 versions of these analyses that are based on
                 object-sensitive points-to {analysis.We} have
                 implemented two instantiations of our parameterized
                 object-sensitive points-to analysis. On a set of 23
                 Java programs, our experiments show that these analyses
                 have comparable cost to a context-insensitive points-to
                 analysis for Java which is based on Andersen's analysis
                 for C. Our results also show that object sensitivity
                 significantly improves the precision of side-effect
                 analysis and call graph construction, compared to (1)
                 context-insensitive analysis, and (2) context-sensitive
                 points-to analysis that models context using the
                 invoking call site. These experiments demonstrate that
                 object-sensitive analyses can achieve substantial
                 precision improvement, while at the same time remaining
                 efficient and practical.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1044834.1044835",
  x-issn =       "1049-331X",
  x-url =        "http://dx.doi.org/10.1145/1044834.1044835",
  xpages =       "1--41",
  year =         "2005",
}

@Article{Xie2007Saturn,
  author =       "Yichen Xie and Alex Aiken",
  citeulike-article-id = "2403573",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1232420.1232423",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1232420.1232423",
  date-added =   "2014-10-28 06:53:33",
  journal =      "ACM Trans. Program. Lang. Syst.",
  month =        may,
  number =       "3",
  priority =     "2",
  publisher =    "ACM",
  title =        "Saturn: {A} Scalable Framework for Error Detection
                 Using Boolean Satisfiability",
  volume =       "29",
  x-abstract =   "This article presents Saturn, a general framework for
                 building precise and scalable static error detection
                 systems. Saturn exploits recent advances in Boolean
                 satisfiability ({SAT}) solvers and is path sensitive,
                 precise down to the bit level, and models pointers and
                 heap data. Our approach is also highly scalable, which
                 we achieve using two techniques. First, for each
                 program function, several optimizations compress the
                 size of the Boolean formulas that model the control
                 flow and data flow and the heap locations accessed by a
                 function. Second, summaries in the spirit of type
                 signatures are computed for each function, allowing
                 interprocedural analysis without a dramatic increase in
                 the size of the Boolean constraints to be solved. We
                 have experimentally validated our approach by
                 conducting two case studies involving a Linux lock
                 checker and a memory leak checker. Results from the
                 experiments show that our system scales well,
                 parallelizes well, and finds more errors with fewer
                 false positives than previous static error detection
                 systems.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1232420.1232423",
  x-issn =       "0164-0925",
  x-url =        "http://dx.doi.org/10.1145/1232420.1232423",
  xpages =       "16+",
  year =         "2007",
}

@InProceedings{Aiken2007Overview,
  author =       "Alex Aiken and Suhabe Bugrara and Isil Dillig and
                 Thomas Dillig and Brian Hackett and Peter Hawkins",
  booktitle =    "Proceedings of the 7th ACM SIGPLAN-SIGSOFT Workshop on
                 Program Analysis for Software Tools and Engineering",
  citeulike-article-id = "13410792",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1251543",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1251535.1251543",
  date-added =   "2014-10-28 06:52:48",
  location =     "San Diego, California, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "An Overview of the Saturn Project",
  x-abstract =   "We present an overview of the Saturn program analysis
                 system, including a rationale for three major design
                 decisions: the use of function-at-a-time, or
                 summary-based, analysis, the use of constraints, and
                 the use of a logic programming language to express
                 program analysis algorithms. We argue that the
                 combination of summaries and constraints allows Saturn
                 to achieve both great scalability and great precision,
                 while the use of a logic programming language with
                 constraints allows for succinct, high-level expression
                 of program analyses.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1251535.1251543",
  x-isbn =       "978-1-59593-595-3",
  x-series =     "PASTE '07",
  x-url =        "http://dx.doi.org/10.1145/1251535.1251543",
  xpages =       "43--48",
  year =         "2007",
}

@Article{Dillig2008Sound,
  author =       "Isil Dillig and Thomas Dillig and Alex Aiken",
  citeulike-article-id = "3383611",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1379022.1375615",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1379022.1375615",
  date-added =   "2014-10-28 06:52:07",
  journal =      "SIGPLAN Not.",
  month =        jun,
  number =       "6",
  priority =     "2",
  publisher =    "ACM",
  title =        "Sound, Complete and Scalable Path-sensitive Analysis",
  volume =       "43",
  x-abstract =   "We present a new, precise technique for fully path-
                 and context-sensitive program analysis. Our technique
                 exploits two observations: First, using quantified,
                 recursive formulas, path- and context-sensitive
                 conditions for many program properties can be expressed
                 exactly. To compute a closed form solution to such
                 recursive constraints, we differentiate between
                 observable and unobservable variables, the latter of
                 which are existentially quantified in our approach.
                 Using the insight that unobservable variables can be
                 eliminated outside a certain scope, our technique
                 computes satisfiability- and validity-preserving
                 closed-form solutions to the original recursive
                 constraints. We prove the solution is as precise as the
                 original system for answering may and must queries as
                 well as being small in practice, allowing our technique
                 to scale to the entire Linux kernel, a program with
                 over 6 million lines of code.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1379022.1375615",
  x-issn =       "0362-1340",
  x-url =        "http://dx.doi.org/10.1145/1379022.1375615",
  xpages =       "270--280",
  year =         "2008",
}

@InProceedings{Reisner2010Using,
  author =       "Elnatan Reisner and Charles Song and Kin K. Ma and
                 Jeffrey S. Foster and Adam Porter",
  booktitle =    "Proceedings of the 32Nd ACM/IEEE International
                 Conference on Software Engineering - Volume 1",
  citeulike-article-id = "9913859",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1806864",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1806799.1806864",
  date-added =   "2014-10-23 04:41:52",
  location =     "Cape Town, South Africa",
  priority =     "2",
  publisher =    "ACM",
  title =        "Using Symbolic Evaluation to Understand Behavior in
                 Configurable Software Systems",
  x-abstract =   "Many modern software systems are designed to be highly
                 configurable, which increases flexibility but can make
                 programs hard to test, analyze, and understand. We
                 present an initial empirical study of how configuration
                 options affect program behavior. We conjecture that, at
                 certain levels of abstraction, configuration spaces are
                 far smaller than the worst case, in which every
                 configuration is distinct. We evaluated our conjecture
                 by studying three configurable software systems:
                 vsftpd, {ngIRCd}, and grep. We used symbolic evaluation
                 to discover how the settings of run-time configuration
                 options affect line, basic block, edge, and condition
                 coverage for our subjects under a given test suite. Our
                 results strongly suggest that for these subject
                 programs, test suites, and configuration options, when
                 abstracted in terms of the four coverage criteria
                 above, configuration spaces are in fact much smaller
                 than combinatorics would suggest and are effectively
                 the composition of many small, self-contained groupings
                 of options.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1806799.1806864",
  x-isbn =       "978-1-60558-719-6",
  x-series =     "ICSE '10",
  x-url =        "http://dx.doi.org/10.1145/1806799.1806864",
  xpages =       "445--454",
  year =         "2010",
}

@InProceedings{Ma2011Directed,
  author =       "Kin K. Ma and Khoo Y. Phang and Jeffrey S. Foster and
                 Michael Hicks",
  booktitle =    "Proceedings of the 18th International Conference on
                 Static Analysis",
  citeulike-article-id = "13405703",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2041563",
  date-added =   "2014-10-23 04:40:18",
  location =     "Venice, Italy",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "Directed Symbolic Execution",
  x-abstract =   "In this paper, we study the problem of automatically
                 finding program executions that reach a particular
                 target line. This problem arises in many debugging
                 scenarios; for example, a developer may want to confirm
                 that a bug reported by a static analysis tool on a
                 particular line is a true positive. We propose two new
                 directed symbolic execution strategies that aim to
                 solve this problem: shortest-distance symbolic
                 execution ({SDSE}) uses a distance metric in an
                 interprocedural control flow graph to guide symbolic
                 execution toward a particular target; and
                 call-chain-backward symbolic execution ({CCBSE})
                 iteratively runs forward symbolic execution, starting
                 in the function containing the target line, and then
                 jumping backward up the call chain until it finds a
                 feasible path from the start of the program. We also
                 propose a hybrid strategy, {Mix-CCBSE}, which
                 alternates {CCBSE} with another (forward) search
                 strategy. We compare these three with several existing
                 strategies from the literature on a suite of six {GNU}
                 Coreutils programs. We find that {SDSE} performs
                 extremely well in many cases but may fail badly.
                 {CCBSE} also performs quite well, but imposes
                 additional overhead that sometimes makes it slower than
                 {SDSE}. Considering all our benchmarks together,
                 {Mix-CCBSE} performed best on average, combining to
                 good effect the features of its constituent
                 components.",
  x-address =    "Berlin, Heidelberg",
  x-isbn =       "978-3-642-23701-0",
  x-series =     "SAS'11",
  x-url =        "http://portal.acm.org/citation.cfm?id=2041563",
  xpages =       "95--111",
  year =         "2011",
}

@InCollection{Pasareanu2004Verification,
  author =       "CorinaS P\u{a}s\u{a}reanu and Willem Visser",
  booktitle =    "Model Checking Software",
  citeulike-article-id = "13405700",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-540-24732-6\_13",
  citeulike-linkout-1 = "http://link.springer.com/chapter/10.1007/978-3-540-24732-6\_13",
  date-added =   "2014-10-23 04:33:29",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "Verification of Java Programs Using Symbolic Execution
                 and Invariant Generation",
  volume =       "2989",
  x-abstract =   "Software verification is recognized as an important
                 and difficult problem. We present a novel framework,
                 based on symbolic execution, for the automated
                 verification of software. The framework uses
                 annotations in the form of method specifications and
                 loop invariants. We present a novel iterative technique
                 that uses invariant strengthening and approximation for
                 discovering these loop invariants automatically. The
                 technique handles different types of data (e.g. boolean
                 and numeric constraints, dynamically allocated
                 structures and arrays) and it allows for checking
                 universally quantified formulas. Our framework is built
                 on top of the Java {PathFinder} model checking toolset
                 and it was used for the verification of several
                 non-trivial Java programs.",
  x-doi =        "10.1007/978-3-540-24732-6\_13",
  x-editor =     "Graf, Susanne and Mounier, Laurent",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-540-24732-6\_13",
  xpages =       "164--181",
  year =         "2004",
}

@Article{Visser2004Test,
  author =       "Willem Visser and Corina S. P\v{a}s\v{a}reanu and
                 Sarfraz Khurshid",
  citeulike-article-id = "80857",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1013886.1007526",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1013886.1007526",
  date-added =   "2014-10-23 04:32:57",
  journal =      "SIGSOFT Softw. Eng. Notes",
  month =        jul,
  number =       "4",
  priority =     "2",
  publisher =    "ACM",
  title =        "Test Input Generation with Java {PathFinder}",
  volume =       "29",
  x-abstract =   "We show how model checking and symbolic execution can
                 be used to generate test inputs to achieve structural
                 coverage of code that manipulates complex data
                 structures. We focus on obtaining branch-coverage
                 during unit testing of some of the core methods of the
                 red-black tree implementation in the Java {TreeMap}
                 library, using the Java {PathFinder} model checker.
                 Three different test generation techniques will be
                 introduced and compared, namely, straight model
                 checking of the code, model checking used in a
                 black-box fashion to generate all inputs up to a fixed
                 size, and lastly, model checking used during white-box
                 test input generation. The main contribution of this
                 work is to show how efficient white-box test input
                 generation can be done for code manipulating complex
                 data, taking into account complex method
                 preconditions.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1013886.1007526",
  x-isbn =       "1581138202",
  x-issn =       "0163-5948",
  x-url =        "http://dx.doi.org/10.1145/1013886.1007526",
  xpages =       "97--107",
  year =         "2004",
}

@InProceedings{Song2008BitBlaze,
  author =       "Dawn Song and David Brumley and Heng Yin and Juan
                 Caballero and Ivan Jager and Min G. Kang and Zhenkai
                 Liang and James Newsome and Pongsin Poosankam and
                 Prateek Saxena",
  booktitle =    "Proceedings of the 4th International Conference on
                 Information Systems Security",
  chapter =      "1",
  citeulike-article-id = "7356749",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1496257",
  citeulike-linkout-1 = "http://dx.doi.org/10.1007/978-3-540-89862-7\_1",
  citeulike-linkout-2 = "http://www.springerlink.com/content/j345p1214231552q",
  date-added =   "2014-10-23 04:27:41",
  location =     "Hyderabad, India",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "{BitBlaze}: {A} New Approach to Computer Security via
                 Binary Analysis",
  volume =       "5352",
  x-abstract =   "In this paper, we give an overview of the {BitBlaze}
                 project, a new approach to computer security via binary
                 analysis. In particular, {BitBlaze} focuses on building
                 a unified binary analysis platform and using it to
                 provide novel solutions to a broad spectrum of
                 different security problems. The binary analysis
                 platform is designed to enable accurate analysis,
                 provide an extensible architecture, and combines static
                 and dynamic analysis as well as program verification
                 techniques to satisfy the common needs of security
                 applications. By extracting security-related properties
                 from binary programs directly, {BitBlaze} enables a
                 principled, root-cause based approach to computer
                 security, offering novel and effective solutions, as
                 demonstrated with over a dozen different security
                 applications.",
  x-address =    "Berlin, Heidelberg",
  x-doi =        "10.1007/978-3-540-89862-7\_1",
  x-isbn =       "978-3-540-89861-0",
  x-issn =       "0302-9743",
  x-series =     "ICISS '08",
  x-url =        "http://dx.doi.org/10.1007/978-3-540-89862-7\_1",
  xpages =       "1--25",
  year =         "2008",
}

@InProceedings{Hayden2012Specifying,
  author =       "Christopher M. Hayden and Stephen Magill and Michael
                 Hicks and Nate Foster and Jeffrey S. Foster",
  booktitle =    "Proceedings of the 4th International Conference on
                 Verified Software: Theories, Tools, Experiments",
  citeulike-article-id = "13405458",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2189336",
  citeulike-linkout-1 = "http://dx.doi.org/10.1007/978-3-642-27705-4\_22",
  date-added =   "2014-10-22 21:31:01",
  location =     "Philadelphia, PA",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "Specifying and Verifying the Correctness of Dynamic
                 Software Updates",
  x-abstract =   "Dynamic software updating ({DSU}) systems allow
                 running programs to be patched on-the-fly to add
                 features or fix bugs. While dynamic updates can be
                 tricky to write, techniques for establishing their
                 correctness have received little attention. In this
                 paper, we present the first methodology for
                 automatically verifying the correctness of dynamic
                 updates. Programmers express the desired properties of
                 an updated execution using <em>client-oriented
                 specifications</em> ({CO}-specs), which can describe a
                 wide range of client-visible behaviors. We verify
                 {CO}-specs automatically by using off-the-shelf tools
                 to analyze a <em>merged</em> program, which is a
                 combination of the old and new versions of a program.
                 We formalize the merging transformation and prove it
                 correct. We have implemented a program merger for C,
                 and applied it to updates for the Redis key-value store
                 and several synthetic programs. Using Thor, a
                 verification tool, we could verify many of the
                 synthetic programs; using Otter, a symbolic executor,
                 we could analyze every program, often in less than a
                 minute. Both tools were able to detect faulty patches
                 and incurred only a factor-of-four slowdown, on
                 average, compared to single version programs.",
  x-address =    "Berlin, Heidelberg",
  x-doi =        "10.1007/978-3-642-27705-4\_22",
  x-isbn =       "978-3-642-27704-7",
  x-series =     "VSTTE'12",
  x-url =        "http://dx.doi.org/10.1007/978-3-642-27705-4\_22",
  xpages =       "278--293",
  year =         "2012",
}

@Article{Harman1998Program,
  author =       "Mark Harman and Keith B. Gallagher",
  citeulike-article-id = "13405423",
  citeulike-linkout-0 = "http://dx.doi.org/10.1016/s0950-5849(98)00084-6",
  date-added =   "2014-10-22 20:25:37",
  journal =      "Information and Software Technology",
  month =        dec,
  number =       "11-12",
  priority =     "2",
  title =        "Program slicing",
  volume =       "40",
  x-doi =        "10.1016/s0950-5849(98)00084-6",
  x-issn =       "09505849",
  x-url =        "http://dx.doi.org/10.1016/s0950-5849(98)00084-6",
  xpages =       "577--581",
  year =         "1998",
}

@InBook{Binkley2004Survey,
  author =       "David Binkley and Mark Harman",
  citeulike-article-id = "13405421",
  citeulike-linkout-0 = "http://dx.doi.org/10.1016/s0065-2458(03)62003-6",
  date-added =   "2014-10-22 20:21:45",
  priority =     "2",
  publisher =    "Elsevier",
  title =        "A Survey of Empirical Results on Program Slicing",
  volume =       "62",
  x-doi =        "10.1016/s0065-2458(03)62003-6",
  x-isbn =       "9780120121625",
  x-url =        "http://dx.doi.org/10.1016/s0065-2458(03)62003-6",
  xpages =       "105--178",
  year =         "2004",
}

@Article{Horwitz1990Interprocedural,
  author =       "Susan Horwitz and Thomas Reps and David Binkley",
  citeulike-article-id = "506076",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=77608",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/77606.77608",
  date-added =   "2014-10-22 20:19:06",
  journal =      "ACM Trans. Program. Lang. Syst.",
  month =        jan,
  number =       "1",
  priority =     "2",
  publisher =    "ACM",
  title =        "Interprocedural Slicing Using Dependence Graphs",
  volume =       "12",
  x-abstract =   "The notion of a program slice, originally introduced
                 by Mark Weiser, is useful in program debugging,
                 automatic parallelization, and program integration. A
                 slice of a program is taken with respect to a program
                 point p and a variable x; the slice consists of all
                 statements of the program that might affect the value
                 of x at point p. This paper concerns the problem of
                 interprocedural slicing—generating a slice of an
                 entire program, where the slice crosses the boundaries
                 of procedure calls. To solve this problem, we introduce
                 a new kind of graph to represent programs, called a
                 system dependence graph, which extends previous
                 dependence representations to incorporate collections
                 of procedures (with procedure calls) rather than just
                 monolithic programs. Our main result is an algorithm
                 for interprocedural slicing that uses the new
                 representation. (It should be noted that our work
                 concerns a somewhat restricted kind of slice: rather
                 than permitting a program to b e sliced with respect to
                 program point p and an arbitrary variable, a slice must
                 be taken with respect to a variable that is defined or
                 used at {p.)The} chief difficulty in interprocedural
                 slicing is correctly accounting for the calling context
                 of a called procedure. To handle this problem, system
                 dependence graphs include some data dependence edges
                 that represent transitive dependences due to the
                 effects of procedure calls, in addition to the
                 conventional direct-dependence edges. These edges are
                 constructed with the aid of an auxiliary structure that
                 represents calling and parameter-linkage relationships.
                 This structure takes the form of an attribute grammar.
                 The step of computing the required
                 transitive-dependence edges is reduced to the
                 construction of the subordinate characteristic graphs
                 for the grammar's nonterminals.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/77606.77608",
  x-issn =       "0164-0925",
  x-url =        "http://dx.doi.org/10.1145/77606.77608",
  xpages =       "26--60",
  year =         "1990",
}

@Article{Weiser1984Program,
  author =       "Mark Weiser",
  citeulike-article-id = "13405258",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2283037.2283165",
  citeulike-linkout-1 = "http://dx.doi.org/10.1109/tse.1984.5010248",
  date-added =   "2014-10-22 20:18:28",
  journal =      "IEEE Trans. Softw. Eng.",
  month =        jul,
  number =       "4",
  priority =     "2",
  publisher =    "IEEE Press",
  title =        "Program Slicing",
  volume =       "10",
  x-abstract =   "Program slicing is a method for automatically
                 decomposing programs by analyzing their data flow and
                 control flow. Starting from a subset of a program's
                 behavior, slicing reduces that program to a minimal
                 form which still produces that behavior. The reduced
                 program, called a ``slice,'' is an independent program
                 guaranteed to represent faithfully the original program
                 within the domain of the specified subset of behavior.
                 Some properties of slices are presented. In particular,
                 finding statement-minimal slices is in general
                 unsolvable, but using data flow analysis is sufficient
                 to find approximate slices. Potential applications
                 include automatic slicing tools for debuggng and
                 parallel processing of slices.",
  x-address =    "Piscataway, NJ, USA",
  x-doi =        "10.1109/tse.1984.5010248",
  x-issn =       "0098-5589",
  x-url =        "http://dx.doi.org/10.1109/tse.1984.5010248",
  xpages =       "352--357",
  year =         "1984",
}

@InProceedings{Weiser1981Program,
  author =       "Mark Weiser",
  booktitle =    "Proceedings of the 5th International Conference on
                 Software Engineering",
  citeulike-article-id = "522778",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=802557",
  date-added =   "2014-10-22 20:15:42",
  location =     "San Diego, California, USA",
  priority =     "2",
  publisher =    "IEEE Press",
  title =        "Program Slicing",
  x-abstract =   "Program slicing is a method used by experienced
                 computer programmers for abstracting from programs.
                 Starting from a subset of a program's behavior, slicing
                 reduces that program to a minimal form which still
                 produces that behavior. The reduced program, called a
                 ” slice”, is an independent program guaranteed to
                 faithfully represent the original program within the
                 domain of the specified subset of {behavior.Finding} a
                 slice is in general unsolvable. A dataflow algorithm is
                 presented for approximating slices when the behavior
                 subset is specified as the values of a set of variables
                 at a statement. Experimental evidence is presented that
                 these slices are used by programmers during debugging.
                 Experience with two automatic slicing tools is
                 summarized. New measures of program complexity are
                 suggested based on the organization of a program's
                 slices.",
  x-address =    "Piscataway, NJ, USA",
  x-isbn =       "0-89791-146-6",
  x-series =     "ICSE '81",
  x-url =        "http://portal.acm.org/citation.cfm?id=802557",
  xpages =       "439--449",
  year =         "1981",
}

@InProceedings{Cook2013Reasoning,
  author =       "Byron Cook and Eric Koskinen",
  booktitle =    "Proceedings of the 34th ACM SIGPLAN Conference on
                 Programming Language Design and Implementation",
  citeulike-article-id = "13403975",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2491969",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2491956.2491969",
  date-added =   "2014-10-22 13:36:01",
  location =     "Seattle, Washington, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "Reasoning About Nondeterminism in Programs",
  x-abstract =   "Branching-time temporal logics (e.g. {CTL}, {CTL}*,
                 modal mu-calculus) allow us to ask sophisticated
                 questions about the nondeterminism that appears in
                 systems. Applications of this type of reasoning include
                 planning, games, security analysis, disproving,
                 precondition synthesis, environment synthesis, etc.
                 Unfortunately, existing automatic branching-time
                 verification tools have limitations that have
                 traditionally restricted their applicability (e.g.
                 push-down systems only, universal path quantifiers
                 only, etc). In this paper we introduce an automation
                 strategy that lifts many of these previous
                 restrictions. Our method works reliably for properties
                 with non-trivial mixtures of universal and existential
                 modal operators. Furthermore, our approach is designed
                 to support (possibly infinite-state) programs. The
                 basis of our approach is the observation that
                 existential reasoning can be reduced to universal
                 reasoning if the system's state-space is appropriately
                 restricted. This restriction on the state-space must
                 meet a constraint derived from recent work on proving
                 non-termination. The observation leads to a new route
                 for implementation based on existing tools. To
                 demonstrate the practical viability of our approach, we
                 report on the results applying our preliminary
                 implementation to a set of benchmarks drawn from the
                 Windows operating system, the {PostgreSQL} database
                 server, {SoftUpdates} patching system, as well as other
                 hand-crafted examples.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2491956.2491969",
  x-isbn =       "978-1-4503-2014-6",
  x-series =     "PLDI '13",
  x-url =        "http://dx.doi.org/10.1145/2491956.2491969",
  xpages =       "219--230",
  year =         "2013",
}

@InProceedings{Nguyen2014Soft,
  author =       "Ph\'{u}c C. Nguyên and Sam Tobin-Hochstadt and David
                 Van{ }Horn",
  booktitle =    "Proceedings of the 19th ACM SIGPLAN International
                 Conference on Functional Programming",
  citeulike-article-id = "13403599",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2628156",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2628136.2628156",
  date-added =   "2014-10-22 00:16:50",
  location =     "Gothenburg, Sweden",
  priority =     "2",
  publisher =    "ACM",
  title =        "Soft Contract Verification",
  x-abstract =   "Behavioral software contracts are a widely used
                 mechanism for governing the flow of values between
                 components. However, run-time monitoring and
                 enforcement of contracts imposes significant overhead
                 and delays discovery of faulty components to run-time.
                 To overcome these issues, we present soft contract
                 verification, which aims to statically prove either
                 complete or partial contract correctness of components,
                 written in an untyped, higher-order language with
                 first-class contracts. Our approach uses higher-order
                 symbolic execution, leveraging contracts as a source of
                 symbolic values including unknown behavioral values,
                 and employs an updatable heap of contract invariants to
                 reason about flow-sensitive facts. We prove the
                 symbolic execution soundly approximates the dynamic
                 semantics and that verified programs can't be blamed.
                 The approach is able to analyze first-class contracts,
                 recursive data structures, unknown functions, and
                 control-flow-sensitive refinements of values, which are
                 all idiomatic in dynamic languages. It makes effective
                 use of an off-the-shelf solver to decide problems
                 without heavy encodings. The approach is competitive
                 with a wide range of existing tools - including type
                 systems, flow analyzers, and model checkers - on their
                 own benchmarks.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2628136.2628156",
  x-isbn =       "978-1-4503-2873-9",
  x-series =     "ICFP '14",
  x-url =        "http://dx.doi.org/10.1145/2628136.2628156",
  xpages =       "139--152",
  year =         "2014",
}

@InCollection{Hoffmann2014TypeBased,
  author =       "Jan Hoffmann and Zhong Shao",
  booktitle =    "Functional and Logic Programming",
  citeulike-article-id = "13388845",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-319-07151-0\_10",
  citeulike-linkout-1 = "http://link.springer.com/chapter/10.1007/978-3-319-07151-0\_10",
  date-added =   "2014-10-11 18:59:51",
  priority =     "2",
  publisher =    "Springer International Publishing",
  title =        "{Type-Based} Amortized Resource Analysis with Integers
                 and Arrays",
  volume =       "8475",
  x-abstract =   "Proving bounds on the resource consumption of a
                 program by statically analyzing its source code is an
                 important and well-studied problem. Automatic
                 approaches for numeric programs with side effects
                 usually apply abstract interpretation–based invariant
                 generation to derive bounds on loops and recursion
                 depths of function calls. This paper presents an
                 alternative approach to resource-bound analysis for
                 numeric, heap-manipulating programs that uses
                 type-based amortized resource analysis. As a first step
                 towards the analysis of imperative code, the technique
                 is developed for a first-order {ML}-like language with
                 unsigned integers and arrays. The analysis
                 automatically derives bounds that are multivariate
                 polynomials in the numbers and the lengths of the
                 arrays in the input. Experiments with example programs
                 demonstrate two main advantages of amortized analysis
                 over current abstract interpretation–based
                 techniques. For one thing, amortized analysis can
                 handle programs with non-linear intermediate values
                 like f((n + m)2). For another thing, amortized
                 analysis is compositional and works naturally for
                 compound programs like f(g(x)).",
  x-doi =        "10.1007/978-3-319-07151-0\_10",
  x-editor =     "Codish, Michael and Sumii, Eijiro",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-319-07151-0\_10",
  xpages =       "152--168",
  year =         "2014",
}

@InCollection{Hoffmann2010BAmortized,
  author =       "Jan Hoffmann and Martin Hofmann",
  booktitle =    "Programming Languages and Systems",
  citeulike-article-id = "13388842",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2175502",
  citeulike-linkout-1 = "http://dx.doi.org/10.1007/978-3-642-11957-6\_16",
  citeulike-linkout-2 = "http://link.springer.com/chapter/10.1007/978-3-642-11957-6\_16",
  date-added =   "2014-10-11 18:57:42",
  location =     "Paphos, Cyprus",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "Amortized Resource Analysis with Polynomial
                 Potential",
  volume =       "6012",
  x-abstract =   "In 2003, Hofmann and Jost introduced a type system
                 that uses a potential-based amortized analysis to infer
                 bounds on the resource consumption of (first-order)
                 functional programs. This analysis has been
                 successfully applied to many standard algorithms but is
                 limited to bounds that are linear in the size of the
                 input. Here we extend this system to polynomial
                 resource bounds. An automatic amortized analysis is
                 used to infer these bounds for functional programs
                 without further annotations if a maximal degree for the
                 bounding polynomials is given. The analysis is generic
                 in the resource and can obtain good bounds on
                 heap-space, stack-space and time usage.",
  x-address =    "Berlin, Heidelberg",
  x-doi =        "10.1007/978-3-642-11957-6\_16",
  x-editor =     "Gordon, AndrewD",
  x-isbn =       "3-642-11956-5, 978-3-642-11956-9",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-642-11957-6\_16",
  xpages =       "287--306",
  year =         "2010",
}

@InCollection{Hoffmann2012Resource,
  author =       "Jan Hoffmann and Klaus Aehlig and Martin Hofmann",
  booktitle =    "Computer Aided Verification",
  citeulike-article-id = "11841310",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-642-31424-7\_64",
  citeulike-linkout-1 = "http://link.springer.com/chapter/10.1007/978-3-642-31424-7\_64",
  date-added =   "2014-10-11 18:53:34",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "Resource Aware {ML}",
  volume =       "7358",
  x-abstract =   "The automatic determination of the quantitative
                 resource consumption of programs is a classic research
                 topic which has many applications in software
                 development. Recently, we developed a novel
                 multivariate amortized resource analysis that
                 automatically computes polynomial resource bounds for
                 first-order functional programs. In this tool paper, we
                 describe Resource Aware {ML} ({RAML}), a functional
                 programming language that implements our analysis.
                 Other than in earlier articles, we focus on the
                 practical aspects of the implementation. We describe
                 the syntax of {RAML}, the code transformation prior to
                 the analysis, the web interface, the output of the
                 analysis, and the results of our experiments with the
                 analysis of example programs.",
  x-doi =        "10.1007/978-3-642-31424-7\_64",
  x-editor =     "Madhusudan, P. and Seshia, SanjitA",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-642-31424-7\_64",
  xpages =       "781--786",
  year =         "2012",
}

@InProceedings{Hoffmann2010Amortized,
  author =       "Jan Hoffmann and Martin Hofmann",
  booktitle =    "Proceedings of the 8th Asian Conference on Programming
                 Languages and Systems",
  citeulike-article-id = "13388841",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1947891",
  date-added =   "2014-10-11 18:47:53",
  location =     "Shanghai, China",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "Amortized Resource Analysis with Polymorphic Recursion
                 and Partial Big-step Operational Semantics",
  x-abstract =   "This paper studies the problem of statically
                 determining upper bounds on the resource consumption of
                 first-order functional programs. A previous work
                 approached the problem with an automatic type-based
                 amortized analysis for polynomial resource bounds. The
                 analysis is parametric in the resource and can be
                 instantiated to heap space, stack space, or clock
                 cycles. Experiments with a prototype implementation
                 have shown that programs are analyzed efficiently and
                 that the computed bounds exactly match the measured
                 worst-case resource behavior for many functions. This
                 paper describes the inference algorithm that is used in
                 the implementation of the system. It can deal with
                 resource-polymorphic recursion which is required in the
                 type derivation of many functions. The computation of
                 the bounds is fully automatic if a maximal degree of
                 the polynomials is given. The soundness of the
                 inference is proved with respect to a novel operational
                 semantics for partial evaluations to show that the
                 inferred bounds hold for terminating as well as
                 non-terminating computations. A corollary is that
                 run-time bounds also establish the termination of
                 programs.",
  x-address =    "Berlin, Heidelberg",
  x-isbn =       "3-642-17163-X, 978-3-642-17163-5",
  x-series =     "APLAS'10",
  x-url =        "http://portal.acm.org/citation.cfm?id=1947891",
  xpages =       "172--187",
  year =         "2010",
}

@InProceedings{Carbonneaux2014Endtoend,
  author =       "Quentin Carbonneaux and Jan Hoffmann and Tahina
                 Ramananandro and Zhong Shao",
  booktitle =    "Proceedings of the 35th ACM SIGPLAN Conference on
                 Programming Language Design and Implementation",
  citeulike-article-id = "13388840",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2594301",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2666356.2594301",
  date-added =   "2014-10-11 18:45:54",
  month =        jun,
  priority =     "2",
  publisher =    "ACM",
  title =        "End-to-end Verification of Stack-space Bounds for {C}
                 Programs",
  x-abstract =   "Verified compilers guarantee the preservation of
                 semantic properties and thus enable formal verification
                 of programs at the source level. However, important
                 quantitative properties such as memory and time usage
                 still have to be verified at the machine level where
                 interactive proofs tend to be more tedious and
                 automation is more challenging. This article describes
                 a framework that enables the formal verification of
                 stack-space bounds of compiled machine code at the C
                 level. It consists of a verified {CompCert}-based
                 compiler that preserves quantitative properties, a
                 verified quantitative program logic for interactive
                 stack-bound development, and a verified stack analyzer
                 that automatically derives stack bounds during
                 compilation. The framework is based on event traces
                 that record function calls and returns. The source
                 language is {CompCert} Clight and the target language
                 is x86 assembly. The compiler is implemented in the Coq
                 Proof Assistant and it is proved that crucial
                 properties of event traces are preserved during
                 compilation. A novel quantitative Hoare logic is
                 developed to verify stack-space bounds at the
                 {CompCert} Clight level. The quantitative logic is
                 implemented in Coq and proved sound with respect to
                 event traces generated by the small-step semantics of
                 {CompCert} Clight. Stack-space bounds can be proved at
                 the source level without taking into account low-level
                 details that depend on the implementation of the
                 compiler. The compiler fills in these low-level details
                 during compilation and generates a concrete stack-space
                 bound that applies to the produced machine code. The
                 verified stack analyzer is guaranteed to automatically
                 derive bounds for code with non-recursive functions. It
                 generates a derivation in the quantitative logic to
                 ensure soundness as well as interoperability with
                 interactively developed stack bounds. In an
                 experimental evaluation, the developed framework is
                 used to obtain verified stack-space bounds for micro
                 benchmarks as well as real system code. The examples
                 include the verified operating-system kernel
                 {CertiKOS}, parts of the {MiBench} embedded benchmark
                 suite, and programs from the {CompCert} benchmarks. The
                 derived bounds are close to the measured stack-space
                 usage of executions of the compiled programs on a Linux
                 x86 system.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2666356.2594301",
  x-issn =       "0362-1340",
  x-url =        "http://dx.doi.org/10.1145/2666356.2594301",
  xpages =       "270--281",
  year =         "2014",
}

@InProceedings{Shalimov2013Advanced,
  author =       "Alexander Shalimov and Dmitry Zuikov and Daria
                 Zimarina and Vasily Pashkov and Ruslan Smeliansky",
  booktitle =    "Proceedings of the 9th Central \&\#38; Eastern
                 European Software Engineering Conference in Russia",
  citeulike-article-id = "13388839",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2556621",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2556610.2556621",
  date-added =   "2014-10-11 18:41:18",
  location =     "Moscow, Russia",
  priority =     "2",
  publisher =    "ACM",
  title =        "Advanced Study of {SDN}/{OpenFlow} Controllers",
  x-abstract =   "This paper presents an independent comprehensive
                 analysis of the efficiency indexes of popular open
                 source {SDN}/{OpenFlow} controllers ({NOX}, {POX},
                 Beacon, Floodlight, {MuL}, Maestro, Ryu). The analysed
                 indexes include performance, scalability, reliability,
                 and security. For testing purposes we developed the new
                 framework called hcprobe. The test bed and the
                 methodology we used are discussed in detail so that
                 everyone could reproduce our experiments. The result of
                 the evaluation show that modern {SDN}/{OpenFlow}
                 controllers are not ready to be used in production and
                 have to be improved in order to increase all above
                 mentioned characteristics.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2556610.2556621",
  x-isbn =       "978-1-4503-2641-4",
  x-series =     "CEE-SECR '13",
  x-url =        "http://dx.doi.org/10.1145/2556610.2556621",
  year =         "2013",
}

@InProceedings{Gulwani2009Controlflow,
  author =       "Sumit Gulwani and Sagar Jain and Eric Koskinen",
  booktitle =    "Proceedings of the 2009 ACM SIGPLAN Conference on
                 Programming Language Design and Implementation",
  citeulike-article-id = "13381674",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1542476.1542518",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1543135.1542518",
  date-added =   "2014-10-03 15:04:46",
  month =        jun,
  priority =     "2",
  publisher =    "ACM",
  title =        "Control-flow Refinement and Progress Invariants for
                 Bound Analysis",
  x-abstract =   "Symbolic complexity bounds help programmers understand
                 the performance characteristics of their
                 implementations. Existing work provides techniques for
                 statically determining bounds of procedures with simple
                 control-flow. However, procedures with nested loops or
                 multiple paths through a single loop are challenging.
                 In this paper we describe two techniques, control-flow
                 refinement and progress invariants, that together
                 enable estimation of precise bounds for procedures with
                 nested and multi-path loops. Control-flow refinement
                 transforms a multi-path loop into a semantically
                 equivalent code fragment with simpler loops by making
                 the structure of path interleaving explicit. We show
                 that this enables non-disjunctive invariant generation
                 tools to find a bound on many procedures for which
                 previous techniques were unable to prove termination.
                 Progress invariants characterize relationships between
                 consecutive states that can arise at a program
                 location. We further present an algorithm that uses
                 progress invariants to compute precise bounds for
                 nested loops. The utility of these two techniques goes
                 beyond our application to symbolic bound analysis. In
                 particular, we discuss applications of control-flow
                 refinement to proving safety properties that otherwise
                 require disjunctive invariants. We have applied our
                 methodology to over 670,000 lines of code of a
                 significant Microsoft product and were able to find
                 symbolic bounds for 90\% of the loops. We are not aware
                 of any other published results that report experiences
                 running a bound analysis on a real code-base.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1543135.1542518",
  x-issn =       "0362-1340",
  x-url =        "http://dx.doi.org/10.1145/1543135.1542518",
  xpages =       "375--385",
  year =         "2009",
}

@InProceedings{Gulwani2010Dimensions,
  author =       "S. Gulwani",
  booktitle =    "Formal Methods in Computer-Aided Design (FMCAD),
                 2010",
  citeulike-article-id = "13381221",
  citeulike-linkout-0 = "http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5770924",
  date-added =   "2014-10-03 01:14:21",
  institution =  "Microsoft Res., Redmond, WA, USA",
  month =        oct,
  priority =     "2",
  publisher =    "IEEE",
  title =        "Dimensions in program synthesis",
  x-isbn =       "978-1-4577-0734-6",
  x-url =        "http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5770924",
  xpages =       "1",
  year =         "2010",
}

@InProceedings{Torlak2014Lightweight,
  author =       "Emina Torlak and Rastislav Bodik",
  booktitle =    "Proceedings of the 35th ACM SIGPLAN Conference on
                 Programming Language Design and Implementation",
  citeulike-article-id = "13381220",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2594340",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2594291.2594340",
  date-added =   "2014-10-03 01:13:37",
  location =     "Edinburgh, United Kingdom",
  priority =     "2",
  publisher =    "ACM",
  title =        "A Lightweight Symbolic Virtual Machine for
                 Solver-aided Host Languages",
  x-abstract =   "Solver-aided domain-specific languages ({SDSLs}) are
                 an emerging class of computer-aided programming
                 systems. They ease the construction of programs by
                 using satisfiability solvers to automate tasks such as
                 verification, debugging, synthesis, and
                 non-deterministic execution. But reducing programming
                 tasks to satisfiability problems involves translating
                 programs to logical constraints, which is an
                 engineering challenge even for domain-specific
                 languages. We have previously shown that translation to
                 constraints can be avoided if {SDSLs} are implemented
                 by (traditional) embedding into a host language that is
                 itself solver-aided. This paper describes how to
                 implement a symbolic virtual machine ({SVM}) for such a
                 host language. Our symbolic virtual machine is
                 lightweight because it compiles to constraints only a
                 small subset of the host's constructs, while allowing
                 {SDSL} designers to use the entire language, including
                 constructs for {DSL} embedding. This lightweight
                 compilation employs a novel symbolic execution
                 technique with two key properties: it produces compact
                 encodings, and it enables concrete evaluation to strip
                 away host constructs that are outside the subset
                 compilable to constraints. Our symbolic virtual machine
                 architecture is at the heart of Rosette, a solver-aided
                 language that is host to several new {SDSLs}.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2594291.2594340",
  x-isbn =       "978-1-4503-2784-8",
  x-series =     "PLDI '14",
  x-url =        "http://dx.doi.org/10.1145/2594291.2594340",
  xpages =       "530--541",
  year =         "2014",
}

@InProceedings{Lezama2005Programming,
  author =       "Armando S. Lezama and Rodric Rabbah and Rastislav
                 Bod'{\i}k and Kemal Ebcio\u{g}lu",
  booktitle =    "Proceedings of the 2005 ACM SIGPLAN Conference on
                 Programming Language Design and Implementation",
  citeulike-article-id = "13381219",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1065045",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1064978.1065045",
  date-added =   "2014-10-03 01:11:56",
  month =        jun,
  priority =     "2",
  publisher =    "ACM",
  title =        "Programming by Sketching for Bit-streaming Programs",
  x-abstract =   "This paper introduces the concept of programming with
                 sketches, an approach for the rapid development of
                 high-performance applications. This approach allows a
                 programmer to write clean and portable reference code,
                 and then obtain a high-quality implementation by simply
                 sketching the outlines of the desired implementation.
                 Subsequently, a compiler automatically fills in the
                 missing details while also ensuring that a completed
                 sketch is faithful to the input reference code. In this
                 paper, we develop {StreamBit} as a sketching
                 methodology for the important class of bit-streaming
                 programs (e.g., coding and {cryptography).A} sketch is
                 a partial specification of the implementation, and as
                 such, it affords several benefits to programmer in
                 terms of productivity and code robustness. First, a
                 sketch is easier to write compared to a complete
                 implementation. Second, sketching allows the programmer
                 to focus on exploiting algorithmic properties rather
                 than on orchestrating low-level details. Third, a
                 sketch-aware compiler rejects {"}buggy{"} sketches,
                 thus improving reliability while allowing the
                 programmer to quickly evaluate sophisticated
                 implementation {ideas.We} evaluated the productivity
                 and performance benefits of our programming methodology
                 in a user-study, where a group of novice {StreamBit}
                 programmers competed with a group of experienced C
                 programmers on implementing a cipher. We learned that,
                 given the same time budget, the ciphers developed in
                 {StreamBit} ran 2.5x faster than ciphers coded in C. We
                 also produced implementations of {DES} and Serpent that
                 were competitive with hand optimized implementations
                 available in the public domain.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1064978.1065045",
  x-issn =       "0362-1340",
  x-url =        "http://dx.doi.org/10.1145/1064978.1065045",
  xpages =       "281--294",
  year =         "2005",
}

@Article{Lezama2006Combinatorial,
  author =       "Armando S. Lezama and Liviu Tancau and Rastislav Bodik
                 and Sanjit Seshia and Vijay Saraswat",
  citeulike-article-id = "13098036",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1168907",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1168917.1168907",
  date-added =   "2014-10-03 01:11:02",
  journal =      "SIGOPS Oper. Syst. Rev.",
  month =        oct,
  number =       "5",
  priority =     "2",
  publisher =    "ACM",
  title =        "Combinatorial Sketching for Finite Programs",
  volume =       "40",
  x-abstract =   "Sketching is a software synthesis approach where the
                 programmer develops a partial implementation - a sketch
                 - and a separate specification of the desired
                 functionality. The synthesizer then completes the
                 sketch to behave like the specification. The
                 correctness of the synthesized implementation is
                 guaranteed by the compiler, which allows, among other
                 benefits, rapid development of highly tuned
                 implementations without the fear of introducing
                 {bugs.We} develop {SKETCH}, a language for finite
                 programs with linguistic support for sketching. Finite
                 programs include many highperformance kernels,
                 including cryptocodes. In contrast to prior
                 synthesizers, which had to be equipped with
                 domain-specific rules, {SKETCH} completes sketches by
                 means of a combinatorial search based on generalized
                 boolean satisfiability. Consequently, our combinatorial
                 synthesizer is complete for the class of finite
                 programs: it is guaranteed to complete any sketch in
                 theory, and in practice has scaled to realistic
                 programming {problems.Freed} from domain rules, we can
                 now write sketches as simpleto-understand partial
                 programs, which are regular programs in which difficult
                 code fragments are replaced with holes to be filled by
                 the synthesizer. Holes may stand for index expressions,
                 lookup tables, or bitmasks, but the programmer can
                 easily define new kinds of holes using a single
                 versatile synthesis {operator.We} have used {SKETCH} to
                 synthesize an efficient implementation of the {AES}
                 cipher standard. The synthesizer produces the most
                 complex part of the implementation and runs in about an
                 hour.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1168917.1168907",
  x-issn =       "0163-5980",
  x-url =        "http://dx.doi.org/10.1145/1168917.1168907",
  xpages =       "404--415",
  year =         "2006",
}

@InProceedings{Alur2013Syntaxguided,
  author =       "Rajeev Alur and Rastislav Bodik and Garvit Juniwal and
                 Milo M. K. Martin and Mukund Raghothaman and Sanjit
                 Seshia and Rajdeep Singh and Armando Solar-Lezama and
                 Emina Torlak and Abhishek Udupa",
  booktitle =    "Formal Methods in Computer-Aided Design (FMCAD),
                 2013",
  citeulike-article-id = "13381218",
  citeulike-linkout-0 = "http://dx.doi.org/10.1109/fmcad.2013.6679385",
  citeulike-linkout-1 = "http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6679385",
  date-added =   "2014-10-03 01:10:11",
  institution =  "Univ. of Pennsylvania, Philadelphia, PA, USA",
  month =        oct,
  priority =     "2",
  publisher =    "IEEE",
  title =        "Syntax-guided synthesis",
  x-doi =        "10.1109/fmcad.2013.6679385",
  x-url =        "http://dx.doi.org/10.1109/fmcad.2013.6679385",
  xpages =       "1--8",
  year =         "2013",
}

@InCollection{Sharma2012Interpolants,
  author =       "Rahul Sharma and AdityaV Nori and Alex Aiken",
  booktitle =    "Computer Aided Verification",
  citeulike-article-id = "13381217",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-642-31424-7\_11",
  citeulike-linkout-1 = "http://link.springer.com/chapter/10.1007/978-3-642-31424-7\_11",
  date-added =   "2014-10-03 01:09:03",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "Interpolants as Classifiers",
  volume =       "7358",
  x-abstract =   "We show how interpolants can be viewed as classifiers
                 in supervised machine learning. This view has several
                 advantages: First, we are able to use off-the-shelf
                 classification techniques, in particular support vector
                 machines ({SVMs}), for interpolation. Second, we show
                 that {SVMs} can find relevant predicates for a number
                 of benchmarks. Since classification algorithms are
                 predictive, the interpolants computed via
                 classification are likely to be invariants. Finally,
                 the machine learning view also enables us to handle
                 superficial non-linearities. Even if the underlying
                 problem structure is linear, the symbolic constraints
                 can give an impression that we are solving a non-linear
                 problem. Since learning algorithms try to mine the
                 underlying structure directly, we can discover the
                 linear structure for such problems. We demonstrate the
                 feasibility of our approach via experiments over
                 benchmarks from various papers on program
                 verification.",
  x-doi =        "10.1007/978-3-642-31424-7\_11",
  x-editor =     "Madhusudan, P. and Seshia, SanjitA",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-642-31424-7\_11",
  xpages =       "71--87",
  year =         "2012",
}

@InCollection{Sharma2013Data,
  author =       "Rahul Sharma and Saurabh Gupta and Bharath Hariharan
                 and Alex Aiken and Percy Liang and AdityaV Nori",
  booktitle =    "Programming Languages and Systems",
  citeulike-article-id = "13381216",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-642-37036-6\_31",
  citeulike-linkout-1 = "http://link.springer.com/chapter/10.1007/978-3-642-37036-6\_31",
  date-added =   "2014-10-03 01:08:20",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "A Data Driven Approach for Algebraic Loop Invariants",
  volume =       "7792",
  x-abstract =   "We describe a {Guess-and-Check} algorithm for
                 computing algebraic equation invariants of the form
                 ∧ i f i (x 1,…,x n ) = 0, where each f i is a
                 polynomial over the variables x 1,…,x n of the
                 program. The ” guess” phase is data driven and
                 derives a candidate invariant from data generated from
                 concrete executions of the program. This candidate
                 invariant is subsequently validated in a ” check”
                 phase by an off-the-shelf {SMT} solver. Iterating
                 between the two phases leads to a sound algorithm.
                 Moreover, we are able to prove a bound on the number of
                 decision procedure queries which {Guess-and-Check}
                 requires to obtain a sound invariant. We show how
                 {Guess-and-Check} can be extended to generate arbitrary
                 boolean combinations of linear equalities as
                 invariants, which enables us to generate expressive
                 invariants to be consumed by tools that cannot handle
                 non-linear arithmetic. We have evaluated our technique
                 on a number of benchmark programs from recent papers on
                 invariant generation. Our results are encouraging –
                 we are able to efficiently compute algebraic invariants
                 in all cases, with only a few tests.",
  x-doi =        "10.1007/978-3-642-37036-6\_31",
  x-editor =     "Felleisen, Matthias and Gardner, Philippa",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-642-37036-6\_31",
  xpages =       "574--592",
  year =         "2013",
}

@InCollection{Sharma2014From,
  author =       "Rahul Sharma and Alex Aiken",
  booktitle =    "Computer Aided Verification",
  citeulike-article-id = "13381215",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-319-08867-9\_6",
  citeulike-linkout-1 = "http://link.springer.com/chapter/10.1007/978-3-319-08867-9\_6",
  date-added =   "2014-10-03 01:07:22",
  priority =     "2",
  publisher =    "Springer International Publishing",
  title =        "From Invariant Checking to Invariant Inference Using
                 Randomized Search",
  volume =       "8559",
  x-abstract =   "We describe a general framework c2i for generating an
                 invariant inference procedure from an invariant
                 checking procedure. Given a checker and a language of
                 possible invariants, c2i generates an inference
                 procedure that iteratively invokes two phases. The
                 search phase uses randomized search to discover
                 candidate invariants and the validate phase uses the
                 checker to either prove or refute that the candidate is
                 an actual invariant. To demonstrate the applicability
                 of c2i, we use it to generate inference procedures that
                 prove safety properties of numerical programs, prove
                 non-termination of numerical programs, prove functional
                 specifications of array manipulating programs, prove
                 safety properties of string manipulating programs, and
                 prove functional specifications of heap manipulating
                 programs that use linked list data structures.",
  x-doi =        "10.1007/978-3-319-08867-9\_6",
  x-editor =     "Biere, Armin and Bloem, Roderick",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-319-08867-9\_6",
  xpages =       "88--105",
  year =         "2014",
}

@Book{ColindelaHiguera2010Grammatical,
  author =       "Colin de la Higuera",
  citeulike-article-id = "13381214",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1830440",
  date-added =   "2014-10-03 01:06:38",
  priority =     "2",
  publisher =    "Cambridge University Press",
  title =        "Grammatical Inference: Learning Automata and
                 Grammars",
  x-abstract =   "The problem of inducing, learning or inferring
                 grammars has been studied for decades, but only in
                 recent years has grammatical inference emerged as an
                 independent field with connections to many scientific
                 disciplines, including bio-informatics, computational
                 linguistics and pattern recognition. This book meets
                 the need for a comprehensive and unified summary of the
                 basic techniques and results, suitable for researchers
                 working in these various areas. In Part I, the objects
                 of use for grammatical inference are studied in detail:
                 strings and their topology, automata and grammars,
                 whether probabilistic or not. Part {II} carefully
                 explores the main questions in the field: What does
                 learning mean? How can we associate complexity theory
                 with learning? In Part {III} the author describes a
                 number of techniques and algorithms that allow us to
                 learn from text, from an informant, or through
                 interaction with the environment. These concern
                 automata, grammars, rewriting systems, pattern
                 languages or transducers.",
  x-address =    "New York, NY, USA",
  x-isbn =       "0521763169, 9780521763165",
  x-url =        "http://portal.acm.org/citation.cfm?id=1830440",
  year =         "2010",
}

@Article{Angluin1980Inductive,
  author =       "Dana Angluin",
  citeulike-article-id = "5845274",
  citeulike-linkout-0 = "http://dx.doi.org/10.1016/s0019-9958(80)90285-5",
  date-added =   "2014-10-03 01:05:23",
  journal =      "Information and Control",
  month =        may,
  number =       "2",
  priority =     "2",
  title =        "Inductive inference of formal languages from positive
                 data",
  volume =       "45",
  x-doi =        "10.1016/s0019-9958(80)90285-5",
  x-issn =       "00199958",
  x-url =        "http://dx.doi.org/10.1016/s0019-9958(80)90285-5",
  xpages =       "117--135",
  year =         "1980",
}

@Article{Xie2009Data,
  author =       "Tao Xie and S. Thummalapenta and D. Lo and Chao Liu",
  citeulike-article-id = "5527867",
  citeulike-linkout-0 = "http://doi.ieeecomputersociety.org/10.1109/MC.2009.256",
  citeulike-linkout-1 = "http://dx.doi.org/10.1109/mc.2009.256",
  citeulike-linkout-2 = "http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5197425",
  date-added =   "2014-10-03 01:04:17",
  institution =  "North Carolina State Univ., Raleigh, NC, USA",
  journal =      "Computer",
  month =        aug,
  number =       "8",
  priority =     "2",
  publisher =    "IEEE",
  title =        "Data Mining for Software Engineering",
  volume =       "42",
  x-abstract =   "To improve software productivity and quality, software
                 engineers are increasingly applying data mining
                 algorithms to various software engineering tasks.
                 However, mining {SE} data poses several challenges. The
                 authors present various algorithms to effectively mine
                 sequences, graphs, and text from such data.",
  x-address =    "Los Alamitos, CA, USA",
  x-doi =        "10.1109/mc.2009.256",
  x-issn =       "0018-9162",
  x-url =        "http://dx.doi.org/10.1109/mc.2009.256",
  xpages =       "55--62",
  year =         "2009",
}

@InProceedings{Shoham2007Static,
  author =       "Sharon Shoham and Eran Yahav and Stephen Fink and
                 Marco Pistoia",
  booktitle =    "Proceedings of the 2007 International Symposium on
                 Software Testing and Analysis",
  citeulike-article-id = "2808863",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1273463.1273487",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1273463.1273487",
  date-added =   "2014-10-03 01:03:30",
  location =     "London, United Kingdom",
  priority =     "2",
  publisher =    "ACM",
  title =        "Static Specification Mining Using Automata-based
                 Abstractions",
  x-abstract =   "We present a novel approach to client-side mining of
                 temporal {API} specifications based on static analysis.
                 Specifically, we present an interprocedural analysis
                 over a combined domain that abstracts both aliasing and
                 event sequences for individual objects. The analysis
                 uses a new family of automata-based abstractions to
                 represent unbounded event sequences, designed to
                 disambiguate distinct usage patterns and merge similar
                 usage patterns. Additionally, our approach includes an
                 algorithm that summarizes abstract traces based on
                 automata clusters, and effectively rules out spurious
                 behaviors. We show experimental results mining
                 specifications from a number of Java clients and
                 {APIs}. The results indicate that effective static
                 analysis for client-side mining requires fairly precise
                 treatment of aliasing and abstract event sequences.
                 Based on the results, we conclude that static
                 client-side specification mining shows promise as a
                 complement or alternative to dynamic approaches.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1273463.1273487",
  x-isbn =       "978-1-59593-734-6",
  x-series =     "ISSTA '07",
  x-url =        "http://dx.doi.org/10.1145/1273463.1273487",
  xpages =       "174--184",
  year =         "2007",
}

@InProceedings{Ammons2002Mining,
  author =       "Glenn Ammons and Rastislav Bodik and James R. Larus",
  booktitle =    "Proceedings of the 29th ACM SIGPLAN-SIGACT Symposium
                 on Principles of Programming Languages",
  citeulike-article-id = "3418",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=503275",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/503272.503275",
  date-added =   "2014-10-03 00:58:54",
  location =     "Portland, Oregon",
  month =        jan,
  priority =     "2",
  publisher =    "ACM",
  title =        "Mining Specifications",
  x-abstract =   "Program verification is a promising approach to
                 improving program quality, because it can search all
                 possible program executions for specific errors.
                 However, the need to formally describe correct behavior
                 or errors is a major barrier to the widespread adoption
                 of program verification, since programmers historically
                 have been reluctant to write formal specifications.
                 Automating the process of formulating specifications
                 would remove a barrier to program verification and
                 enhance its {practicality.This} paper describes
                 specification mining, a machine learning approach to
                 discovering formal specifications of the protocols that
                 code must obey when interacting with an application
                 program interface or abstract data type. Starting from
                 the assumption that a working program is well enough
                 debugged to reveal strong hints of correct protocols,
                 our tool infers a specification by observing program
                 execution and concisely summarizing the frequent
                 interaction patterns as state machines that capture
                 both temporal and data dependences. These state
                 machines can be examined by a programmer, to refine the
                 specification and identify errors, and can be utilized
                 by automatic verification tools, to find {bugs.Our}
                 preliminary experience with the mining tool has been
                 promising. We were able to learn specifications that
                 not only captured the correct protocol, but also
                 discovered serious bugs.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/503272.503275",
  x-isbn =       "1-58113-450-9",
  x-issn =       "0362-1340",
  x-series =     "POPL '02",
  x-url =        "http://dx.doi.org/10.1145/503272.503275",
  xpages =       "4--16",
  year =         "2002",
}

@InProceedings{Saxena2009Loopextended,
  author =       "Prateek Saxena and Pongsin Poosankam and Stephen
                 McCamant and Dawn Song",
  booktitle =    "Proceedings of the Eighteenth International Symposium
                 on Software Testing and Analysis",
  citeulike-article-id = "6588691",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1572272.1572299",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1572272.1572299",
  date-added =   "2014-10-03 00:51:25",
  location =     "Chicago, IL, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "Loop-extended Symbolic Execution on Binary Programs",
  x-abstract =   "Mixed concrete and symbolic execution is an important
                 technique for finding and understanding software bugs,
                 including security-relevant ones. However, existing
                 symbolic execution techniques are limited to examining
                 one execution path at a time, in which symbolic
                 variables reflect only direct data dependencies. We
                 introduce loop-extended symbolic execution, a
                 generalization that broadens the coverage of symbolic
                 results in programs with loops. It introduces symbolic
                 variables for the number of times each loop executes,
                 and links these with features of a known input grammar
                 such as variable-length or repeating fields. This
                 allows the symbolic constraints to cover a class of
                 paths that includes different numbers of loop
                 iterations, expressing loop-dependent program values in
                 terms of properties of the input. By performing more
                 reasoning symbolically, instead of by undirected
                 exploration, applications of loop-extended symbolic
                 execution can achieve better results and/or require
                 fewer program executions. To demonstrate our technique,
                 we apply it to the problem of discovering and
                 diagnosing buffer-overflow vulnerabilities in software
                 given only in binary form. Our tool finds
                 vulnerabilities in both a standard benchmark suite and
                 3 real-world applications, after generating only a
                 handful of candidate inputs, and also diagnoses general
                 vulnerability conditions.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1572272.1572299",
  x-isbn =       "978-1-60558-338-9",
  x-series =     "ISSTA '09",
  x-url =        "http://dx.doi.org/10.1145/1572272.1572299",
  xpages =       "225--236",
  year =         "2009",
}

@InProceedings{Cho2013BLITZ,
  author =       "Chia Y. Cho and V. D'Silva and D. Song",
  booktitle =    "Automated Software Engineering (ASE), 2013 IEEE/ACM
                 28th International Conference on",
  citeulike-article-id = "13381206",
  citeulike-linkout-0 = "http://dx.doi.org/10.1109/ase.2013.6693074",
  citeulike-linkout-1 = "http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6693074",
  date-added =   "2014-10-03 00:50:41",
  institution =  "Univ. of California, Berkeley, Berkeley, CA, USA",
  month =        nov,
  priority =     "2",
  publisher =    "IEEE",
  title =        "{BLITZ}: Compositional bounded model checking for
                 real-world programs",
  x-doi =        "10.1109/ase.2013.6693074",
  x-url =        "http://dx.doi.org/10.1109/ase.2013.6693074",
  xpages =       "136--146",
  year =         "2013",
}

@InProceedings{Cho2011MACE,
  author =       "Chia Y. Cho and Domagoj Babi\'{c} and Pongsin
                 Poosankam and Kevin Z. Chen and Edward X. Wu and Dawn
                 Song",
  booktitle =    "Proceedings of the 20th USENIX Conference on
                 Security",
  citeulike-article-id = "13381205",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2028077",
  date-added =   "2014-10-03 00:49:23",
  location =     "San Francisco, CA",
  priority =     "2",
  publisher =    "USENIX Association",
  title =        "{MACE}: Model-inference-assisted Concolic Exploration
                 for Protocol and Vulnerability Discovery",
  x-abstract =   "Programstate-space exploration is central to software
                 security, testing, and verification. In this paper, we
                 propose a novel technique for state-space exploration
                 of software that maintains an ongoing interaction with
                 its environment. Our technique uses a combination of
                 symbolic and concrete execution to build an abstract
                 model of the analyzed application, in the form of a
                 finite-state automaton, and uses the model to guide
                 further state-space exploration. Through exploration,
                 {MACE} further refines the abstract model. Using the
                 abstract model as a scaffold, our technique wields more
                 control over the search process. In particular: (1)
                 shifting search to different parts of the search-space
                 becomes easier, resulting in higher code coverage, and
                 (2) the search is less likely to get stuck in small
                 local state-subspaces (e.g., loops) irrelevant to the
                 application's interaction with the environment.
                 Preliminary experimental results show significant
                 increases in the code coverage and exploration depth.
                 Further, our approach found a number of new deep
                 vulnerabilities.",
  x-address =    "Berkeley, CA, USA",
  x-series =     "SEC'11",
  x-url =        "http://portal.acm.org/citation.cfm?id=2028077",
  xpages =       "10",
  year =         "2011",
}

@InProceedings{Cho2010Inference,
  author =       "Chia Y. Cho and Domagoj Babi and Eui Chul Richard Shin
                 and Dawn Song",
  booktitle =    "Proceedings of the 17th ACM Conference on Computer and
                 Communications Security",
  citeulike-article-id = "13381204",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1866307.1866355",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1866307.1866355",
  date-added =   "2014-10-03 00:47:58",
  location =     "Chicago, Illinois, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "Inference and Analysis of Formal Models of Botnet
                 Command and Control Protocols",
  x-abstract =   "We propose a novel approach to infer protocol state
                 machines in the realistic high-latency network setting,
                 and apply it to the analysis of botnet Command and
                 Control (C \&C) protocols. Our proposed techniques
                 enable an order of magnitude reduction in the number of
                 queries and time needed to learn a botnet C \&C
                 protocol compared to classic algorithms (from days to
                 hours for inferring the {MegaD} C \&C protocol). We
                 also show that the computed protocol state machines
                 enable formal analysis for botnet defense, including
                 finding the weakest links in a protocol, uncovering
                 protocol design flaws, inferring the existence of
                 unobservable communication back-channels among botnet
                 servers, and finding deviations of protocol
                 implementations which can be used for fingerprinting.
                 We validate our technique by inferring the protocol
                 state-machine from Postfix's {SMTP} implementation and
                 comparing the inferred state-machine to the {SMTP}
                 standard. Further, our experimental results offer new
                 insights into {MegaD}'s C \&C, showing our technique
                 can be used as a powerful tool for defense against
                 botnets.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1866307.1866355",
  x-isbn =       "978-1-4503-0245-6",
  x-series =     "CCS '10",
  x-url =        "http://dx.doi.org/10.1145/1866307.1866355",
  xpages =       "426--439",
  year =         "2010",
}

@InProceedings{Gulwani2010Reachabilitybound,
  author =       "Sumit Gulwani and Florian Zuleger",
  booktitle =    "Proceedings of the 2010 ACM SIGPLAN Conference on
                 Programming Language Design and Implementation",
  citeulike-article-id = "13381203",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1806630",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1806596.1806630",
  date-added =   "2014-10-03 00:46:52",
  location =     "Toronto, Ontario, Canada",
  priority =     "2",
  publisher =    "ACM",
  title =        "The Reachability-bound Problem",
  x-abstract =   "We define the reachability-bound problem to be the
                 problem of finding a symbolic worst-case bound on the
                 number of times a given control location inside a
                 procedure is visited in terms of the inputs to that
                 procedure. This has applications in bounding resources
                 consumed by a program such as time, memory,
                 network-traffic, power, as well as estimating
                 quantitative properties (as opposed to boolean
                 properties) of data in programs, such as information
                 leakage or uncertainty propagation. Our approach to
                 solving the reachability-bound problem brings together
                 two different techniques for reasoning about loops in
                 an effective manner. One of these techniques is an
                 abstract-interpretation based iterative technique for
                 computing precise disjunctive invariants (to summarize
                 nested loops). The other technique is a non-iterative
                 proof-rules based technique (for loop bound
                 computation) that takes over the role of doing
                 inductive reasoning, while deriving its power from the
                 use of {SMT} solvers to reason about abstract loop-free
                 fragments. Our solution to the reachability-bound
                 problem allows us to compute precise symbolic
                 complexity bounds for several loops in .Net base-class
                 libraries for which earlier techniques fail. We also
                 illustrate the precision of our algorithm for
                 disjunctive invariant computation (which has a more
                 general applicability beyond the reachability-bound
                 problem) on a set of benchmark examples.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1806596.1806630",
  x-isbn =       "978-1-4503-0019-3",
  x-series =     "PLDI '10",
  x-url =        "http://dx.doi.org/10.1145/1806596.1806630",
  xpages =       "292--304",
  year =         "2010",
}

@InProceedings{Chang2009Inputs,
  author =       "R. Chang and Guofei Jiang and F. Ivancic and S.
                 Sankaranarayanan and V. Shmatikov",
  booktitle =    "Computer Security Foundations Symposium, 2009. CSF
                 '09. 22nd IEEE",
  citeulike-article-id = "13381202",
  citeulike-linkout-0 = "http://dx.doi.org/10.1109/csf.2009.13",
  citeulike-linkout-1 = "http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5230618",
  date-added =   "2014-10-03 00:45:44",
  institution =  "Univ. of Texas at Austin, Austin, TX, USA",
  month =        jul,
  priority =     "2",
  publisher =    "IEEE",
  title =        "Inputs of Coma: Static Detection of
                 {Denial-of-Service} Vulnerabilities",
  x-doi =        "10.1109/csf.2009.13",
  x-isbn =       "978-0-7695-3712-2",
  x-issn =       "1940-1434",
  x-url =        "http://dx.doi.org/10.1109/csf.2009.13",
  xpages =       "186--199",
  year =         "2009",
}

@InProceedings{Avgerinos2014Enhancing,
  author =       "Thanassis Avgerinos and Alexandre Rebert and Sang K.
                 Cha and David Brumley",
  booktitle =    "Proceedings of the 36th International Conference on
                 Software Engineering",
  citeulike-article-id = "13381201",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2568293",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2568225.2568293",
  date-added =   "2014-10-03 00:44:50",
  location =     "Hyderabad, India",
  priority =     "2",
  publisher =    "ACM",
  title =        "Enhancing Symbolic Execution with Veritesting",
  x-abstract =   "We present {MergePoint}, a new binary-only symbolic
                 execution system for large-scale and fully unassisted
                 testing of commodity off-the-shelf ({COTS}) software.
                 {MergePoint} introduces veritesting, a new technique
                 that employs static symbolic execution to amplify the
                 effect of dynamic symbolic execution. Veritesting
                 allows {MergePoint} to find twice as many bugs, explore
                 orders of magnitude more paths, and achieve higher code
                 coverage than previous dynamic symbolic execution
                 systems. {MergePoint} is currently running daily on a
                 100 node cluster analyzing 33,248 Linux binaries; has
                 generated more than 15 billion {SMT} queries, 200
                 million test cases, 2,347,420 crashes, and found 11,687
                 bugs in 4,379 distinct applications.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2568225.2568293",
  x-isbn =       "978-1-4503-2756-5",
  x-series =     "ICSE 2014",
  x-url =        "http://dx.doi.org/10.1145/2568225.2568293",
  xpages =       "1083--1094",
  year =         "2014",
}

@Article{Ciortea2010Cloud9,
  author =       "Liviu Ciortea and Cristian Zamfir and Stefan Bucur and
                 Vitaly Chipounov and George Candea",
  citeulike-article-id = "12601293",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1713257",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1713254.1713257",
  date-added =   "2014-10-03 00:44:00",
  journal =      "SIGOPS Oper. Syst. Rev.",
  month =        jan,
  number =       "4",
  priority =     "2",
  publisher =    "ACM",
  title =        "Cloud9: {A} Software Testing Service",
  volume =       "43",
  x-abstract =   "Cloud9 aims to reduce the resource-intensive and
                 laborintensive nature of high-quality software testing.
                 First, Cloud9 parallelizes symbolic execution (an
                 effective, but still poorly scalable test automation
                 technique) to large shared-nothing clusters. To our
                 knowledge, Cloud9 is the first symbolic execution
                 engine that scales to large clusters of machines, thus
                 enabling thorough automated testing of real software in
                 conveniently short amounts of time. Preliminary results
                 indicate one to two orders of magnitude speedup over a
                 state-of-the-art symbolic execution engine. Second,
                 Cloud9 is an on-demand software testing service: it
                 runs on compute clouds, like Amazon {EC2}, and scales
                 its use of resources over a wide dynamic range,
                 proportionally with the testing task at hand.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1713254.1713257",
  x-issn =       "0163-5980",
  x-url =        "http://dx.doi.org/10.1145/1713254.1713257",
  xpages =       "5--10",
  year =         "2010",
}

@InProceedings{Xie2005Saturn,
  author =       "Yichen Xie and Alex Aiken",
  booktitle =    "Proceedings of the 17th International Conference on
                 Computer Aided Verification",
  citeulike-article-id = "13381200",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2153248",
  citeulike-linkout-1 = "http://dx.doi.org/10.1007/11513988\_13",
  date-added =   "2014-10-03 00:42:52",
  location =     "Edinburgh, Scotland, UK",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "Saturn: {A} {SAT}-based Tool for Bug Detection",
  x-abstract =   "Saturn is a boolean satisfiability ({SAT}) based
                 framework for static bug detection. Saturn targets
                 software written in C and is designed to support a wide
                 range of property checkers.",
  x-address =    "Berlin, Heidelberg",
  x-doi =        "10.1007/11513988\_13",
  x-isbn =       "3-540-27231-3, 978-3-540-27231-1",
  x-series =     "CAV'05",
  x-url =        "http://dx.doi.org/10.1007/11513988\_13",
  xpages =       "139--143",
  year =         "2005",
}

@InProceedings{Gulwani2009SPEED,
  author =       "Sumit Gulwani and Krishna K. Mehra and Trishul
                 Chilimbi",
  booktitle =    "Proceedings of the 36th annual ACM SIGPLAN-SIGACT
                 Symposium on Principles of Programming Languages",
  citeulike-article-id = "13381198",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1480898",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1594834.1480898",
  date-added =   "2014-10-03 00:35:22",
  month =        jan,
  priority =     "2",
  publisher =    "ACM",
  title =        "{SPEED}: Precise and Efficient Static Estimation of
                 Program Computational Complexity",
  x-abstract =   "This paper describes an inter-procedural technique for
                 computing symbolic bounds on the number of statements a
                 procedure executes in terms of its scalar inputs and
                 user-defined quantitative functions of input
                 data-structures. Such computational complexity bounds
                 for even simple programs are usually disjunctive,
                 non-linear, and involve numerical properties of heaps.
                 We address the challenges of generating these bounds
                 using two novel ideas. We introduce a proof methodology
                 based on multiple counter instrumentation (each counter
                 can be initialized and incremented at potentially
                 multiple program locations) that allows a given linear
                 invariant generation tool to compute linear bounds
                 individually on these counter variables. The bounds on
                 these counters are then composed together to generate
                 total bounds that are non-linear and disjunctive. We
                 also give an algorithm for automating this proof
                 methodology. Our algorithm generates complexity bounds
                 that are usually precise not only in terms of the
                 computational complexity, but also in terms of the
                 constant factors. Next, we introduce the notion of
                 user-defined quantitative functions that can be
                 associated with abstract data-structures, e.g., length
                 of a list, height of a tree, etc. We show how to
                 compute bounds in terms of these quantitative functions
                 using a linear invariant generation tool that has
                 support for handling uninterpreted functions. We show
                 application of this methodology to commonly used
                 data-structures (namely lists, list of lists, trees,
                 bit-vectors) using examples from Microsoft product
                 code. We observe that a few quantitative functions for
                 each data-structure are usually sufficient to allow
                 generation of symbolic complexity bounds of a variety
                 of loops that iterate over these data-structures, and
                 that it is straightforward to define these quantitative
                 functions. The combination of these techniques enables
                 generation of precise computational complexity bounds
                 for real-world examples (drawn from Microsoft product
                 code and C++ {STL} library code) for some of which it
                 is non-trivial to even prove termination. Such
                 automatically generated bounds are very useful for
                 early detection of egregious performance problems in
                 large modular codebases that are constantly being
                 changed by multiple developers who make heavy use of
                 code written by others without a good understanding of
                 their implementation complexity.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1594834.1480898",
  x-issn =       "0362-1340",
  x-url =        "http://dx.doi.org/10.1145/1594834.1480898",
  xpages =       "127--139",
  year =         "2009",
}

@InCollection{Sinn2014Simple,
  author =       "Moritz Sinn and Florian Zuleger and Helmut Veith",
  booktitle =    "Computer Aided Verification",
  citeulike-article-id = "13381196",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-319-08867-9\_50",
  citeulike-linkout-1 = "http://link.springer.com/chapter/10.1007/978-3-319-08867-9\_50",
  date-added =   "2014-10-03 00:33:57",
  priority =     "2",
  publisher =    "Springer International Publishing",
  title =        "A Simple and Scalable Static Analysis for Bound
                 Analysis and Amortized Complexity Analysis",
  volume =       "8559",
  x-abstract =   "We present the first scalable bound analysis that
                 achieves amortized complexity analysis. In contrast to
                 earlier work, our bound analysis is not based on
                 general purpose reasoners such as abstract
                 interpreters, software model checkers or computer
                 algebra tools. Rather, we derive bounds directly from
                 abstract program models, which we obtain from programs
                 by comparatively simple invariant generation and
                 symbolic execution techniques. As a result, we obtain
                 an analysis that is more predictable and more scalable
                 than earlier approaches. We demonstrate by a thorough
                 experimental evaluation that our analysis is fast and
                 at the same time able to compute bounds for challenging
                 loops in a large real-world benchmark. Technically, our
                 approach is based on lossy vector addition systems
                 ({VASS}). Our bound analysis first computes a
                 lexicographic ranking function that proves the
                 termination of a {VASS}, and then derives a bound from
                 this ranking function. Our methodology achieves
                 amortized analysis based on a new insight how
                 lexicographic ranking functions can be used for bound
                 analysis.",
  x-doi =        "10.1007/978-3-319-08867-9\_50",
  x-editor =     "Biere, Armin and Bloem, Roderick",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-319-08867-9\_50",
  xpages =       "745--761",
  year =         "2014",
}

@Article{Hoffmann2012Multivariate,
  author =       "Jan Hoffmann and Klaus Aehlig and Martin Hofmann",
  citeulike-article-id = "12602611",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2362393",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2362389.2362393",
  date-added =   "2014-10-03 00:32:32",
  journal =      "ACM Trans. Program. Lang. Syst.",
  month =        nov,
  number =       "3",
  priority =     "2",
  publisher =    "ACM",
  title =        "Multivariate Amortized Resource Analysis",
  volume =       "34",
  x-abstract =   "We study the problem of automatically analyzing the
                 worst-case resource usage of procedures with several
                 arguments. Existing automatic analyses based on
                 amortization or sized types bound the resource usage or
                 result size of such a procedure by a sum of unary
                 functions of the sizes of the arguments. In this
                 article we generalize this to arbitrary multivariate
                 polynomial functions thus allowing bounds of the form
                 mn which had to be grossly overestimated by m2 \&plus;
                 n2 before. Our framework even encompasses bounds like
                 ∑i,j≤ n mi mj where the mi are the sizes of the
                 entries of a list of length n. This allows us for the
                 first time to derive useful resource bounds for
                 operations on matrices that are represented as lists of
                 lists and to considerably improve bounds on other
                 superlinear operations on lists such as longest common
                 subsequence and removal of duplicates from lists of
                 lists. Furthermore, resource bounds are now closed
                 under composition which improves accuracy of the
                 analysis of composed programs when some or all of the
                 components exhibit superlinear resource or size
                 behavior. The analysis is based on a novel multivariate
                 amortized resource analysis. We present it in form of a
                 type system for a simple first-order functional
                 language with lists and trees, prove soundness, and
                 describe automatic type inference based on linear
                 programming. We have experimentally validated the
                 automatic analysis on a wide range of examples from
                 functional programming with lists and trees. The
                 obtained bounds were compared with actual resource
                 consumption. All bounds were asymptotically tight, and
                 the constants were close or even identical to the
                 optimal ones.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2362389.2362393",
  x-issn =       "0164-0925",
  x-url =        "http://dx.doi.org/10.1145/2362389.2362393",
  year =         "2012",
}

@InProceedings{Magill2010Automatic,
  author =       "Stephen Magill and Ming H. Tsai and Peter Lee and Yih
                 K. Tsay",
  booktitle =    "Proceedings of the 37th annual ACM SIGPLAN-SIGACT
                 Symposium on Principles of Programming Languages",
  citeulike-article-id = "13381195",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1707801.1706326",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1707801.1706326",
  date-added =   "2014-10-03 00:31:34",
  month =        jan,
  number =       "1",
  priority =     "2",
  publisher =    "ACM",
  title =        "Automatic Numeric Abstractions for Heap-manipulating
                 Programs",
  volume =       "45",
  x-abstract =   "We present a logic for relating heap-manipulating
                 programs to numeric abstractions. These numeric
                 abstractions are expressed as simple imperative
                 programs over integer variables and have the property
                 that termination and safety of the numeric program
                 ensures termination and safety of the original,
                 heap-manipulating program. We have implemented an
                 automated version of this abstraction process and
                 present experimental results for programs involving a
                 variety of data structures.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1707801.1706326",
  x-issn =       "0362-1340",
  x-url =        "http://dx.doi.org/10.1145/1707801.1706326",
  xpages =       "211--222",
  year =         "2010",
}

@InProceedings{Goldsmith2007Measuring,
  author =       "Simon F. Goldsmith and Alex S. Aiken and Daniel S.
                 Wilkerson",
  booktitle =    "Proceedings of the the 6th Joint Meeting of the
                 European Software Engineering Conference and the ACM
                 SIGSOFT Symposium on The Foundations of Software
                 Engineering",
  citeulike-article-id = "5287267",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1287681",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1287624.1287681",
  date-added =   "2014-10-03 00:30:24",
  location =     "Dubrovnik, Croatia",
  priority =     "2",
  publisher =    "ACM",
  title =        "Measuring Empirical Computational Complexity",
  x-abstract =   "The standard language for describing the asymptotic
                 behavior of algorithms is theoretical computational
                 complexity. We propose a method for describing the
                 asymptotic behavior of programs in practice by
                 measuring their empirical computational complexity. Our
                 method involves running a program on workloads spanning
                 several orders of magnitude in size, measuring their
                 performance, and fitting these observations to a model
                 that predicts performance as a function of workload
                 size. Comparing these models to the programmer's
                 expectations or to theoretical asymptotic bounds can
                 reveal performance bugs or confirm that a program's
                 performance scales as expected. Grouping and ranking
                 program locations based on these models focuses
                 attention on scalability-critical code. We describe our
                 tool, the Trend Profiler (trend-prof), for constructing
                 models of empirical computational complexity that
                 predict how many times each basic block in a program
                 runs as a linear (y = a + bx) or a powerlaw (y = axb)
                 function of user-specified features of the program's
                 workloads. We ran trend-prof on several large programs
                 and report cases where a program scaled as expected,
                 beat its worst-case theoretical complexity bound, or
                 had a performance bug.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1287624.1287681",
  x-isbn =       "978-1-59593-811-4",
  x-series =     "ESEC-FSE '07",
  x-url =        "http://dx.doi.org/10.1145/1287624.1287681",
  xpages =       "395--404",
  year =         "2007",
}

@InProceedings{Crosby2003Denial,
  author =       "Scott A. Crosby and Dan S. Wallach",
  booktitle =    "Proceedings of the 12th Conference on USENIX Security
                 Symposium - Volume 12",
  citeulike-article-id = "4021705",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1251356",
  date-added =   "2014-10-02 16:55:34",
  location =     "Washington, DC",
  priority =     "2",
  publisher =    "USENIX Association",
  title =        "Denial of Service via Algorithmic Complexity Attacks",
  x-abstract =   "We present a new class of low-bandwidth denial of
                 service attacks that exploit algorithmic deficiencies
                 in many common applications' data structures.
                 Frequently used data structures have {"}average-case{"}
                 expected running time that's far more efficient than
                 the worst case. For example, both binary trees and hash
                 tables can degenerate to linked lists with carefully
                 chosen input. We show how an attacker can effectively
                 compute such input, and we demonstrate attacks against
                 the hash table implementations in two versions of Perl,
                 the Squid web proxy, and the Bro intrusion detection
                 system. Using bandwidth less than a typical dialup
                 modem, we can bring a dedicated Bro server to its
                 knees; after six minutes of carefully chosen packets,
                 our Bro server was dropping as much as 71\% of its
                 traffic and consuming all of its {CPU}. We show how
                 modern universal hashing techniques can yield
                 performance comparable to commonplace hash functions
                 while being provably secure against these attacks.",
  x-address =    "Berkeley, CA, USA",
  x-series =     "SSYM'03",
  x-url =        "http://portal.acm.org/citation.cfm?id=1251356",
  xpages =       "3",
  year =         "2003",
}

@InCollection{Heidegger2010ContractDriven,
  author =       "Phillip Heidegger and Peter Thiemann",
  booktitle =    "Objects, Models, Components, Patterns",
  citeulike-article-id = "13372257",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-642-13953-6\_9",
  citeulike-linkout-1 = "http://link.springer.com/chapter/10.1007/978-3-642-13953-6\_9",
  date-added =   "2014-09-24 01:18:16",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "{Contract-Driven} Testing of {JavaScript} Code",
  x-abstract =   "{JSConTest} is a tool that enhances {JavaScript} with
                 simple, type-like contracts and provides a framework
                 for monitoring and guided random testing of programs
                 against these contracts at the same time. Function
                 contracts in {JSConTest} serve a dual role as
                 specifications of the input/output behavior and as test
                 case generators. Generation of test data for a contract
                 is generally random, but it can be guided by
                 annotations on the contract to achieve higher coverage.
                 Annotations may indicate dependencies among parameters
                 and the result or they may select lightweight program
                 analyses, the results of which influence the choice of
                 test data. A case study substantiates that {JSConTest}
                 finds type-related errors with high probability.",
  x-doi =        "10.1007/978-3-642-13953-6\_9",
  x-editor =     "Vitek, Jan",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-642-13953-6\_9",
  xpages =       "154--172",
  year =         "2010",
}

@InProceedings{export:79160,
  author =       "Michael Barnett and Manuel Fahndrich and Francesco
                 Logozzo and Peli de Halleux and Nikolai Tillmann",
  booktitle =    "Proc. 31st International Conference on Software
                 Engineering (ICSE'2009)",
  citeulike-article-id = "13372256",
  citeulike-linkout-0 = "http://research.microsoft.com/apps/pubs/default.aspx?id=79160",
  date-added =   "2014-09-24 01:10:48",
  month =        may,
  priority =     "2",
  publisher =    "IEEE",
  title =        "Exploiting the Synergy between
                 {Automated-Test}-Generation and
                 {Programming-by-Contract}",
  x-abstract =   "<{p>This} demonstration presents two tools, Code
                 Contracts and Pex, that utilize specification
                 constructs for advanced testing, runtime checking, and
                 static checking of object-oriented .{NET}
                 programs.</p>",
  x-note =       "Research Demonstration",
  x-url =        "http://research.microsoft.com/apps/pubs/default.aspx?id=79160",
  year =         "2009",
}

@InProceedings{Claessen2000QuickCheck,
  author =       "Koen Claessen and John Hughes",
  booktitle =    "Proceedings of the Fifth ACM SIGPLAN International
                 Conference on Functional Programming",
  citeulike-article-id = "2298329",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=351266",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/351240.351266",
  date-added =   "2014-09-24 01:06:52",
  priority =     "2",
  publisher =    "ACM",
  title =        "{QuickCheck}: {A} Lightweight Tool for Random Testing
                 of Haskell Programs",
  x-abstract =   "Quick Check is a tool which aids the Haskell
                 programmer in formulating and testing properties of
                 programs. Properties are described as Haskell
                 functions, and can be automatically tested on random
                 input, but it is also possible to define custom test
                 data generators. We present a number of case studies,
                 in which the tool was successfully used, and also point
                 out some pitfalls to avoid. Random testing is
                 especially suitable for functional programs because
                 properties can be stated at a fine grain. When a
                 function is built from separately tested components,
                 then random testing suffices to obtain good coverage of
                 the definition under test.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/351240.351266",
  x-isbn =       "1-58113-202-6",
  x-series =     "ICFP '00",
  x-url =        "http://dx.doi.org/10.1145/351240.351266",
  xpages =       "268--279",
  year =         "2000",
}

@InProceedings{Klein2010Random,
  author =       "Casey Klein and Matthew Flatt and Robert B. Findler",
  booktitle =    "Proceedings of the ACM International Conference on
                 Object Oriented Programming Systems Languages and
                 Applications",
  citeulike-article-id = "13372252",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1932682.1869505",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1869459.1869505",
  date-added =   "2014-09-24 00:59:53",
  location =     "Reno/Tahoe, Nevada, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "Random Testing for Higher-order, Stateful Programs",
  x-abstract =   "Testing is among the most effective tools available
                 for finding bugs. Still, we know of no automatic
                 technique for generating test cases that expose bugs
                 involving a combination of mutable state and callbacks,
                 even though objects and method overriding set up
                 exactly that combination. For such cases, a test
                 generator must create callbacks or subclasses that
                 aggressively exercise side-effecting operations using
                 combinations of generated objects. This paper presents
                 a new algorithm for randomly testing programs that use
                 state and callbacks. Our algorithm exploits a
                 combination of contracts and environment bindings to
                 guide the test-case generator toward interesting
                 inputs. Our prototype implementation for Racket
                 (formerly {PLT} Scheme) - which has a Java-like class
                 system, but with first-class classes as well as
                 gbeta-like augmentable methods - uncovered dozens of
                 bugs in a well-tested and widely used text-editor
                 library. We describe our approach in a precise, formal
                 notation, borrowing the techniques used to describe
                 operational semantics and type systems. The formalism
                 enables us to provide a compact and self-contained
                 explanation of the core of our technique without the
                 ambiguity usually present in pseudo-code
                 descriptions.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1869459.1869505",
  x-isbn =       "978-1-4503-0203-6",
  x-series =     "OOPSLA '10",
  x-url =        "http://dx.doi.org/10.1145/1869459.1869505",
  xpages =       "555--566",
  year =         "2010",
}

@InProceedings{Bouajjani1997Reachability,
  author =       "Ahmed Bouajjani and Javier Esparza and Oded Maler",
  booktitle =    "CONCUR '97: Concurrency Theory",
  citeulike-article-id = "3857624",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/3-540-63141-0\_10",
  citeulike-linkout-1 = "http://www.springerlink.com/content/q415g87p87k56781",
  citeulike-linkout-2 = "http://link.springer.com/chapter/10.1007/3-540-63141-0\_10",
  date-added =   "2014-08-04 03:04:37",
  journal =      "CONCUR '97: Concurrency Theory",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "Reachability analysis of pushdown automata:
                 Application to model-checking",
  x-abstract =   "We apply the symbolic analysis principle to pushdown
                 systems. We represent (possibly infinite) sets of
                 configurations of such systems by means of finite-state
                 automata. In order to reason in a uniform way about
                 analysis problems involving both existential and
                 universal path quantification (such as model-checking
                 for branching-time logics), we consider the more
                 general class of alternating pushdown systems and use
                 alternating finite-state automata as a representation
                 structure for sets of their configurations. We give a
                 simple and natural procedure to compute sets of
                 predecessors using this representation structure. We
                 incorporate this procedure into the automata-theoretic
                 approach to model-checking to define new model-checking
                 algorithms for pushdown systems against both linear and
                 branching-time properties. From these results we derive
                 upper bounds for several model-checking problems as
                 well as matching lower bounds.",
  x-doi =        "10.1007/3-540-63141-0\_10",
  x-editor =     "Mazurkiewicz, Antoni and Winkowski, J\'{o}zef",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/3-540-63141-0\_10",
  xpages =       "135--150",
  year =         "1997",
}

@Article{Wegman1991Constant,
  author =       "Mark N. Wegman and F. Kenneth Zadeck",
  citeulike-article-id = "225307",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=103136",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/103135.103136",
  date-added =   "2014-08-04 02:30:33",
  journal =      "ACM Trans. Program. Lang. Syst.",
  keywords =     "algorithm, optimization, ssa",
  month =        apr,
  number =       "2",
  priority =     "2",
  publisher =    "ACM",
  title =        "Constant Propagation with Conditional Branches",
  volume =       "13",
  x-abstract =   "Constant propagation is a well-known global flow
                 analysis problem. The goal of constant propagation is
                 to discover values that are constant on all possible
                 executions of a program and to propagate these constant
                 values as far foward through the program as possible.
                 Expressions whose operands are all constants can be
                 evaluated at compile time and the results propagated
                 further. Using the algorithms presented in this paper
                 can produce smaller and faster compiled programs. The
                 same algorithms can be used for other kinds of analyses
                 (e.g., type of determination). We present four
                 algorithms in this paper, all conservitive in the sense
                 that all constants may not be found, but each constant
                 found is constant over all possible executions of the
                 program. These algorithms are among the simplest,
                 fastest, and most powerful global constant propagation
                 algorithms known. We also present a new algorithm that
                 performs a form of interprocedural data flow analysis
                 in which aliasing information is gathered in
                 conjunction with constant progagation. Several variants
                 of this algorithm are considered.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/103135.103136",
  x-issn =       "0164-0925",
  x-url =        "http://dx.doi.org/10.1145/103135.103136",
  xpages =       "181--210",
  year =         "1991",
}

@InProceedings{CousotEtAl-TASE07,
  author =       "Patrick Cousot and Radhia Cousot and J\'{e}r\^{o}me
                 Feret and Laurent Mauborgne and Antoine Min\'{e} and
                 David Monniaux and Xavier Rival",
  booktitle =    "Proc. First IEEE \& IFIP International Symposium on
                 Theoretical Aspects of Software Engineering",
  citeulike-article-id = "13215701",
  date-added =   "2014-08-04 02:23:58",
  keywords =     "abstract-interpretation",
  month =        jun,
  priority =     "2",
  publisher =    "IEEE Computer Society Press, Los Alamitos, California,
                 United States",
  title =        "Varieties of Static Analyzers: {A} Comparison with
                 {A}str\'{e}e, invited paper",
  x-address =    "Shanghai, China",
  x-editor =     "Jifeng, He and Sanders, J.",
  xpages =       "3--17",
  year =         "2007",
}

@InProceedings{Filinski1994Representing,
  author =       "Andrzej Filinski",
  booktitle =    "Proceedings of the 21st ACM SIGPLAN-SIGACT Symposium
                 on Principles of Programming Languages",
  citeulike-article-id = "4838",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=174675.178047",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/174675.178047",
  date-added =   "2014-08-04 02:10:41",
  location =     "Portland, Oregon, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "Representing Monads",
  x-abstract =   "We show that any monad whose unit and extension
                 operations are expressible as purely functional terms
                 can be embedded in a call-by-value language with ”
                 composable continuations”. As part of the
                 development, we extend Meyer and Wand's
                 characterization of the relationship between
                 continuation-passing and direct style to one for
                 continuation-passing vs. general ” monadic” style.
                 We further show that the composable-continuations
                 construct can itself be represented using ordinary,
                 non-composable first-class continuations and a single
                 piece of state. Thus, in the presence of two specific
                 computational effects - storage and escapes - any
                 expressible monadic structure (e.g., nondeterminism as
                 represented by the list monad) can be added as a purely
                 definitional extension, without requiring a
                 reinterpretation of the whole language. The paper
                 includes an implementation of the construction (in
                 Standard {ML} with some New Jersey extensions) and
                 several examples.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/174675.178047",
  x-isbn =       "0-89791-636-0",
  x-series =     "POPL '94",
  x-url =        "http://dx.doi.org/10.1145/174675.178047",
  xpages =       "446--457",
  year =         "1994",
}

@InProceedings{Hardekopf2014Widening,
  author =       "Ben Hardekopf and Ben Wiedermann and Berkeley
                 Churchill and Vineeth Kashyap",
  booktitle =    "Verification, Model Checking, and Abstract
                 Interpretation",
  citeulike-article-id = "13315106",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-642-54013-4\_26",
  citeulike-linkout-1 = "http://link.springer.com/chapter/10.1007/978-3-642-54013-4\_26",
  date-added =   "2014-08-04 01:59:04",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "Widening for {Control-Flow}",
  x-abstract =   "We present a parameterized widening operator that
                 determines the control-flow sensitivity of an analysis,
                 i.e., its flow-sensitivity, context-sensitivity, and
                 path-sensitivity. By instantiating the operator's
                 parameter in different ways, the analysis can be tuned
                 to arbitrary sensitivities without changing the
                 abstract semantics of the analysis itself. Similarly,
                 the analysis can be implemented so that its sensitivity
                 can be tuned without changing the analysis
                 implementation. Thus, the sensitivity is an independent
                 concern, allowing the analysis designer to design and
                 implement the analysis without worrying about its
                 sensitivity and then easily experiment with different
                 sensitivities after the fact. Additionally, we show
                 that the space of control-flow sensitivities induced by
                 this widening operator forms a lattice. The lattice
                 meet and join operators are the product and sum of
                 sensitivities, respectively. They can be used to
                 automatically create new sensitivities from existing
                 ones without manual effort. The sum operation in
                 particular is a novel construction, which creates a new
                 sensitivity less precise than either of its operands
                 but containing elements of both.",
  x-doi =        "10.1007/978-3-642-54013-4\_26",
  x-editor =     "McMillan, KennethL and Rival, Xavier",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-642-54013-4\_26",
  xpages =       "472--491",
  year =         "2014",
}

@InProceedings{Kiselyov2007Delimited,
  author =       "Oleg Kiselyov and Chung-chieh Shan",
  booktitle =    "Modeling and Using Context",
  citeulike-article-id = "4039650",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-540-74255-5\_22",
  citeulike-linkout-1 = "http://www.springerlink.com/content/c72411687q51834v",
  citeulike-linkout-2 = "http://link.springer.com/chapter/10.1007/978-3-540-74255-5\_22",
  date-added =   "2014-08-04 00:08:00",
  journal =      "Modeling and Using Context",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "Delimited Continuations in Operating Systems",
  x-abstract =   "Delimited continuations are the meanings of delimited
                 evaluation contexts in programming languages. We show
                 they offer a uniform view of many scenarios that arise
                 in systems programming, such as a request for a system
                 service, an event handler for input/ output, a snapshot
                 of a process, a file system being read and updated, and
                 a Web page. Explicitly recognizing these uses of
                 delimited continuations helps us design a system of
                 concurrent, isolated transactions where desirable
                 features such as snapshots, undo, copy-on-write,
                 reconciliation, and interposition fall out by default.
                 It also lets us take advantage of efficient
                 implementation techniques from programming-language
                 research. The Zipper File System prototypes these
                 ideas.",
  x-doi =        "10.1007/978-3-540-74255-5\_22",
  x-editor =     "Kokinov, Boicho and Richardson, DanielC and
                 Roth-Berghofer, ThomasR and Vieu, Laure",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-540-74255-5\_22",
  xpages =       "291--302",
  year =         "2007",
}

@InProceedings{Oh2012Design,
  author =       "Hakjoo Oh and Kihong Heo and Wonchan Lee and Woosuk
                 Lee and Kwangkeun Yi",
  booktitle =    "Proceedings of the 33rd ACM SIGPLAN Conference on
                 Programming Language Design and Implementation",
  citeulike-article-id = "13315073",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2254092",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2345156.2254092",
  date-added =   "2014-08-03 23:14:21",
  month =        jun,
  priority =     "2",
  publisher =    "ACM",
  title =        "Design and Implementation of Sparse Global Analyses
                 for {C}-like Languages",
  x-abstract =   "In this article we present a general method for
                 achieving global static analyzers that are precise,
                 sound, yet also scalable. Our method generalizes the
                 sparse analysis techniques on top of the abstract
                 interpretation framework to support relational as well
                 as non-relational semantics properties for C-like
                 languages. We first use the abstract interpretation
                 framework to have a global static analyzer whose
                 scalability is unattended. Upon this underlying sound
                 static analyzer, we add our generalized sparse analysis
                 techniques to improve its scalability while preserving
                 the precision of the underlying analysis. Our framework
                 determines what to prove to guarantee that the
                 resulting sparse version should preserve the precision
                 of the underlying analyzer. We formally present our
                 framework; we present that existing sparse analyses are
                 all restricted instances of our framework; we show more
                 semantically elaborate design examples of sparse
                 non-relational and relational static analyses; we
                 present their implemen- tation results that scale to
                 analyze up to one million lines of C programs. We also
                 show a set of implementation techniques that turn out
                 to be critical to economically support the sparse
                 analysis process.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2345156.2254092",
  x-issn =       "0362-1340",
  x-url =        "http://dx.doi.org/10.1145/2345156.2254092",
  xpages =       "229--238",
  year =         "2012",
}

@InProceedings{Reif1977Symbolic,
  author =       "John H. Reif and Harry R. Lewis",
  booktitle =    "Proceedings of the 4th ACM SIGACT-SIGPLAN Symposium on
                 Principles of Programming Languages",
  citeulike-article-id = "3353403",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=512961",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/512950.512961",
  date-added =   "2014-08-03 23:10:25",
  location =     "Los Angeles, California",
  priority =     "2",
  publisher =    "ACM",
  title =        "Symbolic Evaluation and the Global Value Graph",
  x-abstract =   "This paper is concerned with difficult global flow
                 problems which require the symbolic evaluation of
                 programs. We use, as is common in global flow analysis,
                 a model in which the expressions computed are
                 specified, but the flow of control is indicated only by
                 a directed graph whose nodes are blocks of assignment
                 statements. We show that if such a program model is
                 interpreted in the domain of integer arithmetic then
                 many natural global flow problems are unsolvable. We
                 then develop a direct (non-iterative) method for
                 finding general symbolic values for program
                 expressions. Our method gives results similar to an
                 iterative method due to Kildall and a direct method due
                 to Fong, Kam, and Ullman. By means of a structure
                 called the global value graph which compactly
                 represents both symbolic values and the flow of these
                 values through the program, we are able to obtain
                 results that are as strong as either of these
                 algorithms at a lower time cost, while retaining
                 applicability to all flow graphs.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/512950.512961",
  x-series =     "POPL '77",
  x-url =        "http://dx.doi.org/10.1145/512950.512961",
  xpages =       "104--118",
  year =         "1977",
}

@InProceedings{Salvati2011Krivine,
  author =       "S. Salvati and I. Walukiewicz",
  booktitle =    "Proceedings of the 38th International Conference on
                 Automata, Languages and Programming",
  citeulike-article-id = "13315068",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2027239",
  date-added =   "2014-08-03 22:59:57",
  location =     "Zurich, Switzerland",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "Krivine Machines and Higher-order Schemes",
  x-abstract =   "We propose a new approach to analysing higher-order
                 recursive schemes. Many results in the literature use
                 automata models generalising pushdown automata, most
                 notably higher-order pushdown automata with collapse
                 ({CPDA}). Instead, we propose to use the Krivine
                 machine model. Compared to {CPDA}, this model is closer
                 to lambda-calculus, and incorporates nicely many
                 invariants of computations, as for example the typing
                 information. The usefulness of the proposed approach is
                 demonstrated with new proofs of two central results in
                 the field: the decidability of the local and global
                 model checking problems for higher-order schemes with
                 respect to the mu-calculus.",
  x-address =    "Berlin, Heidelberg",
  x-isbn =       "978-3-642-22011-1",
  x-series =     "ICALP'11",
  x-url =        "http://portal.acm.org/citation.cfm?id=2027239",
  xpages =       "162--173",
  year =         "2011",
}

@InCollection{Schwoon2005Note,
  author =       "Stefan Schwoon and Javier Esparza",
  booktitle =    "Tools and Algorithms for the Construction and Analysis
                 of Systems",
  citeulike-article-id = "13315065",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-540-31980-1\_12",
  citeulike-linkout-1 = "http://link.springer.com/chapter/10.1007/978-3-540-31980-1\_12",
  date-added =   "2014-08-03 22:52:17",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "A Note on {On-the-Fly} Verification Algorithms",
  x-abstract =   "The automata-theoretic approach to {LTL} verification
                 relies on an algorithm for finding accepting cycles in
                 a B{\"{u}}chi automaton. Explicit-state model checkers
                 typically construct the automaton ” on the fly” and
                 explore its states using depth-first search. We survey
                 algorithms proposed for this purpose and identify two
                 good algorithms, a new algorithm based on nested {DFS},
                 and another based on strongly connected components. We
                 compare these algorithms both theoretically and
                 experimentally and determine cases where both
                 algorithms can be useful.",
  x-doi =        "10.1007/978-3-540-31980-1\_12",
  x-editor =     "Halbwachs, Nicolas and Zuck, LenoreD",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-540-31980-1\_12",
  xpages =       "174--190",
  year =         "2005",
}

@InProceedings{Shivers2011Modular,
  author =       "Olin Shivers and Aaron J. Turon",
  booktitle =    "Proceedings of the 16th ACM SIGPLAN International
                 Conference on Functional Programming",
  citeulike-article-id = "13315061",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2034773.2034783",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2034773.2034783",
  date-added =   "2014-08-03 22:42:22",
  location =     "Tokyo, Japan",
  priority =     "2",
  publisher =    "ACM",
  title =        "Modular Rollback Through Control Logging: {A} Pair of
                 Twin Functional Pearls",
  x-abstract =   "We present a technique, based on the use of
                 first-class control operators, enabling programs to
                 maintain and invoke rollback logs for sequences of
                 reversible effects. Our technique is modular, in that
                 it provides complete separation between some library of
                 effectful operations, and a client, {"}driver{"}
                 program which invokes and rolls back sequences of these
                 operations. In particular, the checkpoint mechanism,
                 which is entirely encapsulated within the effect
                 library, logs not only the library's effects, but also
                 the client's control state. Thus, logging and rollback
                 can be almost completely transparent to the client
                 code. This separation of concerns manifests itself
                 nicely when we must implement software with
                 sophisticated error handling. We illustrate with two
                 examples that exploit the architecture to disentangle
                 some core parsing task from its error management. The
                 parser code is completely separate from the
                 error-correction code, although the two components are
                 deeply intertwined at run time.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2034773.2034783",
  x-isbn =       "978-1-4503-0865-6",
  x-series =     "ICFP '11",
  x-url =        "http://dx.doi.org/10.1145/2034773.2034783",
  xpages =       "58--68",
  year =         "2011",
}

@InProceedings{Ong2011Verifying,
  author =       "C. H. Luke Ong and Steven J. Ramsay",
  booktitle =    "Proceedings of the 38th annual ACM SIGPLAN-SIGACT
                 Symposium on Principles of Programming Languages",
  citeulike-article-id = "13231111",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1926453",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1925844.1926453",
  date-added =   "2014-06-17 15:43:43",
  month =        jan,
  priority =     "2",
  publisher =    "ACM",
  title =        "Verifying Higher-order Functional Programs with
                 Pattern-matching Algebraic Data Types",
  x-abstract =   "Type-based model checking algorithms for higher-order
                 recursion schemes have recently emerged as a promising
                 approach to the verification of functional programs. We
                 introduce pattern-matching recursion schemes ({PMRS})
                 as an accurate model of computation for functional
                 programs that manipulate algebraic data-types. {PMRS}
                 are a natural extension of higher-order recursion
                 schemes that incorporate pattern-matching in the
                 defining rules. This paper is concerned with the
                 following (undecidable) verification problem: given a
                 correctness property φ, a functional program ℘ (qua
                 {PMRS}) and a regular input set ℑ, does every term
                 that is reachable from ℑ under rewriting by ℘
                 satisfy φ? To solve the {PMRS} verification problem,
                 we present a sound semi-algorithm which is based on
                 model-checking and counterexample guided abstraction
                 refinement. Given a no-instance of the verification
                 problem, the method is guaranteed to terminate. From an
                 order-n {PMRS} and an input set generated by a regular
                 tree grammar, our method constructs an order-n weak
                 {PMRS} which over-approximates only the first-order
                 pattern-matching behaviour, whilst remaining completely
                 faithful to the higher-order control flow. Using a
                 variation of Kobayashi's type-based approach, we show
                 that the (trivial automaton) model-checking problem for
                 weak {PMRS} is decidable. When a violation of the
                 property is detected in the abstraction which does not
                 correspond to a violation in the model, the abstraction
                 is automatically refined by `unfolding' the
                 pattern-matching rules in the program to give
                 successively more and more accurate weak {PMRS}
                 models.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1925844.1926453",
  x-issn =       "0362-1340",
  x-series =     "POPL",
  x-url =        "http://dx.doi.org/10.1145/1925844.1926453",
  xpages =       "587--598",
  year =         "2011",
}

@InProceedings{Ngo2007Detecting,
  author =       "Minh N. Ngo and Hee Beng Kuan Tan",
  booktitle =    "Proceedings of the the 6th Joint Meeting of the
                 European Software Engineering Conference and the ACM
                 SIGSOFT Symposium on The Foundations of Software
                 Engineering",
  citeulike-article-id = "13231088",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1287655",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1287624.1287655",
  date-added =   "2014-06-17 14:45:34",
  location =     "Dubrovnik, Croatia",
  priority =     "2",
  publisher =    "ACM",
  title =        "Detecting Large Number of Infeasible Paths Through
                 Recognizing Their Patterns",
  x-abstract =   "A great majority of program paths are found to be
                 infeasible, which in turn make static analysis overly
                 conservative. As static analysis plays a central part
                 in many software engineering activities, knowledge
                 about infeasible program paths can be used to greatly
                 improve the performance of these activities especially
                 structural testing and coverage analysis. In this
                 paper, we present an empirical approach to the problem
                 of infeasible path detection. We have discovered that
                 many infeasible paths exhibit some common properties
                 which are caused by four code patterns including
                 identical/complement-decision,
                 mutually-exclusive-decision, check-then-do and
                 looping-by-flag pattern. Through realizing these
                 properties from source code, many infeasible paths can
                 be precisely detected. Binomial tests have been
                 conducted which give strong statistical evidences to
                 support the validity of the empirical properties. Our
                 experimental results show that even with some
                 limitations in the current prototype tool, the proposed
                 approach accurately detects 82.3\% of all the
                 infeasible paths.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1287624.1287655",
  x-isbn =       "978-1-59593-811-4",
  x-series =     "ESEC-FSE '07",
  x-url =        "http://dx.doi.org/10.1145/1287624.1287655",
  xpages =       "215--224",
  year =         "2007",
}

@Article{King1975New,
  author =       "James C. King",
  citeulike-article-id = "13231087",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=800027.808444",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/390016.808444",
  date-added =   "2014-06-17 14:39:05",
  journal =      "SIGPLAN Not.",
  month =        apr,
  number =       "6",
  priority =     "2",
  publisher =    "ACM",
  title =        "A New Approach to Program Testing",
  volume =       "10",
  x-abstract =   "The current approach for testing a program is, in
                 principle, quite primitive. Some small sample of the
                 data that a program is expected to handle is presented
                 to the program. If the program produces correct results
                 for the sample, it is assumed to be correct. Much
                 current work focuses on the question of how to choose
                 this sample. We propose that a program can be more
                 effectively tested by executing it {"}symbolically.{"}
                 Instead of supplying specific constants as input values
                 to a program being tested, one supplies symbols. The
                 normal computational definitions for the basic
                 operations performed by a program can be expanded to
                 accept symbolic inputs and produce symbolic formulae as
                 output. If the flow of control in the program is
                 completely independent of its input parameters, then
                 all output values can be symbolically computed as
                 formulae over the symbolic inputs and examined for
                 correctness. When the control flow of the program is
                 input dependent, a case analysis can be performed
                 producing output formulae for each class of inputs
                 determined by the control flow dependencies. Using
                 these ideas, we have designed and implemented an
                 interactive debugging/testing system called {EFFIGY}.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/390016.808444",
  x-issn =       "0362-1340",
  x-url =        "http://dx.doi.org/10.1145/390016.808444",
  xpages =       "228--233",
  year =         "1975",
}

@InProceedings{Chen2003Mirror,
  author =       "T. Y. Chen and F. C. Kuo and R. G. Merkel and S. P.
                 Ng",
  booktitle =    "Proceedings of the Third International Conference on
                 Quality Software",
  citeulike-article-id = "13231084",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=951282",
  date-added =   "2014-06-17 14:36:01",
  priority =     "2",
  publisher =    "IEEE Computer Society",
  title =        "Mirror Adaptive Random Testing",
  x-abstract =   "Adaptive random testing ({ART}) has recently
                 beenintroduced to improve the fault-detection
                 effectivenessof random testing ({RT}) for certain types
                 of failure-causingpatterns. However, {ART} requires
                 extracomputations to ensure an even spread of test
                 cases,which may render {ART} to be less cost-effective
                 than {RT}.In this paper, we introduce an innovative
                 approach,namely Mirror Adaptive Random Testing
                 ({MART}), toreduce these computations. Our simulation
                 resultsclearly show that {MART} does improve the
                 cost-effectivenessof {ART}.",
  x-address =    "Washington, DC, USA",
  x-isbn =       "0-7695-2015-4",
  x-series =     "QSIC '03",
  x-url =        "http://portal.acm.org/citation.cfm?id=951282",
  year =         "2003",
}

@Article{Chen2010Adaptive,
  author =       "Tsong Y. Chen and Fei-Ching Kuo and Robert G. Merkel
                 and T. H. Tse",
  citeulike-article-id = "13231083",
  citeulike-linkout-0 = "http://dx.doi.org/10.1016/j.jss.2009.02.022",
  date-added =   "2014-06-17 14:35:01",
  journal =      "Journal of Systems and Software",
  month =        jan,
  number =       "1",
  priority =     "2",
  title =        "Adaptive Random Testing: The {ART} of test case
                 diversity",
  volume =       "83",
  x-abstract =   "Random testing is not only a useful testing technique
                 in itself, but also plays a core role in many other
                 testing methods. Hence, any significant improvement to
                 random testing has an impact throughout the software
                 testing community. Recently, Adaptive Random Testing
                 ({ART}) was proposed as an effective alternative to
                 random testing. This paper presents a synthesis of the
                 most important research results related to {ART}. In
                 the course of our research and through further
                 reflection, we have realised how the techniques and
                 concepts of {ART} can be applied in a much broader
                 context, which we present here. We believe such ideas
                 can be applied in a variety of areas of software
                 testing, and even beyond software testing. Amongst
                 these ideas, we particularly note the fundamental role
                 of diversity in test case selection strategies. We hope
                 this paper serves to provoke further discussions and
                 investigations of these ideas.",
  x-doi =        "10.1016/j.jss.2009.02.022",
  x-issn =       "01641212",
  x-url =        "http://dx.doi.org/10.1016/j.jss.2009.02.022",
  xpages =       "60--66",
  year =         "2010",
}

@Article{Cohen2008Constructing,
  author =       "Myra B. Cohen and Matthew B. Dwyer and Jiangfan Shi",
  booktitle =    "Software Engineering, IEEE Transactions on",
  citeulike-article-id = "5043174",
  citeulike-linkout-0 = "http://doi.ieeecomputersociety.org/10.1109/TSE.2008.50",
  citeulike-linkout-1 = "http://dx.doi.org/10.1109/tse.2008.50",
  citeulike-linkout-2 = "http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4564473",
  date-added =   "2014-06-17 14:33:09",
  day =          "27",
  journal =      "IEEE Transactions on Software Engineering",
  month =        jun,
  number =       "5",
  priority =     "2",
  publisher =    "IEEE Computer Society",
  title =        "Constructing Interaction Test Suites for
                 {Highly-Configurable} Systems in the Presence of
                 Constraints: {A} Greedy Approach",
  volume =       "34",
  x-abstract =   "Researchers have explored the application of
                 combinatorial interaction testing ({CIT}) methods to
                 construct samples to drive systematic testing of
                 software system configurations. Applying {CIT} to
                 highly-configurable software systems is complicated by
                 the fact that, in many such systems, there are
                 constraints between specific configuration parameters
                 that render certain combinations invalid. Many {CIT}
                 algorithms lack a mechanism to avoid these. In recent
                 work, automated constraint solving methods have been
                 combined with search-based {CIT} construction methods
                 to address the constraint problem with promising
                 results. However, these techniques can incur a
                 non-trivial overhead. In this paper, we build upon our
                 previous work to develop a family of greedy {CIT}
                 sample generation algorithms that exploit calculations
                 made by modern boolean satisfiability ({SAT}) solvers
                 to prune the search space of the {CIT} problem. We
                 perform a comparative evaluation of the
                 cost-effectiveness of these algorithms on four
                 real-world highly-configurable software systems and on
                 a population of synthetic examples that share the
                 characteristics of those systems. In combination our
                 techniques reduce the cost of {CIT} in the presence of
                 constraints to 30\% of the cost of widely-used
                 unconstrained {CIT} methods without sacrificing the
                 quality of the solutions.",
  x-doi =        "10.1109/tse.2008.50",
  x-url =        "http://dx.doi.org/10.1109/tse.2008.50",
  xpages =       "633--650",
  year =         "2008",
}

@InCollection{Brinksma2001Testing,
  author =       "Ed Brinksma and Jan Tretmans",
  booktitle =    "Modeling and Verification of Parallel Processes",
  citeulike-article-id = "2505475",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/3-540-45510-8\_9",
  citeulike-linkout-1 = "http://link.springer.com/chapter/10.1007/3-540-45510-8\_9",
  date-added =   "2014-06-17 14:30:28",
  journal =      "Modeling and Verification of Parallel Processes",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "Testing Transition Systems: An Annotated
                 Bibliography",
  volume =       "2067",
  x-abstract =   "Labelled transition system based test theory has made
                 remarkable progress over the past 15 years. From a
                 theoretically interesting approach to the semantics of
                 reactive systems it has developed into a field where
                 testing theory is (slowly) narrowing the gap with
                 testing practice. In particular, new test generation
                 algorithms are being designed that can be used in
                 realistic situations whilst maintaining a sound
                 theoretical basis. In this paper we present an
                 annotated bibliography of labelled transition system
                 based test theory and its applications covering the
                 main developments.",
  x-doi =        "10.1007/3-540-45510-8\_9",
  x-editor =     "Cassez, Franck and Jard, Claude and Rozoy, Brigitte
                 and Ryan, MarkDermot",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/3-540-45510-8\_9",
  xpages =       "187--195",
  year =         "2001",
}

@Article{Lee1996Principles,
  author =       "David Lee and Mihalis Yannakakis",
  booktitle =    "Proceedings of the IEEE",
  citeulike-article-id = "3404075",
  citeulike-linkout-0 = "http://dx.doi.org/10.1109/5.533956",
  citeulike-linkout-1 = "http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=533956",
  date-added =   "2014-06-17 14:28:35",
  institution =  "AT\&T Bell Labs., Murray Hill, NJ, USA",
  journal =      "Proceedings of the IEEE",
  keywords =     "finite-state-machine, lecture-vts, reactive-language,
                 testing",
  month =        aug,
  number =       "8",
  priority =     "2",
  publisher =    "IEEE",
  title =        "Principles and methods of testing finite state
                 machines-a survey",
  volume =       "84",
  x-abstract =   "With advanced computer technology, systems are getting
                 larger to fulfill more complicated tasks: however, they
                 are also becoming less reliable. Consequently, testing
                 is an indispensable part of system design and
                 implementation; yet it has proved to be a formidable
                 task for complex systems. This motivates the study of
                 testing finite stare machines to ensure the correct
                 functioning of systems and to discover aspects of their
                 behavior. A finite state machine contains a finite
                 number of states and produces outputs on state
                 transitions after receiving inputs. Finite state
                 machines are widely used to model systems in diverse
                 areas, including sequential circuits, certain types of
                 programs, and, more recently, communication protocols.
                 In a testing problem we have a machine about which we
                 lack some information; we would like to deduce this
                 information by providing a sequence of inputs to the
                 machine and observing the outputs produced. Because of
                 its practical importance and theoretical interest, the
                 problem of testing finite state machines has been
                 studied in different areas and at various times. The
                 earliest published literature on this topic dates back
                 to the 1950's. Activities in the 1960's mid early
                 1970's were motivated mainly by automata theory and
                 sequential circuit testing. The area seemed to have
                 mostly died down until a few years ago when the testing
                 problem was resurrected and is now being studied anew
                 due to its applications to conformance testing of
                 communication protocols. While some old problems which
                 had been open for decades were resolved recently, new
                 concepts and more intriguing problems from new
                 applications emerge. We review the fundamental problems
                 in testing finite state machines and techniques for
                 solving these problems, tracing progress in the area
                 from its inception to the present and the stare of the
                 art. In addition, we discuss extensions of finite state
                 machines and some other topics related to testing",
  x-doi =        "10.1109/5.533956",
  x-issn =       "0018-9219",
  x-url =        "http://dx.doi.org/10.1109/5.533956",
  xpages =       "1090--1123",
  year =         "1996",
}

@InCollection{Xie2005Symstra,
  author =       "Tao Xie and Darko Marinov and Wolfram Schulte and
                 David Notkin",
  booktitle =    "Tools and Algorithms for the Construction and Analysis
                 of Systems",
  chapter =      "24",
  citeulike-article-id = "1869884",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-540-31980-1\_24",
  citeulike-linkout-1 = "http://www.springerlink.com/content/4d3vv767nvtmh9hk",
  citeulike-linkout-2 = "http://link.springer.com/chapter/10.1007/978-3-540-31980-1\_24",
  date-added =   "2014-06-17 14:27:22",
  journal =      "Tools and Algorithms for the Construction and Analysis
                 of Systems",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "Symstra: {A} Framework for Generating
                 {Object-Oriented} Unit Tests Using Symbolic Execution",
  volume =       "3440",
  x-abstract =   "Object-oriented unit tests consist of sequences of
                 method invocations. Behavior of an invocation depends
                 on the method's arguments and the state of the receiver
                 at the beginning of the invocation. Correspondingly,
                 generating unit tests involves two tasks: generating
                 method sequences that build relevant receiver-object
                 states and generating relevant method arguments. This
                 paper proposes Symstra, a framework that achieves both
                 test generation tasks using symbolic execution of
                 method sequences with symbolic arguments. The paper
                 defines symbolic states of object-oriented programs and
                 novel comparisons of states. Given a set of methods
                 from the class under test and a bound on the length of
                 sequences, Symstra systematically explores the
                 object-state space of the class and prunes this
                 exploration based on the state comparisons.
                 Experimental results show that Symstra generates unit
                 tests that achieve higher branch coverage faster than
                 the existing test-generation techniques based on
                 concrete method arguments.",
  x-address =    "Berlin, Heidelberg",
  x-doi =        "10.1007/978-3-540-31980-1\_24",
  x-editor =     "Halbwachs, Nicolas and Zuck, LenoreD",
  x-isbn =       "978-3-540-25333-4",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-540-31980-1\_24",
  xpages =       "365--381",
  year =         "2005",
}

@Article{Anand2013Orchestrated,
  author =       "Saswat Anand and Edmund K. Burke and Tsong Y. Chen and
                 John Clark and Myra B. Cohen and Wolfgang Grieskamp and
                 Mark Harman and Mary J. Harrold and Phil McMinn",
  citeulike-article-id = "13231079",
  citeulike-linkout-0 = "http://dx.doi.org/10.1016/j.jss.2013.02.061",
  date-added =   "2014-06-17 14:23:29",
  journal =      "Journal of Systems and Software",
  month =        aug,
  number =       "8",
  priority =     "2",
  title =        "An orchestrated survey of methodologies for automated
                 software test case generation",
  volume =       "86",
  x-abstract =   "We present an orchestrated survey of the most
                 prominent techniques for automatic generation of
                 software test cases. The survey covers symbolic
                 execution, model-based, combinatorial, search-based and
                 adaptive random testing techniques. For each technique,
                 basic concepts and research challenges are reported,
                 and future research directions are envisioned. Each
                 technique is surveyed by a world renowned expert(s) and
                 active researcher(s) on the topic in a self-contained
                 section. The experts' contributions were coordinated
                 and the paper was edited by the orchestrators/editors
                 into a consistent paper. Test case generation is among
                 the most labour-intensive tasks in software testing. It
                 also has a strong impact on the effectiveness and
                 efficiency of software testing. For these reasons, it
                 has been one of the most active research topics in
                 software testing for several decades, resulting in many
                 different approaches and tools. This paper presents an
                 orchestrated survey of the most prominent techniques
                 for automatic generation of software test cases,
                 reviewed in self-standing sections. The techniques
                 presented include: (a) structural testing using
                 symbolic execution, (b) model-based testing, (c)
                 combinatorial testing, (d) random testing and its
                 variant of adaptive random testing, and (e)
                 search-based testing. Each section is contributed by
                 world-renowned active researchers on the technique, and
                 briefly covers the basic ideas underlying the method,
                 the current state of the art, a discussion of the open
                 research problems, and a perspective of the future
                 development of the approach. As a whole, the paper aims
                 at giving an introductory, up-to-date and (relatively)
                 short overview of research in automatic test case
                 generation, while ensuring a comprehensive and
                 authoritative treatment.",
  x-doi =        "10.1016/j.jss.2013.02.061",
  x-issn =       "01641212",
  x-url =        "http://dx.doi.org/10.1016/j.jss.2013.02.061",
  xpages =       "1978--2001",
  year =         "2013",
}

@InCollection{Rushby2008Automated,
  author =       "John Rushby",
  booktitle =    "Verified Software: Theories, Tools, Experiments",
  citeulike-article-id = "13231073",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-540-69149-5\_18",
  citeulike-linkout-1 = "http://link.springer.com/chapter/10.1007/978-3-540-69149-5\_18",
  date-added =   "2014-06-17 14:17:34",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "Automated Test Generation and Verified Software",
  volume =       "4171",
  x-abstract =   "Testing remains the principal means of verification in
                 commercial practice and in many certification regimes.
                 Formal methods of verification will coexist with
                 testing and should be developed in ways that improve,
                 supplement, and exploit the value of testing. I
                 describe automated test generation, which uses
                 technology from formal methods to mechanize the
                 construction of test cases, and discuss some of the
                 research challenges in this area.",
  x-doi =        "10.1007/978-3-540-69149-5\_18",
  x-editor =     "Meyer, Bertrand and Woodcock, Jim",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-540-69149-5\_18",
  xpages =       "161--172",
  year =         "2008",
}

@Article{Johnson2014Pushdown,
  author =       "J. Ian Johnson and Ilya Sergey and Christopher Earl
                 and Matthew Might and David Van Horn",
  citeulike-article-id = "13214892",
  citeulike-linkout-0 = "http://journals.cambridge.org/action/displayAbstract?fromPage=online\&aid=9262409",
  citeulike-linkout-1 = "http://dx.doi.org/10.1017/s0956796814000100",
  date-added =   "2014-06-06 22:21:24",
  journal =      "Journal of Functional Programming",
  month =        may,
  priority =     "2",
  title =        "Pushdown flow analysis with abstract garbage
                 collection",
  volume =       "24",
  x-abstract =   "In the static analysis of functional programs,
                 pushdown flow analysis and abstract garbage collection
                 push the boundaries of what we can learn about programs
                 statically. This work illuminates and poses solutions
                 to theoretical and practical challenges that stand in
                 the way of combining the power of these techniques.
                 Pushdown flow analysis grants unbounded yet computable
                 polyvariance to the analysis of return-flow in
                 higher-order programs. garbage collection grants
                 unbounded polyvariance to abstract addresses which
                 become unreachable between invocations of the abstract
                 contexts in which they were created. Pushdown analysis
                 solves the problem of precisely analyzing recursion in
                 higher-order languages; abstract garbage collection is
                 essential in solving the ” stickiness” problem.
                 Alone, our benchmarks demonstrate that each method can
                 reduce analysis times and boost precision by orders of
                 magnitude. We combine these methods. The challenge in
                 marrying these techniques is not subtle: computing the
                 reachable control states of a pushdown system relies on
                 limiting access during transition to the top of the
                 stack; abstract garbage collection, on the other hand,
                 needs full access to the entire stack to compute a root
                 set, just as concrete collection does. Conditional
                 pushdown systems were developed for just such a
                 conundrum, but existing methods are ill-suited for the
                 dynamic nature of garbage collection. We show fully
                 precise and approximate solutions to the feasible paths
                 problem for pushdown garbage-collecting control-flow
                 analysis. Experiments reveal synergistic interplay
                 between garbage collection and pushdown techniques, and
                 the fusion demonstrates ” better-than-both-worlds”
                 precision.",
  x-doi =        "10.1017/s0956796814000100",
  x-issn =       "1469-7653",
  x-url =        "http://dx.doi.org/10.1017/s0956796814000100",
  xpages =       "218--283",
  year =         "2014",
}

@InProceedings{Reps1995Precise,
  author =       "Thomas Reps and Susan Horwitz and Mooly Sagiv",
  booktitle =    "Proceedings of the 22nd ACM SIGPLAN-SIGACT Symposium
                 on Principles of Programming Languages",
  citeulike-article-id = "778826",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=199462",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/199448.199462",
  date-added =   "2014-06-06 22:13:27",
  location =     "San Francisco, California, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "Precise Interprocedural Dataflow Analysis via Graph
                 Reachability",
  x-abstract =   "The paper shows how a large class of interprocedural
                 dataflow-analysis problems can be solved precisely in
                 polynomial time by transforming them into a special
                 kind of graph-reachability problem. The only
                 restrictions are that the set of dataflow facts must be
                 a finite set, and that the dataflow functions must
                 distribute over the confluence operator (either union
                 or intersection). This class of probable problems
                 includes—but is not limited to—the classical
                 separable problems (also known as ” gen/kill” or
                 ” bit-vector” problems)—e.g., reaching
                 definitions, available expressions, and live variables.
                 In addition, the class of problems that our techniques
                 handle includes many non-separable problems, including
                 truly-live variables, copy constant propagation, and
                 possibly-uninitialized {variables.Results} are reported
                 from a preliminary experimental study of C programs
                 (for the problem of finding possibly-uninitialized
                 variables).",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/199448.199462",
  x-isbn =       "0-89791-692-1",
  x-series =     "POPL '95",
  x-url =        "http://dx.doi.org/10.1145/199448.199462",
  xpages =       "49--61",
  year =         "1995",
}

@InProceedings{Ernst2006Daikon,
  author =       "Michael D. Ernst and Jeff H. Perkins and Philip J. Guo
                 and Stephen Mccamant and Carlos Pacheco and Matthew S.
                 Tschantz and Chen Xiao",
  booktitle =    "Science of Computer Programming",
  citeulike-article-id = "13138627",
  citeulike-linkout-0 = "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.89.1548",
  date-added =   "2014-04-15 14:04:51",
  priority =     "2",
  title =        "The Daikon system for dynamic detection of likely
                 invariants",
  x-abstract =   "Daikon is an implementation of dynamic detection of
                 likely invariants; that is, the Daikon invariant
                 detector reports likely program invariants. An
                 invariant is a property that holds at a certain point
                 or points in a program; these are often used in assert
                 statements, documentation, and formal specifications.
                 Examples include being constant (x = a), non-zero (x
                 {\"{i}}¿½ = 0), being in a range (a \^{a}¤ x
                 \^{a}¤ b), linear relationships (y = ax + b),
                 ordering (x \^{a}¤ y), functions from a library (x =
                 fn(y)), containment (x \^{a} y), sortedness (x is
                 sorted), and many more. Users can extend Daikon to
                 check for additional invariants. Dynamic invariant
                 detection runs a program, observes the values that the
                 program computes, and then reports properties that were
                 true over the observed executions. Dynamic invariant
                 detection is a machine learning technique that can be
                 applied to arbitrary data. Daikon can detect invariants
                 in C, C++, Java, and Perl programs, and in
                 record-structured data sources; it is easy to extend
                 Daikon to other applications. Invariants can be useful
                 in program understanding and a host of other
                 applications. Daikon\^{a}s output has been used for
                 generating test cases, predicting incompatibilities in
                 component integration, automating theorem-proving,
                 repairing inconsistent data structures, and checking
                 the validity of data streams, among other tasks. Daikon
                 is freely available in source and binary form, along
                 with extensive documentation,",
  x-url =        "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.89.1548",
  year =         "2006",
}

@InProceedings{Johnson2013Optimizing,
  author =       "J. Ian Johnson and Nicholas Labich and Matthew Might
                 and David Van{ }Horn",
  booktitle =    "Proceedings of the 18th ACM SIGPLAN International
                 Conference on Functional Programming",
  citeulike-article-id = "13138099",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2500604",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2500365.2500604",
  date-added =   "2014-04-14 20:55:17",
  location =     "Boston, Massachusetts, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "Optimizing Abstract Abstract Machines",
  x-abstract =   "The technique of abstracting abstract machines ({AAM})
                 provides a systematic approach for deriving computable
                 approximations of evaluators that are easily proved
                 sound. This article contributes a complementary
                 step-by-step process for subsequently going from a
                 naive analyzer derived under the {AAM} approach, to an
                 efficient and correct implementation. The end result of
                 the process is a two to three order-of-magnitude
                 improvement over the systematically derived analyzer,
                 making it competitive with hand-optimized
                 implementations that compute fundamentally less precise
                 results.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2500365.2500604",
  x-isbn =       "978-1-4503-2326-0",
  x-series =     "ICFP '13",
  x-url =        "http://dx.doi.org/10.1145/2500365.2500604",
  xpages =       "443--454",
  year =         "2013",
}

@InProceedings{Necula1997Proofcarrying,
  author =       "George C. Necula",
  booktitle =    "Proceedings of the 24th ACM SIGPLAN-SIGACT Symposium
                 on Principles of Programming Languages",
  citeulike-article-id = "1102230",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=263712",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/263699.263712",
  date-added =   "2014-03-23 18:56:22",
  location =     "Paris, France",
  priority =     "2",
  publisher =    "ACM",
  title =        "Proof-carrying Code",
  x-abstract =   "An abstract is not available.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/263699.263712",
  x-isbn =       "0-89791-853-3",
  x-series =     "POPL '97",
  x-url =        "http://dx.doi.org/10.1145/263699.263712",
  xpages =       "106--119",
  year =         "1997",
}

@Article{Shao2010Certified,
  author =       "Zhong Shao",
  citeulike-article-id = "13114912",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1859226",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1859204.1859226",
  date-added =   "2014-03-23 18:50:50",
  journal =      "Commun. ACM",
  month =        dec,
  number =       "12",
  priority =     "2",
  publisher =    "ACM",
  title =        "Certified Software",
  volume =       "53",
  x-abstract =   "Only if the programmer can prove (through formal
                 machine-checkable proofs) it is free of bugs with
                 respect to a claim of dependability.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1859204.1859226",
  x-issn =       "0001-0782",
  x-url =        "http://dx.doi.org/10.1145/1859204.1859226",
  xpages =       "56--66",
  year =         "2010",
}

@Article{Klein2010SeL4,
  author =       "Gerwin Klein and June Andronick and Kevin Elphinstone
                 and Gernot Heiser and David Cock and Philip Derrin and
                 Dhammika Elkaduwe and Kai Engelhardt and Rafal Kolanski
                 and Michael Norrish and Thomas Sewell and Harvey Tuch
                 and Simon Winwood",
  citeulike-article-id = "9621433",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1743574",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1743546.1743574",
  date-added =   "2014-03-23 18:29:04",
  journal =      "Commun. ACM",
  month =        jun,
  number =       "6",
  priority =     "2",
  publisher =    "ACM",
  title =        "{seL4}: Formal Verification of an Operating-system
                 Kernel",
  volume =       "53",
  x-abstract =   "An abstract is not available.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1743546.1743574",
  x-issn =       "0001-0782",
  x-url =        "http://dx.doi.org/10.1145/1743546.1743574",
  xpages =       "107--115",
  year =         "2010",
}

@Article{Leroy2009Formal,
  author =       "Xavier Leroy",
  citeulike-article-id = "5918113",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1538788.1538814",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1538788.1538814",
  date-added =   "2014-03-23 18:27:44",
  journal =      "Commun. ACM",
  month =        jul,
  number =       "7",
  priority =     "2",
  publisher =    "ACM",
  title =        "Formal Verification of a Realistic Compiler",
  volume =       "52",
  x-abstract =   "This paper reports on the development and formal
                 verification (proof of semantic preservation) of
                 {CompCert}, a compiler from Clight (a large subset of
                 the C programming language) to {PowerPC} assembly code,
                 using the Coq proof assistant both for programming the
                 compiler and for proving its correctness. Such a
                 verified compiler is useful in the context of critical
                 software and its formal verification: the verification
                 of the compiler guarantees that the safety properties
                 proved on the source code hold for the executable
                 compiled code as well.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1538788.1538814",
  x-issn =       "0001-0782",
  x-url =        "http://dx.doi.org/10.1145/1538788.1538814",
  xpages =       "107--115",
  year =         "2009",
}

@Article{Dsilva2008Survey,
  author =       "V. D'silva and D. Kroening and G. Weissenbacher",
  citeulike-article-id = "6053706",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2302032",
  citeulike-linkout-1 = "http://dx.doi.org/10.1109/tcad.2008.923410",
  citeulike-linkout-2 = "http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4544862",
  date-added =   "2014-03-23 18:24:24",
  day =          "17",
  institution =  "Comput. Lab., Univ. of Oxford, Oxford",
  journal =      "Computer-Aided Design of Integrated Circuits and
                 Systems, IEEE Transactions on",
  month =        jul,
  number =       "7",
  priority =     "2",
  publisher =    "IEEE",
  title =        "A Survey of Automated Techniques for Formal Software
                 Verification",
  volume =       "27",
  x-abstract =   "The quality and the correctness of software are often
                 the greatest concern in electronic systems. Formal
                 verification tools can provide a guarantee that a
                 design is free of specific flaws. This paper surveys
                 algorithms that perform automatic static analysis of
                 software to detect programming errors or prove their
                 absence. The three techniques considered are static
                 analysis with abstract domains, model checking, and
                 bounded model checking. A short tutorial on these
                 techniques is provided, highlighting their differences
                 when applied to practical problems. This paper also
                 surveys tools implementing these techniques and
                 describes their merits and shortcomings.",
  x-address =    "Piscataway, NJ, USA",
  x-doi =        "10.1109/tcad.2008.923410",
  x-issn =       "0278-0070",
  x-url =        "http://dx.doi.org/10.1109/tcad.2008.923410",
  xpages =       "1165--1178",
  year =         "2008",
}

@Article{Knowles2010Hybrid,
  author =       "Kenneth Knowles and Cormac Flanagan",
  citeulike-article-id = "6658568",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1667048.1667051",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1667048.1667051",
  date-added =   "2014-02-28 02:07:19",
  journal =      "ACM Trans. Program. Lang. Syst.",
  month =        feb,
  number =       "2",
  priority =     "2",
  publisher =    "ACM",
  title =        "Hybrid Type Checking",
  volume =       "32",
  x-abstract =   "Traditional static type systems are effective for
                 verifying basic interface specifications. Dynamically
                 checked contracts support more precise specifications,
                 but these are not checked until runtime, resulting in
                 incomplete detection of defects. Hybrid type checking
                 is a synthesis of these two approaches that enforces
                 precise interface specifications, via static analysis
                 where possible, but also via dynamic checks where
                 necessary. This article explores the key ideas and
                 implications of hybrid type checking, in the context of
                 the λ-calculus extended with contract types, that is,
                 with dependent function types and with arbitrary
                 refinements of base types.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1667048.1667051",
  x-issn =       "0164-0925",
  x-url =        "http://dx.doi.org/10.1145/1667048.1667051",
  xpages =       "1--34",
  year =         "2010",
}

@InProceedings{Terauchi2010Dependent,
  author =       "Tachio Terauchi",
  booktitle =    "Proceedings of the 37th Annual ACM SIGPLAN-SIGACT
                 Symposium on Principles of Programming Languages",
  citeulike-article-id = "13074547",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1706299.1706315",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1706299.1706315",
  date-added =   "2014-02-28 01:01:00",
  location =     "Madrid, Spain",
  priority =     "2",
  publisher =    "ACM",
  title =        "Dependent Types from Counterexamples",
  x-abstract =   "Motivated by recent research in abstract model
                 checking, we present a new approach to inferring
                 dependent types. Unlike many of the existing
                 approaches, our approach does not rely on programmers
                 to supply the candidate (or the correct) types for the
                 recursive functions and instead does
                 counterexample-guided refinement to automatically
                 generate the set of candidate dependent types. The main
                 idea is to extend the classical fixed-point type
                 inference routine to return a counterexample if the
                 program is found untypable with the current set of
                 candidate types. Then, an interpolating theorem prover
                 is used to validate the counterexample as a real type
                 error or generate additional candidate dependent types
                 to refute the spurious counterexample. The process is
                 repeated until either a real type error is found or
                 sufficient candidates are generated to prove the
                 program typable. Our system makes non-trivial use of
                 {"}linear{"} intersection types in the refinement
                 phase. The paper presents the type inference system and
                 reports on the experience with a prototype
                 implementation that infers dependent types for a subset
                 of the Ocaml language. The implementation infers
                 dependent types containing predicates from the
                 quantifier-free theory of linear arithmetic and
                 equality with uninterpreted function symbols.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1706299.1706315",
  x-isbn =       "978-1-60558-479-9",
  x-series =     "POPL",
  x-url =        "http://dx.doi.org/10.1145/1706299.1706315",
  xpages =       "119--130",
  year =         "2010",
}

@InProceedings{Larson2003High,
  author =       "Eric Larson and Todd Austin",
  booktitle =    "Proceedings of the 12th Conference on USENIX Security
                 Symposium - Volume 12",
  citeulike-article-id = "6665223",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1251362",
  date-added =   "2014-02-26 14:28:56",
  location =     "Washington, DC",
  priority =     "2",
  publisher =    "USENIX Association",
  title =        "High Coverage Detection of Input-related Security
                 Faults",
  x-abstract =   "Improperly bounded program inputs present a major
                 class of program defects. In secure applications, these
                 bugs can be exploited by malicious users, allowing them
                 to overwrite buffers and execute harmful code. In this
                 paper, we present a high coverage dynamic technique for
                 detecting software faults caused by improperly bounded
                 program inputs. Our approach is novel in that it
                 retains the advantages of dynamic bug detection, scope
                 and precision; while at the same time, relaxing the
                 requirement that the user specify the input that
                 exposes the bug. To implement our approach, inputs are
                 shadowed by additional state that characterize the
                 allowed bounds of input-derived variables. Program
                 operations and decision points may alter the shadowed
                 state associated with input variables. Potentially
                 hazardous program sites, such as an array references
                 and string functions, are checked against the entire
                 range of values that the user might specify. The
                 approach found several bugs including two high-risk
                 security bugs in a recent version of {OpenSSH}.",
  x-address =    "Berkeley, CA, USA",
  x-series =     "USENIX Security",
  x-url =        "http://portal.acm.org/citation.cfm?id=1251362",
  xpages =       "9",
  year =         "2003",
}

@InProceedings{Henglein1995Safe,
  author =       "Fritz Henglein and Jakob Rehof",
  booktitle =    "Proceedings of the Seventh International Conference on
                 Functional Programming Languages and Computer
                 Architecture",
  citeulike-article-id = "13053681",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=224203",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/224164.224203",
  date-added =   "2014-02-19 15:45:53",
  location =     "La Jolla, California, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "Safe Polymorphic Type Inference for a Dynamically
                 Typed Language: Translating Scheme to {ML}",
  x-abstract =   "An abstract is not available.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/224164.224203",
  x-isbn =       "0-89791-719-7",
  x-series =     "FPCA '95",
  x-url =        "http://dx.doi.org/10.1145/224164.224203",
  xpages =       "192--203",
  year =         "1995",
}

@Article{King1976Symbolic,
  author =       "James C. King",
  citeulike-article-id = "80858",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=360252",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/360248.360252",
  date-added =   "2014-02-16 22:52:26",
  journal =      "Commun. ACM",
  month =        jul,
  number =       "7",
  priority =     "2",
  publisher =    "ACM",
  title =        "Symbolic Execution and Program Testing",
  volume =       "19",
  x-abstract =   "This paper describes the symbolic execution of
                 programs. Instead of supplying the normal inputs to a
                 program (e.g. numbers) one supplies symbols
                 representing arbitrary values. The execution proceeds
                 as in a normal execution except that values may be
                 symbolic formulas over the input symbols. The
                 difficult, yet interesting issues arise during the
                 symbolic execution of conditional branch type
                 statements. A particular system called {EFFIGY} which
                 provides symbolic execution for program testing and
                 debugging is also described. It interpretively executes
                 programs written in a simple {PL}/I style programming
                 language. It includes many standard debugging features,
                 the ability to manage and to prove things about
                 symbolic expressions, a simple program testing manager,
                 and a program verifier. A brief discussion of the
                 relationship between symbolic execution and program
                 proving is also included.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/360248.360252",
  x-issn =       "0001-0782",
  x-url =        "http://dx.doi.org/10.1145/360248.360252",
  xpages =       "385--394",
  year =         "1976",
}

@InProceedings{Boyer1975SELECTa,
  author =       "Robert S. Boyer and Bernard Elspas and Karl N.
                 Levitt",
  booktitle =    "Proceedings of the International Conference on
                 Reliable Software",
  citeulike-article-id = "9950017",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=808445",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/390016.808445",
  date-added =   "2014-02-16 22:45:38",
  journal =      "SIGPLAN Not.",
  location =     "Los Angeles, California",
  month =        apr,
  priority =     "2",
  publisher =    "ACM",
  title =        "{SELECT}--a Formal System for Testing and Debugging
                 Programs by Symbolic Execution",
  volume =       "10",
  x-abstract =   "{SELECT} is an experimental system for assisting in
                 the formal systematic debugging of programs. It is
                 intended to be a compromise between an automated
                 program proving system and the current ad hoc debugging
                 practice, and is similar to a system being developed by
                 King et al. of {IBM}. {SELECT} systematically handles
                 the paths of programs written in a {LISP} subset that
                 includes arrays. For each execution path {SELECT}
                 returns simplified conditions on input variables that
                 cause the path to be executed, and simplified symbolic
                 values for program variables at the path output. For
                 conditions which form a system of linear equalities and
                 inequalities {SELECT} will return input variable values
                 that can serve as sample test data. The user can insert
                 constraint conditions, at any point in the program
                 including the output, in the form of symbolically
                 executable assertions. These conditions can induce the
                 system to select test data in user-specified regions.
                 {SELECT} can also determine if the path is correct with
                 respect to an output assertion. We present four
                 examples demonstrating the various modes of system
                 operation and their effectiveness in finding bugs. In
                 some examples, {SELECT} was successful in automatically
                 finding useful test data. In others, user interaction
                 was required in the form of output assertions. {SELECT}
                 appears to be a useful tool for rapidly revealing
                 program errors, but for the future there is a need to
                 expand its expressive and deductive power.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/390016.808445",
  x-issn =       "0362-1340",
  x-url =        "http://dx.doi.org/10.1145/390016.808445",
  xpages =       "234--245",
  year =         "1975",
}

@InProceedings{Schwartz2010All,
  author =       "Edward J. Schwartz and Thanassis Avgerinos and David
                 Brumley",
  booktitle =    "Proceedings of the 2010 IEEE Symposium on Security and
                 Privacy",
  citeulike-article-id = "9300207",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1849981",
  citeulike-linkout-1 = "http://doi.ieeecomputersociety.org/10.1109/SP.2010.26",
  citeulike-linkout-2 = "http://dx.doi.org/10.1109/sp.2010.26",
  citeulike-linkout-3 = "http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5504796",
  date-added =   "2014-02-16 16:58:01",
  journal =      "Security and Privacy, IEEE Symposium on",
  month =        may,
  priority =     "2",
  publisher =    "IEEE Computer Society",
  title =        "All You Ever Wanted to Know About Dynamic Taint
                 Analysis and Forward Symbolic Execution (but Might Have
                 Been Afraid to Ask)",
  volume =       "0",
  x-abstract =   "Dynamic taint analysis and forward symbolic execution
                 are quickly becoming staple techniques in security
                 analyses. Example applications of dynamic taint
                 analysis and forward symbolic execution include malware
                 analysis, input filter generation, test case
                 generation, and vulnerability discovery. Despite the
                 widespread usage of these two techniques, there has
                 been little effort to formally define the algorithms
                 and summarize the critical issues that arise when these
                 techniques are used in typical security contexts. The
                 contributions of this paper are two-fold. First, we
                 precisely describe the algorithms for dynamic taint
                 analysis and forward symbolic execution as extensions
                 to the run-time semantics of a general language.
                 Second, we highlight important implementation choices,
                 common pitfalls, and considerations when using these
                 techniques in a security context.",
  x-address =    "Washington, DC, USA",
  x-doi =        "10.1109/sp.2010.26",
  x-isbn =       "978-0-7695-4035-1",
  x-issn =       "1081-6011",
  x-series =     "SP '10",
  x-url =        "http://dx.doi.org/10.1109/sp.2010.26",
  xpages =       "317--331",
  year =         "2010",
}

@InProceedings{Swamy2013Verifying,
  author =       "Nikhil Swamy and Joel Weinberger and Cole Schlesinger
                 and Juan Chen and Benjamin Livshits",
  booktitle =    "Proceedings of the 34th ACM SIGPLAN Conference on
                 Programming Language Design and Implementation",
  citeulike-article-id = "13050512",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2491956.2491978",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2499370.2491978",
  date-added =   "2014-02-15 17:37:36",
  month =        jun,
  number =       "6",
  priority =     "2",
  publisher =    "ACM",
  title =        "Verifying Higher-order Programs with the {D}ijkstra
                 Monad",
  volume =       "48",
  x-abstract =   "Modern programming languages, ranging from Haskell and
                 {ML}, to {JavaScript}, C\# and Java, all make extensive
                 use of higher-order state. This paper advocates a new
                 verification methodology for higher-order stateful
                 programs, based on a new monad of predicate
                 transformers called the Dijkstra monad. Using the
                 Dijkstra monad has a number of benefits. First, the
                 monad naturally yields a weakest pre-condition
                 calculus. Second, the computed specifications are
                 structurally simpler in several ways, e.g.,
                 single-state post-conditions are sufficient (rather
                 than the more complex two-state post-conditions).
                 Finally, the monad can easily be varied to handle
                 features like exceptions and heap invariants, while
                 retaining the same type inference algorithm. We
                 implement the Dijkstra monad and its type inference
                 algorithm for the F* programming language. Our most
                 extensive case study evaluates the Dijkstra monad and
                 its F* implementation by using it to verify
                 {JavaScript} programs. Specifically, we describe a tool
                 chain that translates programs in a subset of
                 {JavaScript} decorated with assertions and loop
                 invariants to F*. Once in F*, our type inference
                 algorithm computes verification conditions and
                 automatically discharges their proofs using an {SMT}
                 solver. We use our tools to prove that a core model of
                 the {JavaScript} runtime in F* respects various
                 invariants and that a suite of {JavaScript} source
                 programs are free of runtime errors.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2499370.2491978",
  x-issn =       "0362-1340",
  x-series =     "PLDI'13",
  x-url =        "http://dx.doi.org/10.1145/2499370.2491978",
  xpages =       "387--398",
  year =         "2013",
}

@InProceedings{Barrett2011CVC4,
  author =       "Clark Barrett and ChristopherL Conway and Morgan
                 Deters and Liana Hadarean and Dejan Jovanovi\'{c} and
                 Tim King and Andrew Reynolds and Cesare Tinelli",
  booktitle =    "Computer Aided Verification",
  citeulike-article-id = "9791297",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-642-22110-1\_14",
  citeulike-linkout-1 = "http://www.springerlink.com/content/r3g3k74m2p281j0n",
  citeulike-linkout-2 = "http://link.springer.com/chapter/10.1007/978-3-642-22110-1\_14",
  date-added =   "2013-07-11 21:52:08",
  priority =     "2",
  publisher =    "Springer",
  title =        "{CVC4}",
  x-abstract =   "{CVC4} is the latest version of the Cooperating
                 Validity Checker. A joint project of {NYU} and U Iowa,
                 {CVC4} aims to support the useful feature set of {CVC3}
                 and {SMT}-{LIBv2} while optimizing the design of the
                 core system architecture and decision procedures to
                 take advantage of recent engineering and algorithmic
                 advances. {CVC4} represents a completely new code base;
                 it is a from-scratch rewrite of {CVC3}, and many
                 subsystems have been completely redesigned. Additional
                 decision procedures for {CVC4} are currently under
                 development, but for what it currently achieves, it is
                 a lighter-weight and higher-performing tool than
                 {CVC3}. We describe the system architecture, subsystems
                 of note, and discuss some applications and continuing
                 work.",
  x-address =    "Berlin, Heidelberg",
  x-doi =        "10.1007/978-3-642-22110-1\_14",
  x-editor =     "Gopalakrishnan, Ganesh and Qadeer, Shaz",
  x-isbn =       "978-3-642-22109-5",
  x-series =     "CAV",
  x-url =        "http://dx.doi.org/10.1007/978-3-642-22110-1\_14",
  xpages =       "171--177",
  year =         "2011",
}

@InProceedings{DeMoura2008Z3,
  author =       "Leonardo De Moura and Nikolaj Bj{\o}rner",
  booktitle =    "Proceedings of the Theory and Practice of Software,
                 14th International Conference on Tools and Algorithms
                 for the Construction and Analysis of Systems",
  citeulike-article-id = "12475017",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1792766",
  date-added =   "2013-07-11 21:36:59",
  location =     "Budapest, Hungary",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "{Z3}: an efficient {SMT} solver",
  x-abstract =   "Satisfiability Modulo Theories ({SMT}) problem is a
                 decision problem for logical first order formulas with
                 respect to combinations of background theories such as:
                 arithmetic, bit-vectors, arrays, and uninterpreted
                 functions. Z3 is a new and efficient {SMT} Solver
                 freely available from Microsoft Research. It is used in
                 various software verification and analysis
                 applications.",
  x-address =    "Berlin, Heidelberg",
  x-isbn =       "3-540-78799-2, 978-3-540-78799-0",
  x-series =     "TACAS",
  x-url =        "http://portal.acm.org/citation.cfm?id=1792766",
  xpages =       "337--340",
  year =         "2008",
}

@InCollection{StAmour2012Typing,
  author =       "Vincent St-Amour and Sam Tobin-Hochstadt and Matthew
                 Flatt and Matthias Felleisen",
  booktitle =    "Practical Aspects of Declarative Languages",
  citeulike-article-id = "12474890",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2187146",
  citeulike-linkout-1 = "http://dx.doi.org/10.1007/978-3-642-27694-1\_21",
  citeulike-linkout-2 = "http://link.springer.com/chapter/10.1007/978-3-642-27694-1\_21",
  date-added =   "2013-07-11 19:08:13",
  location =     "Philadelphia, PA",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "Typing the Numeric Tower",
  x-abstract =   "In the past, the creators of numerical programs had to
                 choose between simple expression of mathematical
                 formulas and static type checking. While the Lisp
                 family and its dynamically typed relatives support the
                 straightforward expression via a rich numeric tower,
                 existing statically typed languages force programmers
                 to pollute textbook formulas with explicit coercions or
                 unwieldy notation. In this paper, we demonstrate how
                 the type system of Typed Racket accommodates both a
                 textbook programming style and expressive static
                 checking. The type system provides a hierarchy of
                 numeric types that can be freely mixed as well as
                 precise specifications of sign, representation, and
                 range information—all while supporting generic
                 operations. In addition, the type system provides
                 information to the compiler so that it can perform
                 standard numeric optimizations.",
  x-address =    "Berlin, Heidelberg",
  x-doi =        "10.1007/978-3-642-27694-1\_21",
  x-editor =     "Russo, Claudio and Zhou, Neng-Fa",
  x-isbn =       "978-3-642-27693-4",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-642-27694-1\_21",
  xpages =       "289--303",
  year =         "2012",
}

@InProceedings{Dimoulas2012Complete,
  author =       "Christos Dimoulas and Sam Tobin-Hochstadt and Matthias
                 Felleisen",
  booktitle =    "21st European Symposium on Programming",
  citeulike-article-id = "12473623",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2259259",
  citeulike-linkout-1 = "http://dx.doi.org/10.1007/978-3-642-28869-2\_11",
  citeulike-linkout-2 = "http://link.springer.com/chapter/10.1007/978-3-642-28869-2\_11",
  date-added =   "2013-07-10 19:07:43",
  location =     "Tallinn, Estonia",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "Complete Monitors for Behavioral Contracts",
  volume =       "7211",
  x-abstract =   "A behavioral contract in a higher-order language may
                 invoke methods of unknown objects. Although this
                 expressive power allows programmers to formulate
                 sophisticated contracts, it also poses a problem for
                 language designers. Indeed, two distinct semantics have
                 emerged for such method calls, dubbed lax and picky.
                 While lax fails to protect components in certain
                 scenarios, picky may blame an uninvolved party for a
                 contract violation. In this paper, we present complete
                 monitoring as the fundamental correctness criterion for
                 contract systems. It demands correct blame assignment
                 as well as complete monitoring of all channels of
                 communication between components. According to this
                 criterion, lax and picky are indeed incorrect ways to
                 monitor contracts. A third semantics, dubbed indy,
                 emerges as the only correct variant.",
  x-address =    "Berlin, Heidelberg",
  x-doi =        "10.1007/978-3-642-28869-2\_11",
  x-editor =     "Seidl, Helmut",
  x-isbn =       "978-3-642-28868-5",
  x-series =     "ESOP'12",
  x-url =        "http://dx.doi.org/10.1007/978-3-642-28869-2\_11",
  xpages =       "214--233",
  year =         "2012",
}

@InProceedings{Gronski2007Unifying,
  author =       "Jessica Gronski and Cormac Flanagan",
  booktitle =    "In Eighth Symposium on Trends in Functional
                 Programming",
  citeulike-article-id = "5820562",
  citeulike-linkout-0 = "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.123.3771",
  date-added =   "2013-07-10 19:05:09",
  priority =     "2",
  title =        "Unifying hybrid types and contracts",
  x-abstract =   "Contract systems and hybrid type systems provide two
                 alternative approaches for enforcing precisely-defined
                 interface specifications, with complementary
                 advantages: contract systems excel at blame assignment,
                 whereas hybrid type systems support type-based static
                 analysis. We unify these two approaches by
                 demonstrating that hybrid type checking is sufficiently
                 expressive to encode higher-order contracts with proper
                 blame assignment. In particular, a contract obligation
                 that enforces both sides of a contract is decomposed
                 into two type casts that each enforce one side of the
                 contract. This expressiveness result provides several
                 benefits, including allowing one of these casts to be
                 lifted to earlier in the program\^{a}s execution,
                 resulting in improved contract coverage. 1",
  x-url =        "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.123.3771",
  year =         "2007",
}

@Article{Blume2006Sound,
  author =       "Matthias Blume and David McAllester",
  citeulike-article-id = "9524694",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1166016",
  citeulike-linkout-1 = "http://dx.doi.org/10.1017/s0956796806005971",
  date-added =   "2013-07-10 18:57:43",
  journal =      "J. Funct. Program.",
  month =        jul,
  number =       "4-5",
  priority =     "2",
  publisher =    "Cambridge University Press",
  title =        "Sound and Complete Models of Contracts",
  volume =       "16",
  x-abstract =   "Even in statically typed languages it is useful to
                 have certain invariants checked dynamically. Findler
                 and Felleisen gave an algorithm for dynamically
                 checking expressive higher-order types called
                 contracts. They did not, however, give a semantics of
                 contracts. The lack of a semantics makes it impossible
                 to define and prove soundness and completeness of the
                 checking algorithm. (Given a semantics, a sound checker
                 never reports violations that do not exist under that
                 semantics; a complete checker is – in principle –
                 able to find violations when violations exist.)
                 Ideally, a semantics should capture what programmers
                 intuitively feel is the meaning of a contract or
                 otherwise clearly point out where intuition does not
                 match reality. In this paper we give an interpretation
                 of contracts for which we prove the {Findler-Felleisen}
                 algorithm sound and (under reasonable assumptions)
                 complete. While our semantics mostly matches intuition,
                 it also exposes a problem with predicate contracts
                 where an arguably more intuitive interpretation than
                 ours would render the checking algorithm unsound. In
                 our semantics we have to make use of a notion of safety
                 (which we define in the paper) to avoid unsoundness. We
                 are able to eliminate the ” leakage” of safety into
                 the semantics by changing the language, replacing the
                 original version of unrestricted predicate contracts
                 with a restricted form. The corresponding loss in
                 expressive power can be recovered by making safety
                 explicit as a contract. This can be done either in
                 ad-hoc fashion or by including general recursive
                 contracts. The addition of recursive contracts has
                 far-reaching implications, deeply affecting the
                 formulation of our model and requiring different
                 techniques for proving soundness.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1017/s0956796806005971",
  x-issn =       "0956-7968",
  x-url =        "http://dx.doi.org/10.1017/s0956796806005971",
  xpages =       "375--414",
  year =         "2006",
}

@InProceedings{Plosch1997Design,
  author =       "R. Plosch",
  booktitle =    "Proceedings of the Joint Asia Pacific Software
                 Engineering Conference",
  citeulike-article-id = "4221458",
  citeulike-linkout-0 = "http://dx.doi.org/10.1109/apsec.1997.640178",
  citeulike-linkout-1 = "http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=640178",
  date-added =   "2013-07-10 03:45:54",
  institution =  "Johannes Kepler Univ., Linz, Austria",
  journal =      "Software Engineering Conference, 1997. Asia Pacific
                 ... and International Computer Science Conference 1997.
                 APSEC '97 and ICSC '97. Proceedings",
  location =     "Hong Kong",
  month =        dec,
  priority =     "2",
  publisher =    "IEEE",
  title =        "Design by contract for {P}ython",
  x-abstract =   "The idea of design by contract ({DEC}), realized in
                 the statically typed object-oriented programming
                 language Eiffel, can be viewed as a systematic approach
                 to specifying and implementing object-oriented software
                 systems. We believe that a statically typed programming
                 language is not suitable in the analysis and design
                 phase of a prototyping-oriented software life cycle.
                 For this purpose, dynamically typed interpreted
                 programming languages are better suited. Unfortunately,
                 dynamically typed programming languages usually do not
                 support the concept of {DEC}. Therefore we integrated
                 {DEC} into the programming language Python by using a
                 metaprogramming approach, i.e., without changing the
                 language or the run-time system. We adopted the {DEC}
                 concept by adding mechanisms for dynamic type checking
                 for method parameters and instance variables. The
                 proposed combination of a more formal approach with a
                 slim programming language provides a good basis for
                 elicitation and documentation tasks in the analysis and
                 design phase, especially in cases of a
                 prototyping-oriented software development approach.
                 Although the approach presented provides basic tool
                 support for the analysis and design phase, further tool
                 support especially for browsing assertions, is
                 desirable",
  x-doi =        "10.1109/apsec.1997.640178",
  x-isbn =       "0-8186-8271-X",
  x-note =       "APSEC/ICSC'97",
  x-url =        "http://dx.doi.org/10.1109/apsec.1997.640178",
  xpages =       "213--219",
  year =         "1997",
}

@InProceedings{Strickland2012Chaperones,
  author =       "T. Stephen Strickland and Sam Tobin-Hochstadt and
                 Robert B. Findler and Matthew Flatt",
  booktitle =    "Proceedings of the ACM International Conference on
                 Object Oriented Programming Systems Languages and
                 Applications",
  citeulike-article-id = "12271764",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2384685",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2398857.2384685",
  date-added =   "2013-07-10 03:04:47",
  location =     "Tucson, Arizona, USA",
  month =        oct,
  priority =     "2",
  publisher =    "ACM",
  title =        "Chaperones and Impersonators: Run-time Support for
                 Reasonable Interposition",
  x-abstract =   "Chaperones and impersonators provide run-time support
                 for interposing on primitive operations such as
                 function calls, array access and update, and structure
                 field access and update. Unlike most interposition
                 support, chaperones and impersonators are restricted so
                 that they constrain the behavior of the interposing
                 code to reasonable interposition, which in practice
                 preserves the abstraction mechanisms and reasoning that
                 programmers and compiler analyses rely on. Chaperones
                 and impersonators are particularly useful for
                 implementing contracts, and our implementation in
                 Racket allows us to improve both the expressiveness and
                 the performance of Racket's contract system.
                 Specifically, contracts on mutable data can be enforced
                 without changing the {API} to that data; contracts on
                 large data structures can be checked lazily on only the
                 accessed parts of the structure; contracts on objects
                 and classes can be implemented with lower overhead; and
                 contract wrappers can preserve object equality where
                 appropriate. With this extension, gradual typing
                 systems, such as Typed Racket, that rely on contracts
                 for interoperation with untyped code can now pass
                 mutable values safely between typed and untyped
                 modules.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2398857.2384685",
  x-isbn =       "978-1-4503-1561-6",
  x-issn =       "0362-1340",
  x-series =     "OOPSLA",
  x-url =        "http://dx.doi.org/10.1145/2398857.2384685",
  xpages =       "943--962",
  year =         "2012",
}

@Article{Greenberg2012Contracts,
  author =       "Michael Greenberg and Benjamin C. Pierce and Stephanie
                 Weirich",
  citeulike-article-id = "12472814",
  citeulike-linkout-0 = "http://journals.cambridge.org/action/displayAbstract?fromPage=online\&aid=8626437",
  citeulike-linkout-1 = "http://dx.doi.org/10.1017/s0956796812000135",
  date-added =   "2013-07-09 22:52:29",
  journal =      "Journal of Functional Programming",
  month =        may,
  priority =     "2",
  title =        "Contracts made manifest",
  volume =       "22",
  x-abstract =   "Since Findler and Felleisen (Findler, R. B. \&
                 Felleisen, M. 2002) introduced higher-order contracts,
                 many variants have been proposed. Broadly, these fall
                 into two groups: some follow Findler and Felleisen
                 (2002) in using latent contracts, purely dynamic checks
                 that are transparent to the type system; others use
                 manifest contracts, where refinement types record the
                 most recent check that has been applied to each value.
                 These two approaches are commonly assumed to be
                 equivalent—different ways of implementing the same
                 idea, one retaining a simple type system, and the other
                 providing more static information. Our goal is to
                 formalize and clarify this folklore understanding. Our
                 work extends that of Gronski and Flanagan (Gronski, J.
                 \& Flanagan, C. 2007), who defined a latent calculus
                 {λC} and a manifest calculus {λH}, gave a translation
                 φ from {λC} to {λH}, and proved that if a {λC} term
                 reduces to a constant, so does its φ-image. We enrich
                 their account with a translation ψ from {λH} to {λC}
                 and prove an analogous theorem. We then generalize the
                 whole framework to dependent contracts, whose
                 predicates can mention free variables. This extension
                 is both pragmatically crucial, supporting a much more
                 interesting range of contracts, and theoretically
                 challenging. We define dependent versions of {λH} and
                 two dialects ( ” lax” and ” picky”) of {λC},
                 establish type soundness—a substantial result in
                 itself, for {λH} — and extend φ and ψ accordingly.
                 Surprisingly, the intuition that the latent and
                 manifest systems are equivalent now breaks down: the
                 extended translations preserve behavior in one
                 direction, but in the other, sometimes yield terms that
                 blame more.",
  x-doi =        "10.1017/s0956796812000135",
  x-issn =       "1469-7653",
  x-url =        "http://dx.doi.org/10.1017/s0956796812000135",
  xpages =       "225--274",
  year =         "2012",
}

@InProceedings{Freeman1991Refinement,
  author =       "Tim Freeman and Frank Pfenning",
  booktitle =    "Proceedings of the ACM SIGPLAN 1991 Conference on
                 Programming Language Design and Implementation",
  citeulike-article-id = "497232",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=113468",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/113445.113468",
  date-added =   "2013-07-09 20:22:08",
  location =     "Toronto, Ontario, Canada",
  month =        jun,
  priority =     "2",
  publisher =    "ACM",
  title =        "Refinement Types for {ML}",
  x-abstract =   "An abstract is not available.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/113445.113468",
  x-isbn =       "0-89791-428-7",
  x-issn =       "0362-1340",
  x-series =     "PLDI",
  x-url =        "http://dx.doi.org/10.1145/113445.113468",
  xpages =       "268--277",
  year =         "1991",
}

@Article{Cartwright1996Program,
  author =       "Robert Cartwright and Matthias Felleisen",
  citeulike-article-id = "190442",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=234747",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/234528.234747",
  date-added =   "2013-07-09 20:02:05",
  journal =      "ACM Comput. Surv.",
  month =        jun,
  number =       "2",
  priority =     "2",
  publisher =    "ACM",
  title =        "Program verification through soft typing",
  volume =       "28",
  x-abstract =   "An abstract is not available.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/234528.234747",
  x-issn =       "0360-0300",
  x-url =        "http://dx.doi.org/10.1145/234528.234747",
  xpages =       "349--351",
  year =         "1996",
}

@InProceedings{Aiken1994Soft,
  author =       "Alexander Aiken and Edward L. Wimmers and T. K.
                 Lakshman",
  booktitle =    "Proceedings of the 21st ACM SIGPLAN-SIGACT Symposium
                 on Principles of Programming Languages",
  citeulike-article-id = "7062350",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=174675.177847",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/174675.177847",
  date-added =   "2013-07-09 19:29:35",
  location =     "Portland, Oregon, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "Soft typing with conditional types",
  x-abstract =   "We present a simple and powerful type inference method
                 for dynamically typed languages where no type
                 information is supplied by the user. Type inference is
                 reduced to the problem of solvability of a system of
                 type inclusion constraints over a type language that
                 includes function types, constructor types, union,
                 intersection, and recursive types, and conditional
                 types. Conditional types enable us to analyze control
                 flow using type inference, thus facilitating
                 computation of accurate types. We demonstrate the power
                 and practicality of the method with examples and
                 performance results from an implementation.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/174675.177847",
  x-isbn =       "0-89791-636-0",
  x-series =     "POPL",
  x-url =        "http://dx.doi.org/10.1145/174675.177847",
  xpages =       "163--173",
  year =         "1994",
}

@InCollection{Kawaguchi2010Dsolve,
  author =       "Ming Kawaguchi and PatrickM Rondon and Ranjit Jhala",
  booktitle =    "Computer Aided Verification",
  citeulike-article-id = "12465105",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-642-14295-6\_12",
  citeulike-linkout-1 = "http://link.springer.com/chapter/10.1007/978-3-642-14295-6\_12",
  date-added =   "2013-07-09 19:24:25",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "Dsolve: Safety Verification via Liquid Types",
  x-abstract =   "We present Dsolve, a verification tool for {OCaml}.
                 Dsolve automates verification by inferring ”
                 Liquid” refinement types that are expressive enough
                 to verify a variety of complex safety properties.",
  x-doi =        "10.1007/978-3-642-14295-6\_12",
  x-editor =     "Touili, Tayssir and Cook, Byron and Jackson, Paul",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-642-14295-6\_12",
  xpages =       "123--126",
  year =         "2010",
}

@InProceedings{Vazou2013Abstract,
  author =       "Niki Vazou and PatrickM Rondon and Ranjit Jhala",
  booktitle =    "European Symposium on Programming",
  citeulike-article-id = "12465100",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-642-37036-6\_13",
  citeulike-linkout-1 = "http://link.springer.com/chapter/10.1007/978-3-642-37036-6\_13",
  date-added =   "2013-07-09 19:19:26",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "Abstract Refinement Types",
  x-abstract =   "We present abstract refinement types which enable
                 quantification over the refinements of data- and
                 function-types. Our key insight is that we can avail of
                 quantification while preserving {SMT}-based
                 decidability, simply by encoding refinement parameters
                 as uninterpreted propositions within the refinement
                 logic. We illustrate how this mechanism yields a
                 variety of sophisticated means for reasoning about
                 programs, including: parametric refinements for
                 reasoning with type classes, index-dependent
                 refinements for reasoning about key-value maps,
                 recursive refinements for reasoning about recursive
                 data types, and inductive refinements for reasoning
                 about higher-order traversal routines. We have
                 implemented our approach in a refinement type checker
                 for Haskell and present experiments using our tool to
                 verify correctness invariants of various programs.",
  x-doi =        "10.1007/978-3-642-37036-6\_13",
  x-editor =     "Felleisen, Matthias and Gardner, Philippa",
  x-series =     "ESOP",
  x-url =        "http://dx.doi.org/10.1007/978-3-642-37036-6\_13",
  xpages =       "209--228",
  year =         "2013",
}

@Article{Henglein1994Dynamic,
  author =       "Fritz Henglein",
  citeulike-article-id = "853230",
  citeulike-linkout-0 = "http://dx.doi.org/10.1016/0167-6423(94)00004-2",
  citeulike-linkout-1 = "http://www.sciencedirect.com/science/article/B6V17-45GMGM9-1K/2/6f1a92280b24d91191679940d586c4fa",
  date-added =   "2013-07-09 19:14:49",
  journal =      "Science of Computer Programming",
  month =        jun,
  number =       "3",
  priority =     "2",
  title =        "Dynamic typing: syntax and proof theory",
  volume =       "22",
  x-abstract =   "We present the dynamically typed \^{I}»-calculus, an
                 extension of the statically typed \^{I}»-calculus with
                 a special type Dyn and explicit dynamic type coercions
                 corresponding to run-time type tagging and type
                 check-and-untag operations. Programs in run-time typed
                 languages can be interpreted in the dynamically typed
                 \^{I}»-calculus via a nondeterministic completion
                 process that inserts explicit coercions and type
                 declarations such that a well-typed term results. We
                 characterize when two different completions of the same
                 run-time typed program are coherent with an equational
                 theory that is independent of an underlying
                 \^{I}»-theory. This theory is refined by orienting
                 some equations to define safety and minimality of
                 completions. Intuitively, a safe completion is one that
                 does not produce an error at run-time which another
                 completion would have avoided, and a minimal completion
                 is a safe completion that executes fewest tagging and
                 check-and-untag operations amongst all safe
                 completions. We show that every untyped \^{I}»-term
                 has a safe completion at any type and that it is unique
                 modulo a suitable congruence relation. Furthermore, we
                 present a rewriting system for generating minimal
                 completions. Assuming strong normalization of this
                 rewriting system we show that every {\^{I}»I}-term has
                 a minimal completion at any type, which is furthermore
                 unique modulo equality in the dynamically typed
                 \^{I}»-calculus.",
  x-doi =        "10.1016/0167-6423(94)00004-2",
  x-issn =       "01676423",
  x-url =        "http://dx.doi.org/10.1016/0167-6423(94)00004-2",
  xpages =       "197--230",
  year =         "1994",
}

@InProceedings{Cartwright1991Soft,
  author =       "Robert Cartwright and Mike Fagan",
  booktitle =    "Proceedings of the ACM SIGPLAN 1991 Conference on
                 Programming Language Design and Implementation",
  citeulike-article-id = "2792466",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=113445.113469",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/113445.113469",
  date-added =   "2013-07-09 19:07:46",
  location =     "Toronto, Ontario, Canada",
  priority =     "2",
  publisher =    "ACM",
  title =        "Soft typing",
  x-abstract =   "An abstract is not available.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/113445.113469",
  x-isbn =       "0-89791-428-7",
  x-series =     "PLDI",
  x-url =        "http://dx.doi.org/10.1145/113445.113469",
  xpages =       "278--292",
  year =         "1991",
}

@InProceedings{Tsukada2010Untyped,
  author =       "Takeshi Tsukada and Naoki Kobayashi",
  booktitle =    "Proceedings of the 13th International Conference on
                 Foundations of Software Science and Computational
                 Structures",
  citeulike-article-id = "12464893",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2175551",
  citeulike-linkout-1 = "http://dx.doi.org/10.1007/978-3-642-12032-9\_24",
  date-added =   "2013-07-09 15:58:48",
  location =     "Paphos, Cyprus",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "Untyped recursion schemes and infinite intersection
                 types",
  x-abstract =   "A new framework for higher-order program verification
                 has been recently proposed, in which higher-order
                 functional programs are modelled as higher-order
                 recursion schemes and then model-checked. As recursion
                 schemes are essentially terms of the simply-typed
                 lambda-calculus with recursion and tree constructors,
                 however, it was not clear how the new framework applies
                 to programs written in languages with more advanced
                 type systems. To circumvent the limitation, this paper
                 introduces an untyped version of recursion schemes and
                 develops an infinite intersection type system that is
                 equivalent to the model checking of untyped recursion
                 schemes, so that the model checking can be reduced to
                 type checking as in recent work by Kobayashi and Ong
                 for typed recursion schemes. The type system is
                 undecidable but we can obtain decidable subsets of the
                 type system by restricting the shapes of intersection
                 types, yielding a sound (but incomplete in general)
                 model checking algorithm.",
  x-address =    "Berlin, Heidelberg",
  x-doi =        "10.1007/978-3-642-12032-9\_24",
  x-isbn =       "3-642-12031-8, 978-3-642-12031-2",
  x-series =     "FoSSaCS",
  x-url =        "http://dx.doi.org/10.1007/978-3-642-12032-9\_24",
  xpages =       "343--357",
  year =         "2010",
}

@InProceedings{Kobayashi2013ModelChecking,
  author =       "Naoki Kobayashi and Atsushi Igarashi",
  booktitle =    "European Symposium on Programming",
  citeulike-article-id = "12461148",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-642-37036-6\_24",
  citeulike-linkout-1 = "http://link.springer.com/chapter/10.1007/978-3-642-37036-6\_24",
  date-added =   "2013-07-05 19:35:52",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "{Model-Checking} {Higher-Order} Programs with
                 Recursive Types",
  x-abstract =   "Model checking of higher-order recursion schemes
                 ({HORS}, for short) has been recently studied as a new
                 promising technique for automated verification of
                 higher-order programs. The previous {HORS} model
                 checking could however deal with only simply-typed
                 programs, so that its application was limited to
                 functional programs. To deal with a broader range of
                 programs such as object-oriented programs and
                 multi-threaded programs, we extend {HORS} model
                 checking to check properties of programs with recursive
                 types. Although the extended model checking problem is
                 undecidable, we develop a sound model-checking
                 algorithm that is relatively complete with respect to a
                 recursive intersection type system and prove its
                 correctness. Preliminary results on the implementation
                 and applications to verification of object-oriented
                 programs and multi-threaded programs are also
                 reported.",
  x-doi =        "10.1007/978-3-642-37036-6\_24",
  x-editor =     "Felleisen, Matthias and Gardner, Philippa",
  x-series =     "ESOP",
  x-url =        "http://dx.doi.org/10.1007/978-3-642-37036-6\_24",
  xpages =       "431--450",
  year =         "2013",
}

@InProceedings{Kobayashi2009Modelchecking,
  author =       "Naoki Kobayashi",
  booktitle =    "Proceedings of the 11th ACM SIGPLAN Conference on
                 Principles and Practice of Declarative Programming",
  citeulike-article-id = "6647894",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1599410.1599415",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1599410.1599415",
  date-added =   "2013-07-05 19:20:54",
  location =     "Coimbra, Portugal",
  priority =     "2",
  publisher =    "ACM",
  title =        "Model-checking higher-order functions",
  x-abstract =   "We propose a novel type-based model checking algorithm
                 for higher-order recursion schemes. As shown by
                 Kobayashi, verification problems of higher-order
                 functional programs can easily be translated into model
                 checking problems of recursion schemes. Thus, the model
                 checking algorithm serves as a basis for verification
                 of higher-order functional programs. To our knowledge,
                 this is the first practical algorithm for model
                 checking recursion schemes: all the previous algorithms
                 always suffer from the {n-EXPTIME} bottleneck, not only
                 in the worst, and there was no implementation of the
                 algorithms. We have implemented a model checker for
                 recursion schemes based on the proposed algorithm, and
                 applied it to verification of functional programs,
                 including reachability, flow analysis and resource
                 usage verification problems. According to our
                 experiments, the model checker is surprisingly fast: it
                 could automatically verify a number of small but tricky
                 higher-order functional programs in less than a
                 second.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1599410.1599415",
  x-isbn =       "978-1-60558-568-0",
  x-series =     "PPDP",
  x-url =        "http://dx.doi.org/10.1145/1599410.1599415",
  xpages =       "25--36",
  year =         "2009",
}

@InProceedings{Kobayashi2010Higherorder,
  author =       "Naoki Kobayashi and Naoshi Tabuchi and Hiroshi Unno",
  booktitle =    "Proceedings of the 37th annual ACM SIGPLAN-SIGACT
                 Symposium on Principles of Programming Languages",
  citeulike-article-id = "12461139",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1706355",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1707801.1706355",
  date-added =   "2013-07-05 19:18:12",
  month =        jan,
  priority =     "2",
  publisher =    "ACM",
  title =        "Higher-order multi-parameter tree transducers and
                 recursion schemes for program verification",
  x-abstract =   "We introduce higher-order, multi-parameter, tree
                 transducers ({HMTTs}, for short), which are kinds of
                 higher-order tree transducers that take input trees and
                 output a (possibly infinite) tree. We study the problem
                 of checking whether the tree generated by a given
                 {HMTT} conforms to a given output specification,
                 provided that the input trees conform to input
                 specifications (where both input/output specifications
                 are regular tree languages). {HMTTs} subsume
                 higher-order recursion schemes and ordinary tree
                 transducers, so that their verification has a number of
                 potential applications to verification of functional
                 programs using recursive data structures, including
                 resource usage verification, string analysis, and exact
                 type-checking of {XML}-processing programs. We propose
                 a sound but incomplete verification algorithm for the
                 {HMTT} verification problem: the algorithm reduces the
                 verification problem to a model-checking problem for
                 higher-order recursion schemes extended with finite
                 data domains, and then uses (an extension
                 {of)Kobayashi}'s algorithm for model-checking recursion
                 schemes. While the algorithm is incomplete (indeed, as
                 we show in the paper, the verification problem is
                 undecidable in general), it is sound and complete for a
                 subclass of {HMTTs} called linear {HMTTs} . We have
                 applied our {HMTT} verification algorithm to various
                 program verification problems and obtained promising
                 results.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1707801.1706355",
  x-issn =       "0362-1340",
  x-series =     "POPL",
  x-url =        "http://dx.doi.org/10.1145/1707801.1706355",
  xpages =       "495--508",
  year =         "2010",
}

@InProceedings{Kobayashi2009Type,
  author =       "Naoki Kobayashi and C. H. Luke Ong",
  booktitle =    "2009 24th Annual IEEE Symposium on Logic In Computer
                 Science",
  citeulike-article-id = "12461130",
  citeulike-linkout-0 = "http://dx.doi.org/10.1109/lics.2009.29",
  citeulike-linkout-1 = "http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5230581",
  date-added =   "2013-07-05 19:12:49",
  location =     "Los Angeles, California, USA",
  month =        aug,
  priority =     "2",
  publisher =    "IEEE",
  title =        "A Type System Equivalent to the Modal {Mu-Calculus}
                 Model Checking of {Higher-Order} Recursion Schemes",
  x-doi =        "10.1109/lics.2009.29",
  x-isbn =       "978-0-7695-3746-7",
  x-series =     "LICS",
  x-url =        "http://dx.doi.org/10.1109/lics.2009.29",
  xpages =       "179--188",
  year =         "2009",
}

@Article{Leroy2009Coinductive,
  author =       "Xavier Leroy and Herv\'{e} Grall",
  citeulike-article-id = "5447147",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1513247",
  citeulike-linkout-1 = "http://dx.doi.org/10.1016/j.ic.2007.12.004",
  date-added =   "2013-06-01 01:45:12",
  journal =      "Information and Computation",
  month =        feb,
  number =       "2",
  priority =     "2",
  publisher =    "Academic Press, Inc.",
  title =        "Coinductive big-step operational semantics",
  volume =       "207",
  x-abstract =   "Using a call-by-value functional language as an
                 example, this article illustrates the use of
                 coinductive definitions and proofs in big-step
                 operational semantics, enabling it to describe
                 diverging evaluations in addition to terminating
                 evaluations. We formalize the connections between the
                 coinductive big-step semantics and the standard
                 small-step semantics, proving that both semantics are
                 equivalent. We then study the use of coinductive
                 big-step semantics in proofs of type soundness and
                 proofs of semantic preservation for compilers. A
                 methodological originality of this paper is that all
                 results have been proved using the Coq proof assistant.
                 We explain the proof-theoretic presentation of
                 coinductive definitions and proofs offered by Coq, and
                 show that it facilitates the discovery and the
                 presentation of the results.",
  x-address =    "Duluth, MN, USA",
  x-doi =        "10.1016/j.ic.2007.12.004",
  x-issn =       "08905401",
  x-url =        "http://dx.doi.org/10.1016/j.ic.2007.12.004",
  xpages =       "284--304",
  year =         "2009",
}

@Article{Schmidt1998TraceBased,
  author =       "David A. Schmidt",
  citeulike-article-id = "12382116",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=305408",
  citeulike-linkout-1 = "http://dx.doi.org/10.1023/a:1007734417713",
  date-added =   "2013-06-01 01:42:45",
  journal =      "Lisp Symb. Comput.",
  month =        may,
  number =       "3",
  priority =     "2",
  publisher =    "Kluwer Academic Publishers",
  title =        "{Trace-Based} Abstract Interpretation of Operational
                 Semantics",
  volume =       "10",
  x-abstract =   "We present trace-based abstract interpretation, a
                 unification of several lines of research on applying
                 {Cousot-Cousot}-style abstract interpretation a.i. to
                 operational semantics definitions (such as flowchart,
                 big-step, and small-step semantics) that express a
                 program's semantics as a concrete computation tree of
                 trace paths. A program's trace-based a.i. is also a
                 computation tree whose nodes contain abstractions of
                 state and whose paths simulate the paths in the
                 program's concrete computation tree. Using such
                 computation trees, we provide a simple explanation of
                 the central concept of collecting semantics, and we
                 distinguish concrete from abstract collecting semantics
                 and state-based from path-based collecting semantics.
                 We also expose the relationship between collecting
                 semantics extraction and results garnered from
                 flow-analytic and model-checking-based analysis
                 techniques. We adapt concepts from concurrency theory
                 to formalize ” safe” and ” live” a.i.'s for
                 computation trees; in particular, coinduction
                 techniques help extend fundamental results to infinite
                 computation {trees.Problems} specific to the various
                 operational semantics methodologies are discussed:
                 Big-step semantics cannot express divergence, so we
                 employ a mixture of induction and coinduction in
                 response; small-step semantics generate sequences of
                 program configurations unbounded in size, so we
                 abstractly interpret source language syntax.
                 Applications of trace-based a.i. to data-flow analysis,
                 model checking, closure analysis, and concurrency
                 theory are demonstrated.",
  x-address =    "Hingham, MA, USA",
  x-doi =        "10.1023/a:1007734417713",
  x-issn =       "0892-4635",
  x-url =        "http://dx.doi.org/10.1023/a:1007734417713",
  xpages =       "237--271",
  year =         "1998",
}

@InProceedings{Cousot1992Inductive,
  author =       "Patrick Cousot and Radhia Cousot",
  booktitle =    "Proceedings of the 19th ACM SIGPLAN-SIGACT Symposium
                 on Principles of Programming Languages",
  citeulike-article-id = "4744445",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=143184",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/143165.143184",
  date-added =   "2013-06-01 01:39:36",
  location =     "Albuquerque, New Mexico, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "Inductive definitions, semantics and abstract
                 interpretations",
  x-abstract =   "We introduce and illustrate a specification method
                 combining rule-based inductive definitions,
                 well-founded induction principles, fixed-point theory
                 and abstract interpretation for general use in computer
                 science. Finite as well as infinite objects can be
                 specified, at various levels of details related by
                 abstraction. General proof principles are applicable to
                 prove properties of the specified {objects.The}
                 specification method is illustrated by introducing G
                 ∞ {SOS}, a structured operational semantics
                 generalizing Plotkin's [28] structured operational
                 semantics ({SOS}) so as to describe the finite, as well
                 as the infinite behaviors of programs in a uniform way
                 and by constructively deriving inductive presentations
                 of the other (relational, denotational, predicate
                 transformers, …) semantics from G ∞ {SOS} by
                 abstract interpretation.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/143165.143184",
  x-isbn =       "0-89791-453-8",
  x-series =     "POPL '92",
  x-url =        "http://dx.doi.org/10.1145/143165.143184",
  xpages =       "83--94",
  year =         "1992",
}

@Proceedings{DBLP:conf/cav/2011,
  booktitle =    "CAV",
  citeulike-article-id = "12338748",
  date-added =   "2013-05-13 03:41:50",
  priority =     "2",
  publisher =    "Springer",
  title =        "Computer Aided Verification - 23rd International
                 Conference, {CAV} 2011, Snowbird, {UT}, {USA}, July
                 14-20, 2011. Proceedings",
  volume =       "6806",
  x-editor =     "Gopalakrishnan, Ganesh and Qadeer, Shaz",
  x-series =     "Lecture Notes in Computer Science",
  year =         "2011",
}

@InProceedings{DBLP:conf/cav/JhalaMR11,
  author =       "Ranjit Jhala and Rupak Majumdar and Andrey
                 Rybalchenko",
  booktitle =    "CAV",
  citeulike-article-id = "12338747",
  date-added =   "2013-05-13 03:41:50",
  priority =     "2",
  publisher =    "Springer",
  title =        "{HMC}: Verifying Functional Programs Using Abstract
                 Interpreters",
  volume =       "6806",
  x-editor =     "Gopalakrishnan, Ganesh and Qadeer, Shaz",
  x-series =     "Lecture Notes in Computer Science",
  xpages =       "470--485",
  year =         "2011",
}

@Misc{Ponto2011Traces,
  archiveprefix = "arXiv",
  author =       "Kate Ponto and Michael Shulman",
  citeulike-article-id = "9604375",
  citeulike-linkout-0 = "http://arxiv.org/abs/1107.6032",
  citeulike-linkout-1 = "http://arxiv.org/pdf/1107.6032",
  date-added =   "2013-05-13 00:15:51",
  day =          "29",
  eprint =       "1107.6032",
  month =        jul,
  priority =     "2",
  title =        "Traces in symmetric monoidal categories",
  x-abstract =   "The purpose of this expository note is to describe
                 duality and trace in a symmetric monoidal category,
                 along with important properties (including naturality
                 and functoriality), and to give as many examples as
                 possible. Among other things, this note is intended as
                 background for the generalizations to the context of
                 bicategories and indexed monoidal categories.",
  x-url =        "http://arxiv.org/abs/1107.6032",
  year =         "2011",
}

@Article{Joyal1996Traced,
  author =       "Andr\'{e} Joyal and Ross Street and Dominic Verity",
  citeulike-article-id = "4870283",
  citeulike-linkout-0 = "http://journals.cambridge.org/action/displayAbstract?fromPage=online\&aid=2102776",
  citeulike-linkout-1 = "http://dx.doi.org/10.1017/s0305004100074338",
  date-added =   "2013-05-13 00:14:01",
  journal =      "Mathematical Proceedings of the Cambridge
                 Philosophical Society",
  month =        mar,
  number =       "03",
  priority =     "2",
  title =        "Traced monoidal categories",
  volume =       "119",
  x-abstract =   "Traced monoidal categories are introduced, a structure
                 theorem is proved for them, and an example is provided
                 where the structure theorem has application.",
  x-doi =        "10.1017/s0305004100074338",
  x-issn =       "1469-8064",
  x-url =        "http://dx.doi.org/10.1017/s0305004100074338",
  xpages =       "447--468",
  year =         "1996",
}

@Article{Stein2005SAGE,
  author =       "William Stein and David Joyner",
  citeulike-article-id = "6506506",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1101884.1101889",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1101884.1101889",
  date-added =   "2013-05-13 00:09:38",
  journal =      "SIGSAM Bull.",
  month =        jun,
  number =       "2",
  priority =     "2",
  publisher =    "ACM",
  title =        "{SAGE}: system for algebra and geometry
                 experimentation",
  volume =       "39",
  x-abstract =   "{SAGE} is a framework for number theory, algebra, and
                 geometry computation that is initially being designed
                 for computing with elliptic curves and modular forms.
                 The current implementation is primarily due to William
                 Stein. It is open source and freely available under the
                 terms of the {GNU} General Public License ({GPL}).",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1101884.1101889",
  x-issn =       "0163-5824",
  x-url =        "http://dx.doi.org/10.1145/1101884.1101889",
  xpages =       "61--64",
  year =         "2005",
}

@Book{GMRFbook,
  author =       "H. Rue and L. Held",
  citeulike-article-id = "12338620",
  date-added =   "2013-05-12 21:09:21",
  priority =     "2",
  publisher =    "Chapman \& Hall",
  title =        "Gaussian {M}arkov Random Fields: {T}heory and
                 Applications",
  volume =       "104",
  x-address =    "London",
  x-series =     "Monographs on Statistics and Applied Probability",
  year =         "2005",
}

@InProceedings{Friedman1998Learning,
  author =       "Nir Friedman and Kevin Murphy and Stuart Russell",
  booktitle =    "Proceedings of the Fourteenth Conference on
                 Uncertainty in Artificial Intelligence",
  citeulike-article-id = "12338619",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2074111",
  date-added =   "2013-05-12 21:05:15",
  location =     "Madison, Wisconsin",
  priority =     "2",
  publisher =    "Morgan Kaufmann Publishers Inc.",
  title =        "Learning the Structure of Dynamic Probabilistic
                 Networks",
  x-abstract =   "Dynamic probabilistic networks are a compact
                 representation of complex stochastic processes. In this
                 paper we examine how to learn the structure of a {DPN}
                 from data. We extend structure scoring rules for
                 standard probabilistic networks to the dynamic case,
                 and show how to search for structure when some of the
                 variables are hidden. Finally, we examine two
                 applications where such a technology might be useful:
                 predicting and classifying dynamic behaviors, and
                 learning causal orderings in biological processes. We
                 provide empirical results that demonstrate the
                 applicability of our methods in both domains.",
  x-address =    "San Francisco, CA, USA",
  x-isbn =       "1-55860-555-X",
  x-series =     "UAI'98",
  x-url =        "http://portal.acm.org/citation.cfm?id=2074111",
  xpages =       "139--147",
  year =         "1998",
}

@InProceedings{Ghahramani1998Learning,
  author =       "Zoubin Ghahramani",
  booktitle =    "Adaptive Processing of Sequences and Data Structures",
  citeulike-article-id = "4021621",
  citeulike-linkout-0 = "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.56.7874",
  date-added =   "2013-05-12 21:02:33",
  priority =     "2",
  title =        "Learning dynamic Bayesian networks",
  volume =       "1387",
  x-abstract =   "Bayesian networks are directed acyclic graphs that
                 represent dependencies between variables in a
                 probabilistic model. Many time series models, including
                 the hidden Markov models ({HMMs}) used in speech
                 recognition and Kalman filter models used in filtering
                 and control applications, can be viewed as examples of
                 dynamic Bayesian networks. We first provide a brief
                 tutorial on learning and Bayesian networks. We then
                 present some dynamic Bayesian networks that can capture
                 much richer structure than {HMMs} and Kalman filters,
                 including spatial and temporal multiresolution
                 structure, distributed hidden state representations,
                 and multiple switching linear regimes. While exact
                 probabilistic inference is intractable in these
                 networks, one can obtain tractable variational
                 approximations which call as subroutines the
                 forward-backward and Kalman filter recursions. These
                 approximations can be used to learn the model
                 parameters...",
  x-url =        "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.56.7874",
  xpages =       "168--197",
  year =         "1998",
}

@Article{DBLP:journals/jmlr/Winn12,
  author =       "John Winn",
  citeulike-article-id = "12338614",
  date-added =   "2013-05-12 20:58:39",
  journal =      "Journal of Machine Learning Research - Proceedings
                 Track",
  priority =     "2",
  title =        "Causality with Gates",
  volume =       "22",
  xpages =       "1314--1322",
  year =         "2012",
}

@Article{DBLP:journals/corr/abs-1302-2692,
  author =       "Shuying Liang and Matthew Might and Thomas Gilray and
                 David Van{ }Horn",
  citeulike-article-id = "12338574",
  date-added =   "2013-05-12 18:47:29",
  journal =      "CoRR",
  priority =     "2",
  title =        "Pushdown {Exception-Flow} Analysis of
                 {Object-Oriented} Programs",
  volume =       "abs/1302.2692",
  year =         "2013",
}

@Article{Johnson2012Correctly,
  author =       "J. Ian Johnson and Nicholas Labich and Matthew Might
                 and David Van{ }Horn",
  citeulike-article-id = "12338571",
  citeulike-linkout-0 = "http://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1211-3722",
  date-added =   "2013-05-12 18:29:02",
  journal =      "CoRR",
  priority =     "2",
  title =        "Correctly Optimizing Abstract Abstract Machines",
  volume =       "abs/1211.3722",
  x-url =        "http://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1211-3722",
  year =         "2012",
}

@Article{Granger1989Static,
  author =       "Philippe Granger",
  citeulike-article-id = "12336370",
  citeulike-linkout-0 = "http://dx.doi.org/10.1080/00207168908803778",
  citeulike-linkout-1 = "http://www.tandfonline.com/doi/abs/10.1080/00207168908803778",
  date-added =   "2013-05-12 05:21:05",
  day =          "1",
  journal =      "International Journal of Computer Mathematics",
  month =        jan,
  number =       "3-4",
  priority =     "2",
  publisher =    "Taylor \& Francis",
  title =        "Static analysis of arithmetical congruences",
  volume =       "30",
  x-abstract =   "In this paper, a new kind of static (or semantic)
                 analysis is defined: congruence analysis, which is
                 conceived to discover the properties of the following
                 type: ?the integer valued variable X is congruent to c
                 modulo m?, where c and m are automatically determined
                 integers. This analysis is then related to an algebraic
                 framework and wholly characterized. Moreover, we show
                 an example how it can be useful for automatic
                 vectorization. Finally, we present some extensions of
                 it, namely its combination with the analysis of bounds,
                 and also some analyses defined when the modulus of
                 congruences is given a priori.",
  x-doi =        "10.1080/00207168908803778",
  x-url =        "http://dx.doi.org/10.1080/00207168908803778",
  xpages =       "165--190",
  year =         "1989",
}

@InProceedings{Cousot1978Automatic,
  author =       "Patrick Cousot and Nicolas Halbwachs",
  booktitle =    "Proceedings of the 5th ACM SIGACT-SIGPLAN Symposium on
                 Principles of Programming Languages",
  citeulike-article-id = "120467",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=512770",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/512760.512770",
  date-added =   "2013-05-12 05:20:04",
  location =     "Tucson, Arizona",
  priority =     "2",
  publisher =    "ACM",
  title =        "Automatic Discovery of Linear Restraints Among
                 Variables of a Program",
  x-abstract =   "An abstract is not available.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/512760.512770",
  x-series =     "POPL '78",
  x-url =        "http://dx.doi.org/10.1145/512760.512770",
  xpages =       "84--96",
  year =         "1978",
}

@InProceedings{Mine2002Few,
  author =       "Antoine Min{\'{e}}",
  booktitle =    "Proceedings of the 9th International Symposium on
                 Static Analysis",
  citeulike-article-id = "12336369",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=647171.718313",
  date-added =   "2013-05-12 05:17:08",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "A Few {Graph-Based} Relational Numerical Abstract
                 Domains",
  x-abstract =   "This article presents the systematic design of a class
                 of relational numerical abstract domains from
                 non-relational ones. Constructed domains represent sets
                 of invariants of the form (vj - vi \^{A}¿ C), where vj
                 and vi are two variables, and C lives in an abstraction
                 of {P(Z}), {P(Q}), or {P(R}). We will call this family
                 of domains weakly relational domains. The underlying
                 concept allowing this construction is an extension of
                 potential graphs and shortest-path closure algorithms
                 in exotic-like {algebras.Example} constructions are
                 given in order to retrieve well-known domains as well
                 as new ones. Such domains can then be used in the
                 Abstract Interpretation framework in order to design
                 various static analyses. A major benefit of this
                 construction is its modularity, allowing to quickly
                 implement new abstract domains from existing ones.",
  x-address =    "London, UK, UK",
  x-isbn =       "3-540-44235-9",
  x-series =     "SAS '02",
  x-url =        "http://portal.acm.org/citation.cfm?id=647171.718313",
  xpages =       "117--132",
  year =         "2002",
}

@Article{File1996Unifying,
  author =       "Gilberto Fil{\'{e}} and Roberto Giacobazzi and
                 Francesco Ranzato",
  citeulike-article-id = "6998540",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=234528.234742",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/234528.234742",
  date-added =   "2013-05-12 05:15:58",
  journal =      "ACM Comput. Surv.",
  month =        jun,
  number =       "2",
  priority =     "2",
  publisher =    "ACM",
  title =        "A unifying view of abstract domain design",
  volume =       "28",
  x-abstract =   "An abstract is not available.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/234528.234742",
  x-issn =       "0360-0300",
  x-url =        "http://dx.doi.org/10.1145/234528.234742",
  xpages =       "333--336",
  year =         "1996",
}

@InProceedings{Mine2001New,
  author =       "Antoine Min{\'{e}}",
  booktitle =    "Proceedings of the Second Symposium on Programs as
                 Data Objects",
  citeulike-article-id = "12336368",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=668110",
  date-added =   "2013-05-12 05:14:30",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "A New Numerical Abstract Domain Based on
                 {Difference-Bound} Matrices",
  x-abstract =   "This paper presents a new numerical abstract domain
                 for static analysis by abstract interpretation. This
                 domain allows us to represent invariants of the form (x
                 - y ≤ c)an d (±x ≤ c), where x and y are variables
                 values and c is an integer or real constant. Abstract
                 elements are represented by {Difference-Bound}
                 Matrices, widely used by model-checkers, but we had to
                 design new operators to meet the needs of abstract
                 interpretation. The result is a complete lattice of
                 infinite height featuring widening, narrowing and
                 common transfer functions. We focus on giving an
                 efficient O(n2)re presentation and graph-based O(n3)
                 algorithms--where n is the number of variables--and
                 claim that this domain always performs more precisely
                 than the well-known interval domain. To illustrate the
                 precision/cost tradeoff of this domain, we have
                 implemented simple abstract interpreters for toy
                 imperative and parallel languages which allowed us to
                 prove some non-trivial algorithms correct.",
  x-address =    "London, UK, UK",
  x-isbn =       "3-540-42068-1",
  x-series =     "PADO '01",
  x-url =        "http://portal.acm.org/citation.cfm?id=668110",
  xpages =       "155--172",
  year =         "2001",
}

@Article{Mine2006Octagon,
  author =       "Antoine Min\'{e}",
  booktitle =    "Higher-Order and Symbolic Computation",
  citeulike-article-id = "2798522",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1145526",
  citeulike-linkout-1 = "http://dx.doi.org/10.1007/s10990-006-8609-1",
  citeulike-linkout-2 = "http://www.springerlink.com/content/q805711557559810",
  citeulike-linkout-3 = "http://link.springer.com/article/10.1007/s10990-006-8609-1",
  date-added =   "2013-05-12 05:12:37",
  day =          "1",
  journal =      "Higher-Order and Symbolic Computation",
  month =        mar,
  number =       "1",
  priority =     "2",
  publisher =    "Kluwer Academic Publishers",
  title =        "The octagon abstract domain",
  volume =       "19",
  x-abstract =   "This article presents the octagon abstract domain, a
                 relational numerical abstract domain for static
                 analysis by abstract interpretation. It allows
                 representing conjunctions of constraints of the form ±
                 X ± Y ≤ c where X and Y range among program
                 variables and c is a constant in ℤ, ℚ, or ℝ
                 automatically inferred. Abstract elements are
                 represented using modified Difference Bound Matrices
                 and we use a normalization algorithm loosely based on
                 the shortest-path closure to compute canonical
                 representations and construct best-precision abstract
                 transfer functions. We achieve a quadratic memory cost
                 per abstract element and a cubic worst-case time cost
                 per abstract operation, with respect to the number of
                 program variables. In terms of cost and precision, our
                 domain is in between the well-known fast but imprecise
                 interval domain and the costly polyhedron domain. We
                 show that it is precise enough to treat interesting
                 examples requiring relational invariants, and hence,
                 out of the reach of the interval domain. We also
                 present a packing strategy that allows scaling our
                 domain up to large programs by tuning the amount of
                 relationality. The octagon domain was incorporated into
                 the {ASTR\'{E}E} industrial-strength static analyzer
                 and was key in proving the absence of run-time errors
                 in large critical embedded flight control software for
                 Airbus planes.",
  x-address =    "Hingham, MA, USA",
  x-doi =        "10.1007/s10990-006-8609-1",
  x-issn =       "1388-3690",
  x-url =        "http://dx.doi.org/10.1007/s10990-006-8609-1",
  xpages =       "31--100",
  year =         "2006",
}

@Article{Amato2012Abstract,
  author =       "Gianluca Amato and Francesca Scozzari",
  citeulike-article-id = "11639434",
  citeulike-linkout-0 = "http://dx.doi.org/10.1016/j.entcs.2012.09.003",
  date-added =   "2013-05-12 05:07:20",
  journal =      "Electronic Notes in Theoretical Computer Science",
  month =        nov,
  priority =     "2",
  title =        "The Abstract Domain of Parallelotopes",
  volume =       "287",
  x-abstract =   "We propose a numerical abstract domain based on
                 parallelotopes. A parallelotope is a polyhedron whose
                 constraint matrix is squared and invertible. The domain
                 of parallelotopes is a fully relational abstraction of
                 the Cousot and Halbwachs\^{E}¼ polyhedra abstract
                 domain, and does not use templates. We equip the domain
                 of parallelotopes with all the necessary operations for
                 the analysis of imperative programs, and show
                 optimality results for the abstract operators.",
  x-doi =        "10.1016/j.entcs.2012.09.003",
  x-issn =       "15710661",
  x-url =        "http://dx.doi.org/10.1016/j.entcs.2012.09.003",
  xpages =       "17--28",
  year =         "2012",
}

@Article{Cortesi2011Widening,
  author =       "Agostino Cortesi and Matteo Zanioli",
  citeulike-article-id = "7884628",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1869209",
  citeulike-linkout-1 = "http://dx.doi.org/10.1016/j.cl.2010.09.001",
  date-added =   "2013-05-12 04:28:24",
  day =          "21",
  journal =      "Comput. Lang. Syst. Struct.",
  month =        apr,
  number =       "1",
  priority =     "2",
  publisher =    "Elsevier Science Publishers B. V.",
  title =        "Widening and narrowing operators for abstract
                 interpretation",
  volume =       "37",
  x-abstract =   "Abstract Interpretation, one of the most applied
                 techniques for semantics based static analysis of
                 software, is based on two main key-concepts: the
                 correspondence between concrete and abstract semantics
                 through Galois connections/insertions, and the
                 feasibility of a fixed point computation of the
                 abstract semantics, through the fast convergence of
                 widening operators. The latter point is crucial to
                 ensure the scalability of the analysis to large
                 software systems. The aim of this paper is to set the
                 ground for a systematic design of widening and
                 narrowing operators, by comparing the different
                 definitions introduced in the literature and by
                 discussing how to tune them in case of domain
                 abstraction and domains' combination through cartesian
                 and reduced products.",
  x-address =    "Amsterdam, The Netherlands, The Netherlands",
  x-doi =        "10.1016/j.cl.2010.09.001",
  x-issn =       "1477-8424",
  x-url =        "http://dx.doi.org/10.1016/j.cl.2010.09.001",
  xpages =       "24--42",
  year =         "2011",
}

@InProceedings{furr:esop06,
  author =       "Michael Furr and Jeffrey S. Foster",
  booktitle =    "European Symposium on Programming (ESOP)",
  citeulike-article-id = "12336353",
  date-added =   "2013-05-12 03:52:44",
  month =        mar,
  priority =     "2",
  publisher =    "Springer",
  title =        "{Polymorphic Type Inference for the JNI}",
  volume =       "3924",
  x-address =    "Vienna, Austria",
  x-series =     "Lecture Notes in Computer Science",
  xpages =       "309--324",
  year =         "2006",
}

@InProceedings{furr:oops09,
  author =       "Michael Furr and Jong hoon David An and Jeffrey S.
                 Foster and Michael Hicks",
  booktitle =    "Object-Oriented Program Languages and Systems (OOPS)
                 Track at ACM Symposium on Applied Computing (SAC)",
  citeulike-article-id = "12336352",
  date-added =   "2013-05-12 03:52:44",
  month =        mar,
  priority =     "2",
  title =        "{Static Type Inference for Ruby}",
  x-address =    "Honolulu, Hawaii",
  xpages =       "1859--1866",
  year =         "2009",
}

@InProceedings{khoo:pldi10,
  author =       "Yit P. Khoo and Bor-Yuh E. Chang and Jeffrey S.
                 Foster",
  booktitle =    "Proceedings of the 2010 ACM SIGPLAN Conference on
                 Programming Language Design and Implementation (PLDI)",
  citeulike-article-id = "12336351",
  date-added =   "2013-05-12 03:52:44",
  month =        jun,
  priority =     "2",
  title =        "{Mixing Type Checking and Symbolic Execution}",
  x-address =    "Toronto, Canada",
  xpages =       "436--447",
  year =         "2010",
}

@InProceedings{chaudhuri:ccs10,
  author =       "Avik Chaudhuri and Jeffrey S. Foster",
  booktitle =    "Proceedings of the 17th ACM Conference on Computer and
                 Communications Security (CCS)",
  citeulike-article-id = "12336350",
  date-added =   "2013-05-12 03:52:44",
  month =        oct,
  priority =     "2",
  title =        "{Symbolic Security Analysis of Ruby-on-Rails Web
                 Applications}",
  x-address =    "Chicago, IL, USA",
  xpages =       "585--594",
  year =         "2010",
}

@InProceedings{an:popl11,
  author =       "Jong hoon David An and Avik Chaudhuri and Jeffrey S.
                 Foster and Michael Hicks",
  booktitle =    "ACM SIGPLAN-SIGACT Symposium on Principles of
                 Programming Languages (POPL)",
  citeulike-article-id = "12336349",
  date-added =   "2013-05-12 03:52:44",
  month =        jan,
  priority =     "2",
  title =        "{Dynamic Inference of Static Types for Ruby}",
  x-address =    "Austin, TX, USA",
  xpages =       "459--472",
  year =         "2011",
}

@InProceedings{jeon:spsm12,
  author =       "Jinseong Jeon and Kristopher K. Micinski and Jeffrey
                 A. Vaughan and Ari Fogel and Nikhilesh Reddy and
                 Jeffrey S. Foster and Todd Millstein",
  booktitle =    "ACM CCS Workshop on Security and Privacy in
                 Smartphones and Mobile Devices (SPSM)",
  citeulike-article-id = "12336348",
  date-added =   "2013-05-12 03:52:43",
  month =        oct,
  priority =     "2",
  title =        "{Dr. Android and Mr. Hide: Fine-grained Permissions in
                 Android Applications}",
  x-address =    "Raleigh, NC, USA",
  xpages =       "3--14",
  year =         "2012",
}

@InProceedings{Kohlbecker1987Macrobyexample,
  author =       "E. E. Kohlbecker and M. Wand",
  booktitle =    "Proceedings of the 14th ACM SIGACT-SIGPLAN Symposium
                 on Principles of Programming Languages",
  citeulike-article-id = "190436",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=41632",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/41625.41632",
  date-added =   "2013-05-12 01:11:38",
  location =     "Munich, West Germany",
  priority =     "2",
  publisher =    "ACM",
  title =        "Macro-by-example: Deriving syntactic transformations
                 from their specifications",
  x-abstract =   "This paper presents two new developments. First, it
                 describes a ” macro-by-example” specification
                 language for syntactic abstractions in Lisp and related
                 languages. This specification language allows a more
                 declarative specification of macros than conventional
                 macro facilities do by giving a better treatment of
                 iteration and mapping constructs. Second, it gives a
                 formal semantics for the language and a derivation of a
                 compiler from the semantics. This derivation is a
                 practical application of semantics-directed compiler
                 development methodology.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/41625.41632",
  x-isbn =       "0-89791-215-2",
  x-series =     "POPL '87",
  x-url =        "http://dx.doi.org/10.1145/41625.41632",
  xpages =       "77--84",
  year =         "1987",
}

@Article{Felleisen2004Building,
  author =       "Matthias Felleisen and Robert B. Findler and Matthew
                 Flatt and Shriram Krishnamurthi",
  citeulike-article-id = "12336323",
  citeulike-linkout-0 = "http://www.drdobbs.com/architecture-and-design/building-little-languages-with-macros/184405618",
  date-added =   "2013-05-12 01:05:39",
  journal =      "Dr. Dobb's",
  priority =     "2",
  title =        "Building Little Languages with Macros",
  x-url =        "http://www.drdobbs.com/architecture-and-design/building-little-languages-with-macros/184405618",
  year =         "2004",
}

@Article{Culpepper2010Debugging,
  author =       "Ryan Culpepper and Matthias Felleisen",
  citeulike-article-id = "5333767",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1773163",
  citeulike-linkout-1 = "http://dx.doi.org/10.1016/j.scico.2009.06.001",
  date-added =   "2013-05-12 01:01:20",
  day =          "17",
  journal =      "Sci. Comput. Program.",
  month =        jul,
  number =       "7",
  priority =     "2",
  publisher =    "Elsevier North-Holland, Inc.",
  title =        "Debugging hygienic macros",
  volume =       "75",
  x-abstract =   "Over the past two decades, Scheme macros have evolved
                 into a powerful {API} for the compiler front end. Like
                 Lisp macros, their predecessors, Scheme macros expand
                 source programs into a small core language; unlike Lisp
                 systems, Scheme macro expanders preserve lexical
                 scoping, and advanced Scheme macro systems handle other
                 important properties such as source location. Using
                 such macros, Scheme programmers now routinely develop
                 the ultimate abstraction: embedded domain-specific
                 programming languages. Unfortunately, a typical Scheme
                 programming environment provides little support for
                 macro development. This lack makes it difficult for
                 programmers to debug their macros and for novices to
                 study the behavior of macros. In response, we have
                 developed a stepping debugger specialized to the
                 concerns of macro expansion. This debugger presents the
                 macro expansion process as a linear rewriting sequence
                 of annotated terms; it graphically illustrates the
                 binding structure of the program as expansion reveals
                 it; and it adapts to the programmer's level of
                 abstraction, hiding details of syntactic forms that the
                 programmer considers built-in.",
  x-address =    "Amsterdam, The Netherlands, The Netherlands",
  x-doi =        "10.1016/j.scico.2009.06.001",
  x-issn =       "0167-6423",
  x-url =        "http://dx.doi.org/10.1016/j.scico.2009.06.001",
  xpages =       "496--515",
  year =         "2010",
}

@Article{Flanagan1999Componential,
  author =       "Cormac Flanagan and Matthias Felleisen",
  citeulike-article-id = "4155",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=316703",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/316686.316703",
  date-added =   "2013-05-12 00:58:51",
  journal =      "ACM Trans. Program. Lang. Syst.",
  month =        mar,
  number =       "2",
  priority =     "2",
  publisher =    "ACM",
  title =        "Componential set-based analysis",
  volume =       "21",
  x-abstract =   "Set-based analysis ({SBA}) produces good predictions
                 about the behavior of functional and object-oriented
                 programs. The analysis proceeds by inferring
                 constraints that characterize the data flow
                 relationships of the analyzed program. Experiences with
                 {MrSpidey}, a static debugger based on {SBA}, indicate
                 that {SBA} can adequately deal with programs of up to a
                 couple of thousand lines of code. {SBA} fails, however,
                 to cope with larger programs because it generates
                 systems of constraints that are at least linear, and
                 possibility quadratic, in the size of the analyzed
                 program. This article presents theoretical and
                 practical results concerning methods for reducing the
                 size of constraint systems. The theoretical results
                 include of proof-theoretic characterization of the
                 observable behavior of constraint systems for program
                 components, and a complete algorithm for deciding the
                 observable equivalence of constraint systems. In the
                 course of this development we establish a close
                 connection between the observable equivalence of
                 constraint systems and the equivalence of regular-tree
                 grammars. We then exploit this connection to adapt a
                 variety of algoirthms for simplifying grammars to the
                 problem of simplifying constraint systems. Based on the
                 resulting algorithms, we have developed componential
                 set-based analysis, a modular and polymorphic variant
                 of {SBA}. Experimental results verify the effectiveness
                 of the simplification algorithms and the componential
                 analysis. The simplified constraint systems are
                 typically an order of magnitude smaller than the
                 original systems. These reductions in size produce
                 significant gains in the speed of the analysis.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/316686.316703",
  x-issn =       "0164-0925",
  x-url =        "http://dx.doi.org/10.1145/316686.316703",
  xpages =       "370--416",
  year =         "1999",
}

@InProceedings{Flatt2009Scribble,
  author =       "Matthew Flatt and Eli Barzilay and Robert B. Findler",
  booktitle =    "Proceedings of the 14th ACM SIGPLAN International
                 Conference on Functional Programming",
  citeulike-article-id = "5724331",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1596550.1596569",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1596550.1596569",
  date-added =   "2013-05-12 00:52:57",
  location =     "Edinburgh, Scotland",
  priority =     "2",
  publisher =    "ACM",
  title =        "Scribble: closing the book on ad hoc documentation
                 tools",
  x-abstract =   "Scribble is a system for writing library
                 documentation, user guides, and tutorials. It builds on
                 {PLT} Scheme's technology for language extension, and
                 at its heart is a new approach to connecting prose
                 references with library bindings. Besides the base
                 system, we have built Scribble libraries for
                 {JavaDoc}-style {API} documentation, literate
                 programming, and conference papers. We have used
                 Scribble to produce thousands of pages of documentation
                 for {PLT} Scheme; the new documentation is more
                 complete, more accessible, and better organized, thanks
                 in large part to Scribble's flexibility and the ease
                 with which we cross-reference information across
                 levels. This paper reports on the use of Scribble and
                 on its design as both an extension and an extensible
                 part of {PLT} Scheme.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1596550.1596569",
  x-isbn =       "978-1-60558-332-7",
  x-series =     "ICFP '09",
  x-url =        "http://dx.doi.org/10.1145/1596550.1596569",
  xpages =       "109--120",
  year =         "2009",
}

@InCollection{Chang2013Laziness,
  author =       "Stephen Chang",
  booktitle =    "Programming Languages and Systems",
  citeulike-article-id = "12336316",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-642-37036-6\_5",
  citeulike-linkout-1 = "http://link.springer.com/chapter/10.1007/978-3-642-37036-6\_5",
  date-added =   "2013-05-12 00:50:43",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "Laziness by Need",
  volume =       "7792",
  x-abstract =   "Lazy functional programming has many benefits that
                 strict functional languages can simulate via lazy data
                 constructors. In recognition, {ML}, Scheme, and other
                 strict functional languages have supported lazy stream
                 programming with delaytt and forcett for several
                 decades. Unfortunately, the manual insertion of delaytt
                 and forcett can be tedious and error-prone. We present
                 a semantics-based refactoring that helps strict
                 programmers manage manual lazy programming. The
                 refactoring uses a static analysis to identify where
                 additional delaytts and forcetts might be needed to
                 achieve the desired simplification and performance
                 benefits, once the programmer has added the initial
                 lazy data constructors. The paper presents a
                 correctness argument for the underlying transformations
                 and some preliminary experiences with a prototype tool
                 implementation.",
  x-doi =        "10.1007/978-3-642-37036-6\_5",
  x-editor =     "Felleisen, Matthias and Gardner, Philippa",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-642-37036-6\_5",
  xpages =       "81--100",
  year =         "2013",
}

@InProceedings{StAmour2012Optimization,
  author =       "Vincent St-Amour and Sam Tobin-Hochstadt and Matthias
                 Felleisen",
  booktitle =    "OOPSLA '12 Proceedings of the ACM International
                 Conference on Object Oriented Programming Systems
                 Languages and Applications",
  citeulike-article-id = "12336314",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2384629",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2398857.2384629",
  date-added =   "2013-05-12 00:46:59",
  month =        oct,
  priority =     "2",
  publisher =    "ACM",
  title =        "Optimization coaching: optimizers learn to communicate
                 with programmers",
  x-abstract =   "Optimizing compilers map programs in high-level
                 languages to high-performance target language code. To
                 most programmers, such a compiler constitutes an
                 impenetrable black box whose inner workings are beyond
                 their understanding. Since programmers often must
                 understand the workings of their compilers to achieve
                 their desired performance goals, they typically resort
                 to various forms of reverse engineering, such as
                 examining compiled code or intermediate forms. Instead,
                 optimizing compilers should engage programmers in a
                 dialog. This paper introduces one such possible form of
                 dialog: optimization coaching. An optimization coach
                 watches while a program is compiled, analyzes the
                 results, generates suggestions for enabling further
                 compiler optimization in the source program, and
                 presents a suitable synthesis of its results to the
                 programmer. We present an evaluation based on case
                 studies, which illustrate how an optimization coach can
                 help programmers achieve optimizations resulting in
                 substantial performance improvements.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2398857.2384629",
  x-issn =       "0362-1340",
  x-url =        "http://dx.doi.org/10.1145/2398857.2384629",
  xpages =       "163--178",
  year =         "2012",
}

@Article{Fisher2008Building,
  author =       "David Fisher and Olin Shivers",
  citeulike-article-id = "12336313",
  citeulike-linkout-0 = "http://journals.cambridge.org/action/displayAbstract?fromPage=online\&aid=2519912",
  citeulike-linkout-1 = "http://dx.doi.org/10.1017/s0956796808006928",
  date-added =   "2013-05-12 00:45:14",
  journal =      "Journal of Functional Programming",
  month =        aug,
  priority =     "2",
  title =        "Building language towers with Ziggurat",
  volume =       "18",
  x-abstract =   "Ziggurat is a meta-language system that permits
                 programmers to develop Scheme-like macros for languages
                 with nontrivial static semantics, such as C or Java
                 (suitably encoded in an S-expression concrete syntax).
                 Ziggurat permits language designers to construct
                 'towers' of language levels with macros; each level in
                 the tower may have its own static semantics, such as
                 type systems or flow analyses. Crucially, the static
                 semantics of the languages at two adjacent levels in
                 the tower can be connected, allowing improved reasoning
                 power at a higher level to be reflected down to the
                 static semantics of the language level below. We
                 demonstrate the utility of the Ziggurat framework by
                 implementing higher level language facilities as macros
                 on top of an assembly language, utilizing static
                 semantics such as termination analysis, a polymorphic
                 type system and higher order flow analysis.",
  x-doi =        "10.1017/s0956796808006928",
  x-issn =       "1469-7653",
  x-url =        "http://dx.doi.org/10.1017/s0956796808006928",
  xpages =       "707--780",
  year =         "2008",
}

@InProceedings{Culpepper2010Fortifying,
  author =       "Ryan Culpepper and Matthias Felleisen",
  booktitle =    "ICFP '10 Proceedings of the 15th ACM SIGPLAN
                 International Conference on Functional Programming",
  citeulike-article-id = "12336311",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1863577",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1932681.1863577",
  date-added =   "2013-05-12 00:40:14",
  month =        sep,
  priority =     "2",
  publisher =    "ACM",
  title =        "Fortifying macros",
  x-abstract =   "Existing macro systems force programmers to make a
                 choice between clarity of specification and robustness.
                 If they choose clarity, they must forgo validating
                 significant parts of the specification and thus produce
                 low-quality language extensions. If they choose
                 robustness, they must write in a style that mingles the
                 implementation with the specification and therefore
                 obscures the latter. This paper introduces a new
                 language for writing macros. With the new macro system,
                 programmers naturally write robust language extensions
                 using easy-to-understand specifications. The system
                 translates these specifications into validators that
                 detect misuses - including violations of
                 context-sensitive constraints - and automatically
                 synthesize appropriate feedback, eliminating the need
                 for ad hoc validation code.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1932681.1863577",
  x-issn =       "0362-1340",
  x-url =        "http://dx.doi.org/10.1145/1932681.1863577",
  xpages =       "235--246",
  year =         "2010",
}

@Article{DBLP:journals/jcss/Wand79,
  author =       "Mitchell Wand",
  citeulike-article-id = "12336308",
  date-added =   "2013-05-12 00:28:15",
  journal =      "J. Comput. Syst. Sci.",
  number =       "1",
  priority =     "2",
  title =        "Final Algebra Semantics and Data Type Extensions",
  volume =       "19",
  xpages =       "27--44",
  year =         "1979",
}

@Article{DBLP:journals/iandc/CartwrightCF94,
  author =       "Robert Cartwright and Pierre-Louis Curien and Matthias
                 Felleisen",
  citeulike-article-id = "12336307",
  date-added =   "2013-05-12 00:25:28",
  journal =      "Inf. Comput.",
  number =       "2",
  priority =     "2",
  title =        "Fully Abstract Semantics for Observably Sequential
                 Languages",
  volume =       "111",
  xpages =       "297--401",
  year =         "1994",
}

@InCollection{Matthews2004Visual,
  author =       "Jacob Matthews and RobertBruce Findler and Matthew
                 Flatt and Matthias Felleisen",
  booktitle =    "Rewriting Techniques and Applications",
  citeulike-article-id = "12335584",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-540-25979-4\_21",
  citeulike-linkout-1 = "http://link.springer.com/chapter/10.1007/978-3-540-25979-4\_21",
  date-added =   "2013-05-11 02:26:22",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "A Visual Environment for Developing
                 {Context-Sensitive} Term Rewriting Systems",
  volume =       "3091",
  x-abstract =   "Over the past decade, researchers have found
                 context-sensitive term-rewriting semantics to be
                 powerful and expressive tools for modeling programming
                 languages, particularly in establishing type soundness
                 proofs. Unfortunately, developing such semantics is an
                 error-prone activity. To address that problem, we have
                 designed {PLT} Redex, an embedded domain-specific
                 language that helps users interactively create and
                 debug context-sensitive term-rewriting systems. We
                 introduce the tool with a series of examples and
                 discuss our experience using it in courses and
                 developing an operational semantics for {R5RS}
                 Scheme.",
  x-doi =        "10.1007/978-3-540-25979-4\_21",
  x-editor =     "Oostrom, Vincent",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-540-25979-4\_21",
  xpages =       "301--311",
  year =         "2004",
}

@InProceedings{Klein2012Run,
  author =       "Casey Klein and John Clements and Christos Dimoulas
                 and Carl Eastlund and Matthias Felleisen and Matthew
                 Flatt and Jay A. McCarthy and Jon Rafkind and Sam T.
                 Hochstadt and Robert B. Findler",
  booktitle =    "POPL '12 Proceedings of the 39th annual ACM
                 SIGPLAN-SIGACT Symposium on Principles of Programming
                 Languages",
  citeulike-article-id = "12335583",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2103691",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2103621.2103691",
  date-added =   "2013-05-11 02:22:53",
  month =        jan,
  priority =     "2",
  publisher =    "ACM",
  title =        "Run Your Research: On the Effectiveness of Lightweight
                 Mechanization",
  x-abstract =   "Formal models serve in many roles in the programming
                 language community. In its primary role, a model
                 communicates the idea of a language design; the
                 architecture of a language tool; or the essence of a
                 program analysis. No matter which role it plays,
                 however, a faulty model doesn't serve its purpose. One
                 way to eliminate flaws from a model is to write it down
                 in a mechanized formal language. It is then possible to
                 state theorems about the model, to prove them, and to
                 check the proofs. Over the past nine years, {PLT} has
                 developed and explored a lightweight version of this
                 approach, dubbed Redex. In a nutshell, Redex is a
                 domain-specific language for semantic models that is
                 embedded in the Racket programming language. The effort
                 of creating a model in Redex is often no more
                 burdensome than typesetting it with {LaTeX}; the
                 difference is that Redex comes with tools for the
                 semantics engineering life cycle.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2103621.2103691",
  x-issn =       "0362-1340",
  x-url =        "http://dx.doi.org/10.1145/2103621.2103691",
  xpages =       "285--296",
  year =         "2012",
}

@InProceedings{Blanchet2003Static,
  author =       "Bruno Blanchet and Patrick Cousot and Radhia Cousot
                 and J\'{e}rome Feret and Laurent Mauborgne and Antoine
                 Min\'{e} and David Monniaux and Xavier Rival",
  booktitle =    "Proceedings of the ACM SIGPLAN Conference on
                 Programming Language Design and Implementation",
  citeulike-article-id = "2353363",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=781153",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/781131.781153",
  date-added =   "2013-05-09 17:14:07",
  journal =      "SIGPLAN Not.",
  location =     "San Diego, California, USA",
  month =        may,
  number =       "5",
  priority =     "2",
  publisher =    "ACM",
  title =        "A Static Analyzer for Large Safety-critical Software",
  volume =       "38",
  x-abstract =   "We show that abstract interpretation-based static
                 program analysis can be made efficient and precise
                 enough to formally verify a class of properties for a
                 family of large programs with few or no false alarms.
                 This is achieved by refinement of a general purpose
                 static analyzer and later adaptation to particular
                 programs of the family by the end-user through
                 parametrization. This is applied to the proof of
                 soundness of data manipulation operations at the
                 machine level for periodic synchronous safety critical
                 embedded {software.The} main novelties are the design
                 principle of static analyzers by refinement and
                 adaptation through parametrization (Sect. 3 and 7), the
                 symbolic manipulation of expressions to improve the
                 precision of abstract transfer functions (Sect. 6.3),
                 the octagon (Sect. 6.2.2), ellipsoid (Sect. 6.2.3), and
                 decision tree (Sect. 6.2.4) abstract domains, all with
                 sound handling of rounding errors in oating point
                 computations, widening strategies (with thresholds:
                 Sect. 7.1.2, delayed: Sect. 7.1.3) and the automatic
                 determination of the parameters (parametrized packing:
                 Sect. 7.2).",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/781131.781153",
  x-isbn =       "1-58113-662-5",
  x-issn =       "0362-1340",
  x-series =     "PLDI '03",
  x-url =        "http://dx.doi.org/10.1145/781131.781153",
  xpages =       "196--207",
  year =         "2003",
}

@InCollection{Monniaux2000Abstract,
  author =       "David Monniaux",
  booktitle =    "Static Analysis",
  citeulike-article-id = "12333705",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-540-45099-3\_17",
  citeulike-linkout-1 = "http://link.springer.com/chapter/10.1007/978-3-540-45099-3\_17",
  date-added =   "2013-05-09 16:02:58",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "Abstract Interpretation of Probabilistic Semantics",
  volume =       "1824",
  x-abstract =   "Following earlier models, we lift standard
                 deterministic and nondeterministic semantics of
                 imperative programs to probabilistic semantics. This
                 semantics allows for random external inputs of known or
                 unknown probability and random number generators. We
                 then propose a method for analysing programs according
                 to this semantics, in the general framework of abstract
                 interpretation. This method lifts an ” ordinary”
                 abstract lattice, for non-probabilistic programs, to
                 one suitable for probabilistic programs. Our
                 construction is highly generic. We discuss the
                 influence of certain parameters on the precision of the
                 analysis, basing ourselves on experimental results.",
  x-doi =        "10.1007/978-3-540-45099-3\_17",
  x-editor =     "Palsberg, Jens",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-540-45099-3\_17",
  xpages =       "322--339",
  year =         "2000",
}

@InCollection{Cousot2012Probabilistic,
  author =       "Patrick Cousot and Michael Monerau",
  booktitle =    "Programming Languages and Systems",
  citeulike-article-id = "12333704",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-642-28869-2\_9",
  citeulike-linkout-1 = "http://link.springer.com/chapter/10.1007/978-3-642-28869-2\_9",
  date-added =   "2013-05-09 16:01:49",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "Probabilistic Abstract Interpretation",
  volume =       "7211",
  x-abstract =   "Abstract interpretation has been widely used for
                 verifying properties of computer systems. Here, we
                 present a way to extend this framework to the case of
                 probabilistic systems. The probabilistic abstraction
                 framework that we propose allows us to systematically
                 lift any classical analysis or verification method to
                 the probabilistic setting by separating in the program
                 semantics the probabilistic behavior from the
                 (non-)deterministic behavior. This separation provides
                 new insights for designing novel probabilistic static
                 analyses and verification methods. We define the
                 concrete probabilistic semantics and propose different
                 ways to abstract them. We provide examples illustrating
                 the expressiveness and effectiveness of our approach.",
  x-doi =        "10.1007/978-3-642-28869-2\_9",
  x-editor =     "Seidl, Helmut",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-642-28869-2\_9",
  xpages =       "169--193",
  year =         "2012",
}

@InProceedings{Kiselyov2009Embedded,
  author =       "Oleg Kiselyov and Chung C. Shan",
  booktitle =    "Proceedings of the IFIP TC 2 Working Conference on
                 Domain-Specific Languages",
  chapter =      "17",
  citeulike-article-id = "8330350",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1575971",
  citeulike-linkout-1 = "http://dx.doi.org/10.1007/978-3-642-03034-5\_17",
  citeulike-linkout-2 = "http://www.springerlink.com/content/e03504147589x005",
  date-added =   "2013-05-08 21:39:03",
  location =     "Oxford, UK",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "Embedded Probabilistic Programming",
  volume =       "5658",
  x-abstract =   "Two general techniques for implementing a
                 domain-specific language ({DSL}) with less overhead are
                 the <em>finally-tagless</em> embedding of object
                 programs and the <em>direct-style</em> representation
                 of side effects. We use these techniques to build a
                 {DSL} for <em>probabilistic programming</em> , for
                 expressing countable probabilistic models and
                 performing exact inference and importance sampling on
                 them. Our language is embedded as an ordinary {OCaml}
                 library and represents probability distributions as
                 ordinary {OCaml} programs. We use delimited
                 continuations to reify probabilistic programs as lazy
                 search trees, which inference algorithms may traverse
                 without imposing any interpretive overhead on
                 deterministic parts of a model. We thus take advantage
                 of the existing {OCaml} implementation to achieve
                 competitive performance and ease of use. Inference
                 algorithms can easily be embedded in probabilistic
                 programs themselves.",
  x-address =    "Berlin, Heidelberg",
  x-doi =        "10.1007/978-3-642-03034-5\_17",
  x-isbn =       "978-3-642-03033-8",
  x-series =     "DSL '09",
  x-url =        "http://dx.doi.org/10.1007/978-3-642-03034-5\_17",
  xpages =       "360--384",
  year =         "2009",
}

@InProceedings{WSG11,
  author =       "David Wingate and Andreas Stuhlm{\"{u}}ller and Noah
                 D. Goodman",
  booktitle =    "Proc. of the 14th Artificial Intelligence and
                 Statistics",
  citeulike-article-id = "12331919",
  citeulike-linkout-0 = "http://stanford.edu/\~{}ngoodman/papers/WSG-AIStats11.pdf",
  date-added =   "2013-05-08 21:34:43",
  priority =     "2",
  title =        "Lightweight Implementations of Probabilistic
                 Programming Languages Via Transformational
                 Compilation",
  x-url =        "http://stanford.edu/\~{}ngoodman/papers/WSG-AIStats11.pdf",
  year =         "2011",
}

@InProceedings{Goodman2008Church,
  author =       "Noah D. Goodman and Vikash K. Mansinghka and Daniel
                 Roy and Keith Bonawitz and Joshua B. Tenenbaum",
  booktitle =    "Uncertainty in Artificial Intelligence",
  citeulike-article-id = "2805713",
  citeulike-linkout-0 = "http://web.mit.edu/droy/www/papers/GooManRoyBonTenUAI2008.pdf",
  date-added =   "2013-05-08 21:32:05",
  keywords =     "church, generative, models, non-parametric",
  priority =     "2",
  title =        "Church: a language for generative models",
  x-url =        "http://web.mit.edu/droy/www/papers/GooManRoyBonTenUAI2008.pdf",
  year =         "2008",
}

@InProceedings{TobinHochstadt2011Languages,
  author =       "Sam Tobin-Hochstadt and Vincent St-Amour and Ryan
                 Culpepper and Matthew Flatt and Matthias Felleisen",
  booktitle =    "Proceedings of the 32nd ACM SIGPLAN Conference on
                 Programming Language Design and Implementation",
  citeulike-article-id = "9534653",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1993514",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1993498.1993514",
  date-added =   "2013-05-08 05:53:42",
  location =     "San Jose, California, USA",
  month =        jun,
  priority =     "2",
  publisher =    "ACM",
  title =        "Languages As Libraries",
  x-abstract =   "Programming language design benefits from constructs
                 for extending the syntax and semantics of a host
                 language. While C's string-based macros empower
                 programmers to introduce notational shorthands, the
                 parser-level macros of Lisp encourage experimentation
                 with domain-specific languages. The Scheme programming
                 language improves on Lisp with macros that respect
                 lexical scope. The design of Racket---a descendant of
                 Scheme---goes even further with the introduction of a
                 full-fledged interface to the static semantics of the
                 language. A Racket extension programmer can thus add
                 constructs that are indistinguishable from {"}native{"}
                 notation, large and complex embedded domain-specific
                 languages, and even optimizing transformations for the
                 compiler backend. This power to experiment with
                 language design has been used to create a series of
                 sub-languages for programming with first-class classes
                 and modules, numerous languages for implementing the
                 Racket system, and the creation of a complete and fully
                 integrated typed sister language to Racket's untyped
                 base language. This paper explains Racket's language
                 extension {API} via an implementation of a small typed
                 sister language. The new language provides a rich type
                 system that accommodates the idioms of untyped Racket.
                 Furthermore, modules in this typed language can safely
                 exchange values with untyped modules. Last but not
                 least, the implementation includes a type-based
                 optimizer that achieves promising speedups. Although
                 these extensions are complex, their Racket
                 implementation is just a library, like any other
                 library, requiring no changes to the Racket
                 implementation.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1993498.1993514",
  x-isbn =       "978-1-4503-0663-8",
  x-issn =       "0362-1340",
  x-series =     "PLDI",
  x-url =        "http://dx.doi.org/10.1145/1993498.1993514",
  xpages =       "132--141",
  year =         "2011",
}

@Book{Kaufmann2000ComputerAided,
  author =       "Matt Kaufmann and J. Strother Moore and Panagiotis
                 Manolios",
  citeulike-article-id = "6014020",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=555902",
  date-added =   "2013-04-13 23:29:35",
  priority =     "2",
  publisher =    "Kluwer Academic Publishers",
  title =        "{Computer-Aided} Reasoning: An Approach",
  x-abstract =   {From the {Publisher:An} Approach {Computer-Aided}
                 Reasoning: An Approach is a textbook introduction to
                 computer-aided reasoning. It can be used in graduate
                 and upper-division undergraduate courses on software
                 engineering or formal methods. It is also suitable in
                 conjunction with other books in courses on hardware
                 design, discrete mathematics, or theory, especially
                 courses stressing formalism, rigor, or mechanized
                 support. It is also appropriate for courses on
                 artificial intelligence or automated reasoning and as a
                 reference for business and industry. Current hardware
                 and software systems are often very complex and the
                 trend is towards increased complexity. Many of these
                 systems are of critical importance; therefore making
                 sure that they behave as expected is also of critical
                 importance. By modeling computing systems
                 mathematically, we obtain models that we can prove
                 behave correctly. The complexity of computing systems
                 makes such proofs very long, complicated, and
                 error-prone. To further increase confidence in our
                 reasoning, we can use a computer program to check our
                 proofs and even to automate some of their construction.
                 In this book we present: A practical functional
                 programming language closely related to Common Lisp
                 which is used to define functions (which can model
                 computing systems) and to make assertions about defined
                 functions; A formal logic in which defined functions
                 correspond to axioms; the logic is first-order,
                 includes induction, and allows us to prove theorems
                 about the functions; The computer-aided reasoning
                 system {ACL2}, which includes the programming language,
                 the logic, and mechanical support for the proof
                 process. The {ACL2} system hasbeen successfully applied
                 to projects of commercial interest, including
                 microprocessor, modeling, hardware verification,
                 microcode verification, and software verification. This
                 book gives a methodology for modeling computing systems
                 formally and for reasoning about those models with
                 mechanized assistance. The practicality of
                 computer-aided reasoning is further demonstrated in the
                 companion book, {Computer-Aided} Reasoning: {ACL2} Case
                 Studies. Approximately 140 exercises are distributed
                 throughout the book. Additional material is freely
                 available from the {ACL2} home page on the Web,
                 http://www.cs.utexas.edu/users/moore/ac12, including
                 solutions to the exercises, additional exercises, case
                 studies from the companion book, research papers, and
                 the {ACL2} system with detailed documentation. {ACL2}
                 Case Studies {Computer-Aided} Reasoning: {ACL2} Case
                 Studies illustrates how the computer-aided reasoning
                 system {ACL2} can be used in productive and innovative
                 ways to design, build, and maintain hardware and
                 software systems. Included here are technical papers
                 written by twenty-one contributors that report on
                 self-contained case studies, some of which are
                 sanitized industrial projects. The papers deal with a
                 wide variety of ideas, including floating-point
                 arithmetic, microprocessor simulation, model checking,
                 symbolic trajectory evaluation, compilation, proof
                 checking, real analysis, and several others.
                 {Computer-Aided} Reasoning: {ACL2} Case Studies is
                 meant for two audiences: those looking for innovative
                 ways to design, build, and maintain hardware and
                 software systems faster and more reliably, and those
                 wishing to learn how to do this. The former audience
                 includes project managers and students in
                 survey-oriented courses. The latter audience includes
                 students and professionals pursuing rigorous approaches
                 to hardware and software engineering or formal methods.
                 {Computer-Aided} Reasoning: {ACL2} Case Studies can be
                 used in graduate and upper-division undergraduate
                 courses on Software Engineering, Formal Methods,
                 Hardware Design, Theory of Computation, Artificial
                 Intelligence, and Automated Reasoning. The book is
                 divided into two parts. Part I begins with a discussion
                 of the effort involved in using {ACL2}. It also
                 contains a brief introduction to the {ACL2} logic and
                 its mechanization, which is intended to give the reader
                 sufficient background to read the case studies. A m
?? BibTeX string too long for field ``x-abstract''.
ore thorough, textbook introduction to {ACL2} may be found in the companion book, {Computer-Aided} Reasoning: An Approach.  The heart of the book is Part {II}, where the case studies are presented. The case studies contain exercises whose solutions are on the Web. In addition, the complete {ACL2} scripts necessary to formalize the models and prove all the properties discussed are on the Web. For example, when we say that one of the case studies formalizes a floating-point multiplier and proves it correct, we mean that not only can you read an English description of the model and how it was proved correct, but you can obtain the entire formal content of the project and replay the proofs, if you wish, with your copy of {ACL2}. {ACL2} may be obtained from its home page, http://www.cs.utexas.edu/users/moore/ac12. The results reported in each case study, as {ACL2} input scripts, as well as exercise solutions for both books, are available from this page.},
    x-address = {Norwell, MA, USA},
    x-isbn = {0792377443},
    x-url = {http://portal.acm.org/citation.cfm?id=555902},
    year = {2000}
}

@InProceedings{Proulx2006Design,
  author =       "Viera K. Proulx and Kathryn E. Gray",
  booktitle =    "Proceedings of the 37th SIGCSE technical symposium on
                 Computer science education",
  citeulike-article-id = "12268176",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1121341.1121431",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1121341.1121431",
  date-added =   "2013-04-13 22:07:37",
  location =     "Houston, Texas, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "Design of class hierarchies: an introduction to {OO}
                 program design",
  x-abstract =   "We report on the experience of teaching an
                 introductory second semester computer science course on
                 Fundamentals of Computer Science that uses our
                 curriculum How to Design Class Hierarchies and the
                 {ProfessorJ} programming languages implemented within
                 the {DrScheme} programming {environment.This}
                 comprehensive curriculum for an introductory course
                 focuses on principled design of class based programs in
                 an object-oriented language (Java) with a carefully
                 structured gradual increase in the complexity of the
                 class structure and the programming {language.The}
                 curriculum includes extensive lecture notes,
                 programming assignments, closed lab plans, exams, and
                 the first part of a textbook. The curriculum is
                 supported by a programming environment {ProfessorJ}
                 with a series of gradually more complex teaching
                 languages that support a novice learner. The pedagogy
                 focuses on teaching the students problem solving and
                 design skills that transcend the study of programming.
                 The organization of the topics draws its strength from
                 the theory of programming languages by focusing on the
                 structure of data rather than on algorithms, user
                 interactions, or arcane details of the programming
                 language syntax.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1121341.1121431",
  x-isbn =       "1-59593-259-3",
  x-series =     "SIGCSE '06",
  x-url =        "http://dx.doi.org/10.1145/1121341.1121431",
  xpages =       "288--292",
  year =         "2006",
}

@Article{Hsia2005Taming,
  author =       "James I. Hsia and Elspeth Simpson and Daniel Smith and
                 Robert Cartwright",
  citeulike-article-id = "12262146",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1047459",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1047124.1047459",
  date-added =   "2013-04-12 22:30:09",
  journal =      "SIGCSE Bull.",
  month =        feb,
  number =       "1",
  priority =     "2",
  publisher =    "ACM",
  title =        "Taming Java for the classroom",
  volume =       "37",
  x-abstract =   "Java is the canonical language for teaching
                 introductory programming, but its complex syntax and
                 abundance of constructs are difficult for beginners to
                 learn. This paper shows how object-oriented programming
                 in Java can be made more accessible to beginners
                 through the use of {"}language levels{"}, a hierarchy
                 of progressively richer subsets of Java. This hierarchy
                 is implemented as an extension of the {DrJava}
                 pedagogic programming environment.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1047124.1047459",
  x-issn =       "0097-8418",
  x-url =        "http://dx.doi.org/10.1145/1047124.1047459",
  xpages =       "327--331",
  year =         "2005",
}

@InProceedings{Bruce2001Library,
  author =       "Kim B. Bruce and Andrea Danyluk and Thomas Murtagh",
  booktitle =    "Proceedings of the thirty-second SIGCSE technical
                 symposium on Computer Science Education",
  citeulike-article-id = "2817546",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=364527",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/366413.364527",
  date-added =   "2013-04-12 22:29:31",
  journal =      "SIGCSE Bull.",
  location =     "Charlotte, North Carolina, USA",
  month =        mar,
  number =       "1",
  priority =     "2",
  publisher =    "ACM",
  title =        "A library to support a graphics-based object-first
                 approach to {CS} 1",
  volume =       "33",
  x-abstract =   "In this paper we describe a library we have developed
                 that supports an {"}{OO}-from-the-beginning{"} approach
                 to {CS} 1. The use of real graphics {"}objects{"} and
                 event-driven programming are important components of
                 our approach. The design of interactive graphical
                 programs helps students to both use objects and write
                 methods early while designing and implementing
                 interesting programs.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/366413.364527",
  x-isbn =       "1-58113-329-4",
  x-issn =       "0097-8418",
  x-series =     "SIGCSE '01",
  x-url =        "http://dx.doi.org/10.1145/366413.364527",
  xpages =       "6--10",
  year =         "2001",
}

@InProceedings{Alphonce2003Using,
  author =       "Carl Alphonce and Phil Ventura",
  booktitle =    "Companion of the 18th annual ACM SIGPLAN conference on
                 Object-oriented programming, systems, languages, and
                 applications",
  citeulike-article-id = "12262145",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=949391",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/949344.949391",
  date-added =   "2013-04-12 22:29:16",
  location =     "Anaheim, CA, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "Using graphics to support the teaching of fundamental
                 object-oriented principles in {CS1}",
  x-abstract =   "Teaching object-oriented programming in {CS1} is hard.
                 Keeping the attention of {CS1} students is perhaps even
                 harder. In our experience the former can be done
                 successfully with very satisfying results by focusing
                 on the fundamental principles of object-orientation,
                 such as inheritance, polymorphism and encapsulation.
                 The latter can be done by having students create
                 graphical event-driven programs. Care must be taken,
                 however, since teaching graphics can easily distract
                 students and certainly takes time away from the
                 fundamentals being taught. We use Java as a vehicle for
                 {OO} instruction, but rather than expose {CS1} students
                 to the intricacies of Swing we employ an elegant and
                 small graphics package called {NGP}. {NGP} allows
                 students to create event-driven graphical programs
                 using only inheritance and method overriding. We
                 describe how we use {NGP} to enhance rather than
                 detract from our teaching of fundamental {OO}
                 principles.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/949344.949391",
  x-isbn =       "1-58113-751-6",
  x-series =     "OOPSLA '03",
  x-url =        "http://dx.doi.org/10.1145/949344.949391",
  xpages =       "156--161",
  year =         "2003",
}

@Article{Chakravarty2004Risks,
  author =       "Manuel M. T. Chakravarty and Gabriele Keller",
  citeulike-article-id = "10035586",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=967497",
  citeulike-linkout-1 = "http://dx.doi.org/10.1017/S0956796803004805",
  date-added =   "2013-04-12 21:42:51",
  journal =      "J. Funct. Program.",
  month =        jan,
  number =       "1",
  priority =     "2",
  publisher =    "Cambridge University Press",
  title =        "The risks and benefits of teaching purely functional
                 programming in first year",
  volume =       "14",
  x-abstract =   "We argue that teaching purely functional programming
                 as such in freshman courses is detrimental to both the
                 curriculum as well as to promoting the paradigm.
                 Instead, we need to focus on the more general aims of
                 teaching elementary techniques of programming and
                 essential concepts of computing. We support this
                 viewpoint with experience gained during several
                 semesters of teaching large first-year classes (up to
                 600 students) in Haskell. These classes consisted of
                 computer science students as well as students from
                 other disciplines. We have systematically gathered
                 student feedback by conducting surveys after each
                 semester. This article contributes an approach to the
                 use of modern functional languages in first year
                 courses and, based on this, advocates the use of
                 functional languages in this setting.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1017/S0956796803004805",
  x-issn =       "0956-7968",
  x-url =        "http://dx.doi.org/10.1017/S0956796803004805",
  xpages =       "113--123",
  year =         "2004",
}

@InProceedings{Ragde2008Chilling,
  author =       "Prabhakar Ragde",
  booktitle =    "Proceedings of the 2008 international workshop on
                 Functional and declarative programming in education",
  citeulike-article-id = "12262127",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1411263",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1411260.1411263",
  date-added =   "2013-04-12 21:39:54",
  location =     "Victoria, BC, Canada",
  priority =     "2",
  publisher =    "ACM",
  title =        "The chilling descent: making the transition to a
                 conventional curriculum",
  x-abstract =   "The transitional course following an introduction to
                 computer science using functional programming must
                 prepare students to handle a traditional,
                 imperative-based curriculum while ensuring that the
                 lessons of the introductory course are not lost. This
                 paper describes the design of a second course using
                 both Scheme and C, and examines the rationales behind
                 the major design decisions.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1411260.1411263",
  x-isbn =       "978-1-60558-068-5",
  x-series =     "FDPE '08",
  x-url =        "http://dx.doi.org/10.1145/1411260.1411263",
  xpages =       "13--20",
  year =         "2008",
}

@Article{Bloch2000Scheme,
  author =       "Stephen A. Bloch",
  citeulike-article-id = "12262126",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=364177",
  date-added =   "2013-04-12 21:37:51",
  journal =      "J. Comput. Sci. Coll.",
  month =        apr,
  number =       "5",
  priority =     "2",
  publisher =    "Consortium for Computing Sciences in Colleges",
  title =        "Scheme and Java in the first year",
  volume =       "15",
  x-abstract =   "An abstract is not available.",
  x-address =    "USA",
  x-issn =       "1937-4771",
  x-url =        "http://portal.acm.org/citation.cfm?id=364177",
  xpages =       "157--165",
  year =         "2000",
}

@Article{Bloch2008Teach,
  author =       "Stephen Bloch",
  citeulike-article-id = "12262125",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1352639",
  date-added =   "2013-04-12 21:34:40",
  journal =      "J. Comput. Sci. Coll.",
  month =        may,
  number =       "5",
  priority =     "2",
  publisher =    "Consortium for Computing Sciences in Colleges",
  title =        "Teach Scheme, reach Java: introducing object-oriented
                 programming without drowning in syntax",
  volume =       "23",
  x-abstract =   "We'll discuss a multi-lingual approach to the first
                 year of programming, starting in a simple, consistent
                 language like Scheme to get across essential concepts
                 (e.g. variables, functions, parameters, data types,
                 composition, testing, conditionals, classes with
                 fields, polymorphism, recursion) and a principled
                 methodology of programming. We'll demonstrate how the
                 same topics can be subsequently covered in a more
                 mainstream, but more complex, language such as Java,
                 taking advantage of students' preparation during the
                 Scheme phase of the course. Participants will be
                 invited to a week-long, {NSF}-funded workshop in Summer
                 2008, which goes into much more depth on technical,
                 classroom, and curriculum issues [{TSRJ08}].",
  x-address =    "USA",
  x-issn =       "1937-4771",
  x-url =        "http://portal.acm.org/citation.cfm?id=1352639",
  xpages =       "65--67",
  year =         "2008",
}

@Article{Kolling2003,
  author =       "Michael K{\"{o}}lling and Bruce Quig and Andrew
                 Patterson and John Rosenberg",
  citeulike-article-id = "493692",
  citeulike-linkout-0 = "http://www.bluej.org/papers/2003-12-CSEd-bluej.pdf",
  date-added =   "2013-04-12 15:45:21",
  journal =      "Journal of Computer Science Education",
  keywords =     "bluej",
  month =        dec,
  number =       "4",
  priority =     "2",
  title =        "The {BlueJ} system and its pedagogy",
  volume =       "13",
  x-url =        "http://www.bluej.org/papers/2003-12-CSEd-bluej.pdf",
  year =         "2003",
}

@Article{Allen2002DrJava,
  author =       "Eric Allen and Robert Cartwright and Brian Stoler",
  citeulike-article-id = "1894872",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1089197",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/563517.563395",
  date-added =   "2013-04-12 15:37:34",
  journal =      "SIGCSE Bull.",
  month =        feb,
  number =       "1",
  priority =     "2",
  publisher =    "ACM",
  title =        "{DrJava}: a lightweight pedagogic environment for
                 Java",
  volume =       "34",
  x-abstract =   "{DrJava} is a pedagogic programming environment for
                 Java that enables students to focus on designing
                 programs, rather than learning how to use the
                 environment. The environment provides a simple
                 interface based on a {"}read-eval-print loop{"} that
                 enables a programmer to develop, test, and debug Java
                 programs in an interactive, incremental fashion. This
                 paper gives an overview of {DrJava} including its
                 pedagogic rationale, functionality, and
                 implementation.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/563517.563395",
  x-issn =       "0097-8418",
  x-url =        "http://dx.doi.org/10.1145/563517.563395",
  xpages =       "137--141",
  year =         "2002",
}

@InProceedings{Gray2003ProfessorJ,
  author =       "Kathryn E. Gray and Matthew Flatt",
  booktitle =    "Companion of the 18th annual ACM SIGPLAN conference on
                 Object-oriented programming, systems, languages, and
                 applications",
  citeulike-article-id = "190418",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=949394",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/949344.949394",
  date-added =   "2013-04-12 15:32:37",
  location =     "Anaheim, CA, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "{ProfessorJ}: a gradual introduction to Java through
                 language levels",
  x-abstract =   "In the second-semester programming course at the
                 University of Utah, we have observed that our students
                 suffer unnecessarily from a mismatch between the course
                 content and the programming environment. The course is
                 typical, in that it exposes students to Java a little
                 at a time. The programming environments are also
                 typical, in that they report compilation and run-time
                 errors in the jargon of professional programmers who
                 use the full Java language. As a result, students rely
                 heavily on teaching assistants to interpret error
                 messages, and valuable classroom time is wasted on
                 syntactic {diversions.ProfessorJ} is our new
                 programming environment that remedies this problem.
                 Like other pedagogical environments, such as {BlueJ}
                 and {DrJava}, {ProfessorJ} presents the student with a
                 simplified interface to the Java compiler and virtual
                 machine. Unlike existing environments, {ProfessorJ}
                 tailors the Java language and error messages to the
                 students' needs. Since their needs evolve through the
                 course, {ProfessorJ} offers several language levels,
                 from Beginner Java to Full Java.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/949344.949394",
  x-isbn =       "1-58113-751-6",
  x-series =     "OOPSLA '03",
  x-url =        "http://dx.doi.org/10.1145/949344.949394",
  xpages =       "170--177",
  year =         "2003",
}

@Article{Felleisen2004Structure,
  author =       "Matthias Felleisen and Robert B. Findler and Matthew
                 Flatt and Shriram Krishnamurthi",
  citeulike-article-id = "1398",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=997813",
  citeulike-linkout-1 = "http://journals.cambridge.org/action/displayAbstract?fromPage=online\&aid=227683",
  citeulike-linkout-2 = "http://dx.doi.org/10.1017/s0956796804005076",
  date-added =   "2013-04-12 15:25:50",
  journal =      "Journal of Functional Programming",
  month =        jun,
  number =       "4",
  priority =     "2",
  publisher =    "Cambridge University Press",
  title =        "The structure and interpretation of the computer
                 science curriculum",
  volume =       "14",
  x-abstract =   "Twenty years ago Abelson and Sussman\&apos;s Structure
                 and Interpretation of Computer Programs radically
                 changed the intellectual landscape of introductory
                 computing courses. Instead of teaching some currently
                 fashionable programming language, it employed Scheme
                 and functional programming to teach important ideas.
                 Introductory courses based on the book showed up around
                 the world and made Scheme and functional programming
                 popular. Unfortunately, these courses quickly
                 disappeared again due to shortcomings of the book and
                 the whimsies of Scheme. Worse, the experiment left
                 people with a bad impression of Scheme and functional
                 programming in general. In this pearl, we propose an
                 alternative role for functional programming in the
                 first-year curriculum. Specifically, we present a
                 framework for discussing the first-year curriculum and,
                 based on it, the design rationale for our book and
                 course, dubbed How to Design Programs. The approach
                 emphasizes the systematic design of programs.
                 Experience shows that it works extremely well as a
                 preparation for a course on object-oriented
                 programming.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1017/s0956796804005076",
  x-issn =       "1469-7653",
  x-url =        "http://dx.doi.org/10.1017/s0956796804005076",
  xpages =       "365--378",
  year =         "2004",
}

@InProceedings{Goodman2013Principles,
  author =       "Noah D. Goodman",
  booktitle =    "Proceedings of the 40th annual ACM SIGPLAN-SIGACT
                 symposium on Principles of programming languages",
  citeulike-article-id = "12007845",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2429069.2429117",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2429069.2429117",
  date-added =   "2013-02-09 02:45:35",
  location =     "Rome, Italy",
  priority =     "2",
  publisher =    "ACM",
  title =        "The principles and practice of probabilistic
                 programming",
  x-abstract =   "An abstract is not available.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2429069.2429117",
  x-isbn =       "978-1-4503-1832-7",
  x-series =     "POPL '13",
  x-url =        "http://dx.doi.org/10.1145/2429069.2429117",
  xpages =       "399--402",
  year =         "2013",
}

@InProceedings{Fournet2013Fully,
  author =       "Cedric Fournet and Nikhil Swamy and Juan Chen and
                 Pierre E. Dagand and Pierre Y. Strub and Benjamin
                 Livshits",
  booktitle =    "Proceedings of the 40th annual ACM SIGPLAN-SIGACT
                 symposium on Principles of programming languages",
  citeulike-article-id = "12007844",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2429069.2429114",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2429069.2429114",
  date-added =   "2013-02-09 02:37:57",
  location =     "Rome, Italy",
  priority =     "2",
  publisher =    "ACM",
  title =        "Fully abstract compilation to {JavaScript}",
  x-abstract =   "Many tools allow programmers to develop applications
                 in high-level languages and deploy them in web browsers
                 via compilation to {JavaScript}. While practical and
                 widely used, these compilers are ad hoc: no guarantee
                 is provided on their correctness for whole programs,
                 nor their security for programs executed within
                 arbitrary {JavaScript} contexts. This paper presents a
                 compiler with such guarantees. We compile an {ML}-like
                 language with higher-order functions and references to
                 {JavaScript}, while preserving all source program
                 properties. Relying on type-based invariants and
                 applicative bisimilarity, we show full abstraction: two
                 programs are equivalent in all source contexts if and
                 only if their wrapped translations are equivalent in
                 all {JavaScript} contexts. We evaluate our compiler on
                 sample programs, including a series of secure
                 libraries.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2429069.2429114",
  x-isbn =       "978-1-4503-1832-7",
  x-series =     "POPL '13",
  x-url =        "http://dx.doi.org/10.1145/2429069.2429114",
  xpages =       "371--384",
  year =         "2013",
}

@InProceedings{Gaboardi2013Linear,
  author =       "Marco Gaboardi and Andreas Haeberlen and Justin Hsu
                 and Arjun Narayan and Benjamin C. Pierce",
  booktitle =    "Proceedings of the 40th annual ACM SIGPLAN-SIGACT
                 symposium on Principles of programming languages",
  citeulike-article-id = "12007843",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2429069.2429113",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2429069.2429113",
  date-added =   "2013-02-09 02:37:43",
  location =     "Rome, Italy",
  priority =     "2",
  publisher =    "ACM",
  title =        "Linear dependent types for differential privacy",
  x-abstract =   "Differential privacy offers a way to answer queries
                 about sensitive information while providing strong,
                 provable privacy guarantees, ensuring that the presence
                 or absence of a single individual in the database has a
                 negligible statistical effect on the query's result.
                 Proving that a given query has this property involves
                 establishing a bound on the query's sensitivity---how
                 much its result can change when a single record is
                 added or removed. A variety of tools have been
                 developed for certifying that a given query
                 differentially private. In one approach, Reed and
                 Pierce [34] proposed a functional programming language,
                 Fuzz, for writing differentially private queries. Fuzz
                 uses linear types to track sensitivity and a
                 probability monad to express randomized computation; it
                 guarantees that any program with a certain type is
                 differentially private. Fuzz can successfully verify
                 many useful queries. However, it fails when the
                 sensitivity analysis depends on values that are not
                 known statically. We present {DFuzz}, an extension of
                 Fuzz with a combination of linear indexed types and
                 lightweight dependent types. This combination allows a
                 richer sensitivity analysis that is able to certify a
                 larger class of queries as differentially private,
                 including ones whose sensitivity depends on runtime
                 information. As in Fuzz, the differential privacy
                 guarantee follows directly from the soundness theorem
                 of the type system. We demonstrate the enhanced
                 expressivity of {DFuzz} by certifying differential
                 privacy for a broad class of iterative algorithms that
                 could not be typed previously.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2429069.2429113",
  x-isbn =       "978-1-4503-1832-7",
  x-series =     "POPL '13",
  x-url =        "http://dx.doi.org/10.1145/2429069.2429113",
  xpages =       "357--370",
  year =         "2013",
}

@InProceedings{Jensen2013Highlevel,
  author =       "Jonas B. Jensen and Nick Benton and Andrew Kennedy",
  booktitle =    "Proceedings of the 40th annual ACM SIGPLAN-SIGACT
                 symposium on Principles of programming languages",
  citeulike-article-id = "12007839",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2429069.2429105",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2429069.2429105",
  date-added =   "2013-02-09 02:33:52",
  location =     "Rome, Italy",
  priority =     "2",
  publisher =    "ACM",
  title =        "High-level separation logic for low-level code",
  x-abstract =   "Separation logic is a powerful tool for reasoning
                 about structured, imperative programs that manipulate
                 pointers. However, its application to unstructured,
                 lower-level languages such as assembly language or
                 machine code remains challenging. In this paper we
                 describe a separation logic tailored for this purpose
                 that we have applied to x86 machine-code programs. The
                 logic is built from an assertion logic on machine
                 states over which we construct a specification logic
                 that encapsulates uses of frames and step indexing. The
                 traditional notion of Hoare triple is not applicable
                 directly to unstructured machine code, where code and
                 data are mixed together and programs do not in general
                 run to completion, so instead we adopt a
                 continuation-passing style of specification with
                 preconditions alone. Nevertheless, the range of
                 primitives provided by the specification logic, which
                 include a higher-order frame connective, a novel
                 read-only frame connective, and a 'later' modality,
                 support the definition of derived forms to support
                 structured-programming-style reasoning for common
                 cases, in which standard rules for Hoare triples are
                 derived as lemmas. Furthermore, our encoding of scoped
                 assembly-language labels lets us give definitions and
                 proof rules for powerful assembly-language 'macros'
                 such as while loops, conditionals and procedures. We
                 have applied the framework to a model of sequential x86
                 machine code built entirely within the Coq proof
                 assistant, including tactic support based on
                 computational reflection.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2429069.2429105",
  x-isbn =       "978-1-4503-1832-7",
  x-series =     "POPL '13",
  x-url =        "http://dx.doi.org/10.1145/2429069.2429105",
  xpages =       "301--314",
  year =         "2013",
}

@InProceedings{Krishnamurthi2013From,
  author =       "Shriram Krishnamurthi",
  booktitle =    "Proceedings of the 40th annual ACM SIGPLAN-SIGACT
                 symposium on Principles of programming languages",
  citeulike-article-id = "12007838",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2429069.2429097",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2429069.2429097",
  date-added =   "2013-02-09 02:26:11",
  location =     "Rome, Italy",
  priority =     "2",
  publisher =    "ACM",
  title =        "From principles to programming languages (and back)",
  x-abstract =   "An abstract is not available.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2429069.2429097",
  x-isbn =       "978-1-4503-1832-7",
  x-series =     "POPL '13",
  x-url =        "http://dx.doi.org/10.1145/2429069.2429097",
  xpages =       "233--234",
  year =         "2013",
}

@InProceedings{Hur2013Power,
  author =       "Chung K. Hur and Georg Neis and Derek Dreyer and
                 Viktor Vafeiadis",
  booktitle =    "Proceedings of the 40th Annual ACM SIGPLAN-SIGACT
                 Symposium on Principles of Programming Languages",
  citeulike-article-id = "12007837",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2429069.2429093",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2429069.2429093",
  date-added =   "2013-02-09 02:24:13",
  location =     "Rome, Italy",
  priority =     "2",
  publisher =    "ACM",
  title =        "The Power of Parameterization in Coinductive Proof",
  x-abstract =   "Coinduction is one of the most basic concepts in
                 computer science. It is therefore surprising that the
                 commonly-known lattice-theoretic accounts of the
                 principles underlying coinductive proofs are lacking in
                 two key respects: they do not support compositional
                 reasoning (i.e. breaking proofs into separate pieces
                 that can be developed in isolation), and they do not
                 support incremental reasoning (i.e. developing proofs
                 interactively by starting from the goal and
                 generalizing the coinduction hypothesis repeatedly as
                 necessary). In this paper, we show how to support
                 coinductive proofs that are both compositional and
                 incremental, using a dead simple construction we call
                 the parameterized greatest fixed point. The basic idea
                 is to parameterize the greatest fixed point of interest
                 over the accumulated knowledge of {"}the proof so
                 far{"}. While this idea has been proposed before, by
                 Winskel in 1989 and by Moss in 2001, neither of the
                 previous accounts suggests its general applicability to
                 improving the state of the art in interactive
                 coinductive proof. In addition to presenting the
                 lattice-theoretic foundations of parameterized
                 coinduction, demonstrating its utility on
                 representative examples, and studying its composition
                 with {"}up-to{"} techniques, we also explore its
                 mechanization in proof assistants like Coq and
                 Isabelle. Unlike traditional approaches to mechanizing
                 coinduction (e.g. Coq's cofix), which employ syntactic
                 {"}guardedness checking{"}, parameterized coinduction
                 offers a semantic account of guardedness. This leads to
                 faster and more robust proof development, as we
                 demonstrate using our new Coq library, Paco.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2429069.2429093",
  x-isbn =       "978-1-4503-1832-7",
  x-series =     "POPL '13",
  x-url =        "http://dx.doi.org/10.1145/2429069.2429093",
  xpages =       "193--206",
  year =         "2013",
}

@InProceedings{Atkey2013Abstraction,
  author =       "Robert Atkey and Patricia Johann and Andrew Kennedy",
  booktitle =    "Proceedings of the 40th annual ACM SIGPLAN-SIGACT
                 symposium on Principles of programming languages",
  citeulike-article-id = "12007836",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2429069.2429082",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2429069.2429082",
  date-added =   "2013-02-09 02:21:04",
  location =     "Rome, Italy",
  priority =     "2",
  publisher =    "ACM",
  title =        "Abstraction and invariance for algebraically indexed
                 types",
  x-abstract =   "Reynolds' relational parametricity provides a powerful
                 way to reason about programs in terms of invariance
                 under changes of data representation. A dazzling array
                 of applications of Reynolds' theory exists, exploiting
                 invariance to yield {"}free theorems{"},
                 non-inhabitation results, and encodings of algebraic
                 datatypes. Outside computer science, invariance is a
                 common theme running through many areas of mathematics
                 and physics. For example, the area of a triangle is
                 unaltered by rotation or flipping. If we scale a
                 triangle, then we scale its area, maintaining an
                 invariant relationship between the two. The
                 transformations under which properties are invariant
                 are often organised into groups, with the algebraic
                 structure reflecting the composability and
                 invertibility of transformations. In this paper, we
                 investigate programming languages whose types are
                 indexed by algebraic structures such as groups of
                 geometric transformations. Other examples include types
                 indexed by principals--for information flow
                 security--and types indexed by distances--for analysis
                 of analytic uniform continuity properties. Following
                 Reynolds, we prove a general Abstraction Theorem that
                 covers all these instances. Consequences of our
                 Abstraction Theorem include free theorems expressing
                 invariance properties of programs, type isomorphisms
                 based on invariance properties, and non-definability
                 results indicating when certain algebraically indexed
                 types are uninhabited or only inhabited by trivial
                 programs. We have fully formalised our framework and
                 most examples in Coq.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2429069.2429082",
  x-isbn =       "978-1-4503-1832-7",
  x-series =     "POPL '13",
  x-url =        "http://dx.doi.org/10.1145/2429069.2429082",
  xpages =       "87--100",
  year =         "2013",
}

@InProceedings{Unno2013Automating,
  author =       "Hiroshi Unno and Tachio Terauchi and Naoki Kobayashi",
  booktitle =    "Proceedings of the 40th annual ACM SIGPLAN-SIGACT
                 symposium on Principles of programming languages",
  citeulike-article-id = "12007831",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2429069.2429081",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2429069.2429081",
  date-added =   "2013-02-09 02:17:57",
  location =     "Rome, Italy",
  priority =     "2",
  publisher =    "ACM",
  title =        "Automating relatively complete verification of
                 higher-order functional programs",
  x-abstract =   "We present an automated approach to relatively
                 completely verifying safety (i.e., reachability)
                 property of higher-order functional programs. Our
                 contribution is two-fold. First, we extend the
                 refinement type system framework employed in the recent
                 work on (incomplete) automated higher-order
                 verification by drawing on the classical work on
                 relatively complete {"}Hoare logic like{"} program
                 logic for higher-order procedural languages. Then, by
                 adopting the recently proposed techniques for solving
                 constraints over quantified first-order logic formulas,
                 we develop an automated type inference method for the
                 type system, thereby realizing an automated relatively
                 complete verification of higher-order programs.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2429069.2429081",
  x-isbn =       "978-1-4503-1832-7",
  x-series =     "POPL '13",
  x-url =        "http://dx.doi.org/10.1145/2429069.2429081",
  xpages =       "75--86",
  year =         "2013",
}

@InProceedings{Tate2013Sequential,
  author =       "Ross Tate",
  booktitle =    "Proceedings of the 40th annual ACM SIGPLAN-SIGACT
                 symposium on Principles of programming languages",
  citeulike-article-id = "12007828",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2429069.2429074",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2429069.2429074",
  date-added =   "2013-02-09 02:03:58",
  location =     "Rome, Italy",
  priority =     "2",
  publisher =    "ACM",
  title =        "The sequential semantics of producer effect systems",
  x-abstract =   "Effects are fundamental to programming languages. Even
                 the lambda calculus has effects, and consequently the
                 two famous evaluation strategies produce different
                 semantics. As such, much research has been done to
                 improve our understanding of effects. Since Moggi
                 introduced monads for his computational lambda
                 calculus, further generalizations have been designed to
                 formalize increasingly complex computational effects,
                 such as indexed monads followed by layered monads
                 followed by parameterized monads. This succession
                 prompted us to determine the most general formalization
                 possible. In searching for this formalization we came
                 across many surprises, such as the insufficiencies of
                 arrows, as well as many unexpected insights, such as
                 the importance of considering an effect as a small
                 component of a whole system rather than just an
                 isolated feature. In this paper we present our semantic
                 formalization for producer effect systems, which we
                 call a productor, and prove its maximal generality by
                 focusing on only sequential composition of effectful
                 computations, consequently guaranteeing that the
                 existing monadic techniques are specializations of
                 productors.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2429069.2429074",
  x-isbn =       "978-1-4503-1832-7",
  x-series =     "POPL '13",
  x-url =        "http://dx.doi.org/10.1145/2429069.2429074",
  xpages =       "15--26",
  year =         "2013",
}

@InProceedings{DBLP:conf/vmcai/Ranzato13,
  author =       "Francesco Ranzato",
  booktitle =    "VMCAI",
  citeulike-article-id = "12007825",
  date-added =   "2013-02-09 01:59:48",
  priority =     "2",
  title =        "Complete Abstractions Everywhere",
  xpages =       "15--26",
  year =         "2013",
}

@InProceedings{DBLP:conf/vmcai/MouraJ13,
  author =       "Leonardo M. de Moura and Dejan Jovanovic",
  booktitle =    "VMCAI",
  citeulike-article-id = "12007824",
  date-added =   "2013-02-09 01:59:38",
  priority =     "2",
  title =        "A {Model-Constructing} Satisfiability Calculus",
  xpages =       "1--12",
  year =         "2013",
}

@InProceedings{DBLP:conf/vmcai/Pearce13,
  author =       "David J. Pearce",
  booktitle =    "VMCAI",
  citeulike-article-id = "12007819",
  date-added =   "2013-02-09 01:28:44",
  priority =     "2",
  title =        "Sound and Complete Flow Typing with Unions,
                 Intersections and Negations",
  xpages =       "335--354",
  year =         "2013",
}

@InProceedings{DBLP:conf/vmcai/ZhuJ13,
  author =       "He Zhu and Suresh Jagannathan",
  booktitle =    "Conference on Verification, Model-Checking and
                 Abstract Interpretation",
  citeulike-article-id = "12007818",
  date-added =   "2013-02-09 01:15:27",
  priority =     "2",
  title =        "Compositional and Lightweight Dependent Type Inference
                 for {ML}",
  xpages =       "295--314",
  year =         "2013",
}

@Proceedings{DBLP:conf/vmcai/2013,
  booktitle =    "VMCAI",
  citeulike-article-id = "12007817",
  date-added =   "2013-02-09 01:06:59",
  priority =     "2",
  publisher =    "Springer",
  title =        "Verification, Model Checking, and Abstract
                 Interpretation, 14th International Conference, {VMCAI}
                 2013, Rome, Italy, January 20-22, 2013. Proceedings",
  volume =       "7737",
  x-editor =     "Giacobazzi, Roberto and Berdine, Josh and Mastroeni,
                 Isabella",
  x-series =     "Lecture Notes in Computer Science",
  year =         "2013",
}

@InProceedings{DBLP:conf/vmcai/CousotCFL13,
  author =       "Patrick Cousot and Radhia Cousot and Manuel
                 F{\"{a}}hndrich and Francesco Logozzo",
  booktitle =    "VMCAI",
  citeulike-article-id = "12007816",
  date-added =   "2013-02-09 01:06:59",
  priority =     "2",
  publisher =    "Springer",
  title =        "Automatic Inference of Necessary Preconditions",
  volume =       "7737",
  x-editor =     "Giacobazzi, Roberto and Berdine, Josh and Mastroeni,
                 Isabella",
  x-series =     "Lecture Notes in Computer Science",
  xpages =       "128--148",
  year =         "2013",
}

@InProceedings{Guha2009Static,
  author =       "Arjun Guha and Shriram Krishnamurthi and Trevor Jim",
  booktitle =    "In International World Wide Web Conference",
  citeulike-article-id = "11975596",
  citeulike-linkout-0 = "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.186.4892",
  date-added =   "2013-01-31 02:17:14",
  priority =     "2",
  title =        "Static analysis for Ajax intrusion detection",
  x-abstract =   "We present a static control-flow analysis for
                 {JavaScript} programs running in a web browser. Our
                 analysis tackles numerous challenges posed by modern
                 web applications including asynchronous communication,
                 frameworks, and dynamic code generation. We use our
                 analysis to extract a model of expected client behavior
                 as seen from the server, and build an
                 intrusion-prevention proxy for the server: the proxy
                 intercepts client requests and disables those that do
                 not meet the expected behavior. We insert random
                 asynchronous requests to foil mimicry attacks. Finally,
                 we evaluate our technique against several real
                 applications and show that it protects against an
                 attack in a widely-used web application.",
  x-url =        "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.186.4892",
  year =         "2009",
}

@InProceedings{Vytiniotis2013HALO,
  author =       "Dimitrios Vytiniotis and Simon Peyton Jones and Koen
                 Claessen and Dan Ros\'{e}n",
  booktitle =    "Proceedings of the 40th Annual ACM SIGPLAN-SIGACT
                 Symposium on Principles of Programming Languages",
  citeulike-article-id = "11975564",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2429121",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2429069.2429121",
  date-added =   "2013-01-31 01:53:01",
  location =     "Rome, Italy",
  priority =     "0",
  publisher =    "ACM",
  title =        "{HALO}: {H}askell to logic through denotational
                 semantics",
  x-abstract =   "Even well-typed programs can go wrong in modern
                 functional languages, by encountering a pattern-match
                 failure, or simply returning the wrong answer. An
                 increasingly-popular response is to allow programmers
                 to write contracts that express semantic properties,
                 such as crash-freedom or some useful post-condition. We
                 study the static verification of such contracts. Our
                 main contribution is a novel translation to first-order
                 logic of both Haskell programs, and contracts written
                 in Haskell, all justified by denotational semantics.
                 This translation enables us to prove that functions
                 satisfy their contracts using an off-the-shelf
                 first-order logic theorem prover.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2429069.2429121",
  x-isbn =       "978-1-4503-1832-7",
  x-series =     "POPL",
  x-url =        "http://dx.doi.org/10.1145/2429069.2429121",
  xpages =       "431--442",
  year =         "2013",
}

@InCollection{Alur2004Temporal,
  author =       "Rajeev Alur and Kousha Etessami and P. Madhusudan",
  booktitle =    "Tools and Algorithms for the Construction and Analysis
                 of Systems",
  citeulike-article-id = "11975561",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-540-24730-2\_35",
  citeulike-linkout-1 = "http://link.springer.com/chapter/10.1007/978-3-540-24730-2\_35",
  date-added =   "2013-01-31 01:50:42",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "A Temporal Logic of Nested Calls and Returns",
  volume =       "2988",
  x-abstract =   "Model checking of linear temporal logic ({LTL})
                 specifications with respect to pushdown systems has
                 been shown to be a useful tool for analysis of programs
                 with potentially recursive procedures. {LTL}, however,
                 can specify only regular properties, and properties
                 such as correctness of procedures with respect to pre
                 and post conditions, that require matching of calls and
                 returns, are not regular. We introduce a temporal logic
                 of calls and returns ({CaRet}) for specification and
                 algorithmic verification of correctness requirements of
                 structured programs. The formulas of {CaRet} are
                 interpreted over sequences of propositional valuations
                 tagged with special symbols call and ret. Besides the
                 standard global temporal modalities, {CaRet} admits the
                 abstract-next operator that allows a path to jump from
                 a call to the matching return. This operator can be
                 used to specify a variety of non-regular properties
                 such as partial and total correctness of program blocks
                 with respect to pre and post conditions. The abstract
                 versions of the other temporal modalities can be used
                 to specify regular properties of local paths within a
                 procedure that skip over calls to other procedures.
                 {CaRet} also admits the caller modality that jumps to
                 the most recent pending call, and such caller
                 modalities allow specification of a variety of security
                 properties that involve inspection of the call-stack.
                 Even though verifying context-free properties of
                 pushdown systems is undecidable, we show that model
                 checking {CaRet} formulas against a pushdown model is
                 decidable. We present a tableau construction that
                 reduces our model checking problem to the emptiness
                 problem for a B{\"{u}}chi pushdown system. The
                 complexity of model checking {CaRet} formulas is the
                 same as that of checking {LTL} formulas, namely,
                 polynomial in the model and singly exponential in the
                 size of the specification.",
  x-doi =        "10.1007/978-3-540-24730-2\_35",
  x-editor =     "Jensen, Kurt and Podelski, Andreas",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-540-24730-2\_35",
  xpages =       "467--481",
  year =         "2004",
}

@InCollection{Scott1975Data,
  author =       "Dana Scott",
  booktitle =    "⊨ISILC Logic Conference",
  citeulike-article-id = "5212385",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/bfb0079432",
  citeulike-linkout-1 = "http://www.springerlink.com/content/1g4802177006m187",
  citeulike-linkout-2 = "http://link.springer.com/chapter/10.1007/BFb0079432",
  date-added =   "2013-01-30 18:28:54",
  journal =      "?ISILC Logic Conference",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "Data types as lattices",
  volume =       "499",
  x-abstract =   "Without Abstract",
  x-doi =        "10.1007/bfb0079432",
  x-editor =     "M{\"{u}}ller, GertH and Oberschelp, Arnold and
                 Potthoff, Klaus",
  x-series =     "Lecture Notes in Mathematics",
  x-url =        "http://dx.doi.org/10.1007/bfb0079432",
  xpages =       "579--651",
  year =         "1975",
}

@InProceedings{Findler2006Contracts,
  author =       "Robert B. Findler and Matthias Blume",
  booktitle =    "Proceedings of the 8th International Conference on
                 Functional and Logic Programming",
  citeulike-article-id = "11973864",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2100094",
  citeulike-linkout-1 = "http://dx.doi.org/10.1007/11737414\_16",
  date-added =   "2013-01-30 18:28:04",
  location =     "Fuji-Susono, Japan",
  priority =     "0",
  publisher =    "Springer-Verlag",
  title =        "Contracts as pairs of projections",
  x-abstract =   "Assertion-based contracts provide a powerful mechanism
                 for stating invariants at module boundaries and for
                 enforcing them uniformly. In 2002, Findler and
                 Felleisen showed how to add contracts to higher-order
                 functional languages, allowing programmers to assert
                 invariants about functions as values. Following up in
                 2004, Blume and {McAllester} provided a quotient model
                 for contracts. Roughly speaking, their model equates a
                 contract with the set of values that cannot violate the
                 contract. Their studies raised interesting questions
                 about the nature of contracts and, in particular, the
                 nature of the any contract. In this paper, we develop a
                 model for software contracts that follows Dana Scott's
                 program by interpreting contracts as projections. The
                 model has already improved our implementation of
                 contracts. We also demonstrate how it increases our
                 understanding of contract-oriented programming and
                 design. In particular, our work provides a definitive
                 answer to the questions raised by Blume and
                 {McAllester}'s work. The key insight from our model
                 that resolves those questions is that a contract that
                 puts no obligation on either party is not the same as
                 the most permissive contract for just one of the
                 parties.",
  x-address =    "Berlin, Heidelberg",
  x-doi =        "10.1007/11737414\_16",
  x-isbn =       "3-540-33438-6, 978-3-540-33438-5",
  x-series =     "FLOPS'06",
  x-url =        "http://dx.doi.org/10.1007/11737414\_16",
  xpages =       "226--241",
  year =         "2006",
}

@InProceedings{Gordon1994Tutorial,
  author =       "Andrew D. Gordon",
  booktitle =    "IN GLASGOW FUNCTIONAL PROGRAMMING WORKSHOP",
  citeulike-article-id = "11973862",
  citeulike-linkout-0 = "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.37.3914",
  date-added =   "2013-01-30 18:27:15",
  priority =     "0",
  title =        "A Tutorial on Co-induction and Functional
                 Programming",
  x-abstract =   "Co-induction is an important tool for reasoning about
                 unbounded structures. This tutorial explains the
                 foundations of co-induction, and shows how it justifies
                 intuitive arguments about lazy streams, of central
                 importance to lazy functional programmers. We explain
                 from first principles a theory based on a new
                 formulation of bisimilarity for functional programs,
                 which coincides exactly with Morris-style contextual
                 equivalence. We show how to prove properties of lazy
                 streams by co-induction and derive Bird and Wadler's
                 Take Lemma, a well-known proof technique for lazy
                 streams.",
  x-url =        "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.37.3914",
  xpages =       "78--95",
  year =         "1994",
}

@Article{Alur2009Adding,
  author =       "Rajeev Alur and P. Madhusudan",
  citeulike-article-id = "9726460",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1516518",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1516512.1516518",
  date-added =   "2012-11-30 23:52:11",
  day =          "01",
  journal =      "J. ACM",
  month =        may,
  number =       "3",
  priority =     "2",
  publisher =    "ACM",
  title =        "Adding nesting structure to words",
  volume =       "56",
  x-abstract =   "We propose the model of nested words for
                 representation of data with both a linear ordering and
                 a hierarchically nested matching of items. Examples of
                 data with such dual linear-hierarchical structure
                 include executions of structured programs, annotated
                 linguistic data, and {HTML}/{XML} documents. Nested
                 words generalize both words and ordered trees, and
                 allow both word and tree operations. We define nested
                 word automata—finite-state acceptors for nested
                 words, and show that the resulting class of regular
                 languages of nested words has all the appealing
                 theoretical properties that the classical regular word
                 languages enjoys: deterministic nested word automata
                 are as expressive as their nondeterministic
                 counterparts; the class is closed under union,
                 intersection, complementation, concatenation,
                 Kleene-\&ast;, prefixes, and language homomorphisms;
                 membership, emptiness, language inclusion, and language
                 equivalence are all decidable; and definability in
                 monadic second order logic corresponds exactly to
                 finite-state recognizability. We also consider regular
                 languages of infinite nested words and show that the
                 closure properties, {MSO}-characterization, and
                 decidability of decision problems carry over. The
                 linear encodings of nested words give the class of
                 visibly pushdown languages of words, and this class
                 lies between balanced languages and deterministic
                 context-free languages. We argue that for algorithmic
                 verification of structured programs, instead of viewing
                 the program as a context-free language over words, one
                 should view it as a regular language of nested words
                 (or equivalently, a visibly pushdown language), and
                 this would allow model checking of many properties
                 (such as stack inspection, pre-post conditions) that
                 are not expressible in existing specification logics.
                 We also study the relationship between ordered trees
                 and nested words, and the corresponding automata: while
                 the analysis complexity of nested word automata is the
                 same as that of classical tree automata, they combine
                 both bottom-up and top-down traversals, and enjoy
                 expressiveness and succinctness benefits over tree
                 automata.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1516512.1516518",
  x-issn =       "0004-5411",
  x-url =        "http://dx.doi.org/10.1145/1516512.1516518",
  xpages =       "1--43",
  year =         "2009",
}

@Article{Landin1966Next,
  author =       "P. J. Landin",
  citeulike-article-id = "221703",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=365257",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/365230.365257",
  date-added =   "2012-11-14 07:39:17",
  journal =      "Commun. ACM",
  month =        mar,
  number =       "3",
  priority =     "2",
  publisher =    "ACM",
  title =        "The Next 700 Programming Languages",
  volume =       "9",
  x-abstract =   "A family of unimplemented computing languages is
                 described that is intended to span differences of
                 application area by a unified framework. This framework
                 dictates the rules about the uses of user-coined names,
                 and the conventions about characterizing functional
                 relationships. Within this framework the design of a
                 specific language splits into two independent parts.
                 One is the choice of written appearances of programs
                 (or more generally, their physical representation). The
                 other is the choice of the abstract entities (such as
                 numbers, character-strings, list of them, functional
                 relations among them) that can be referred to in the
                 {language.The} system is biased towards ”
                 expressions” rather than ” statements.” It
                 includes a nonprocedural (purely functional) subsystem
                 that aims to expand the class of users' needs that can
                 be met by a single print-instruction, without
                 sacrificing the important properties that make
                 conventional right-hand-side expressions easy to
                 construct and understand.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/365230.365257",
  x-issn =       "0001-0782",
  x-url =        "http://dx.doi.org/10.1145/365230.365257",
  xpages =       "157--166",
  year =         "1966",
}

@InProceedings{Cousot1979Systematic,
  author =       "Patrick Cousot and Radhia Cousot",
  booktitle =    "Proceedings of the 6th ACM SIGACT-SIGPLAN Symposium on
                 Principles of Programming Languages",
  citeulike-article-id = "225306",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=567778",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/567752.567778",
  date-added =   "2012-11-14 06:04:21",
  location =     "San Antonio, Texas",
  priority =     "2",
  publisher =    "ACM",
  title =        "Systematic Design of Program Analysis Frameworks",
  x-abstract =   {Semantic analysis of programs is essential in
                 optimizing compilers and program verification systems.
                 It encompasses data flow analysis, data type
                 determination, generation of approximate invariant
                 assertions, etc. Several recent papers (among others
                 Cousot \& Cousot[77a], Graham \& Wegman[76], Kam \&
                 Ullman[76], Kildall[73], Rosen[78], Tarjan[76],
                 Wegbreit[75]) have introduced abstract approaches to
                 program analysis which are tantamount to the use of a
                 program analysis framework (A,t,\~{a}) where A is a
                 lattice of (approximate) assertions, t is an
                 (approximate) predicate transformer and \~{a} is an
                 often implicit function specifying the meaning of the
                 elements of A. This paper is devoted to the systematic
                 and correct design of program analysis frameworks with
                 respect to a formal semantics. Preliminary definitions
                 are given in Section 2 concerning the merge over all
                 paths and (least) fixpoint program-wide analysis
                 methods. In Section 3 we briefly define the (forward
                 and backward) deductive semantics of programs which is
                 later used as a formal basis in order to prove the
                 correctness of the approximate program analysis
                 frameworks. Section 4 very shortly recall the main
                 elements of the lattice theoretic approach to
                 approximate semantic analysis of programs. The design
                 of a space of approximate assertions A is studied in
                 Section 5. We first justify the very reasonable
                 assumption that A must be chosen such that the exact
                 invariant assertions of any program must have an upper
                 approximation in A and that the approximate analysis of
                 any program must be performed using a deterministic
                 process. These assumptions are shown to imply that A is
                 a Moore family, that the approximation operator (wich
                 defines the least upper approximation of any assertion)
                 is an upper closure operator and that A is necessarily
                 a complete lattice. We next show that the connection
                 between a space of approximate assertions and a
                 computer representation is naturally made using a pair
                 of isotone adjoined functions. This type of connection
                 between two complete lattices is related to Galois
                 connections thus making available classical
                 mathematical results. Additional results are proved,
                 they hold when no two approximate assertions have the
                 same meaning. In Section 6 we study and examplify
                 various methods which can be used in order to define a
                 space of approximate assertions or equivalently an
                 approximation function. They include the
                 characterization of the least Moore family containing
                 an arbitrary set of assertions, the construction of the
                 least closure operator greater than or equal to an
                 arbitrary approximation function, the definition of
                 closure operators by composition, the definition of a
                 space of approximate assertions by means of a complete
                 join congruence relation or by means of a family of
                 principal ideals. Section 7 is dedicated to the design
                 of the approximate predicate transformer induced by a
                 space of approximate assertions. First we look for a
                 reasonable definition of the correctness of approximate
                 predicate transformers and show that a local
                 correctness condition can be given which has to be
                 verified for every type of elementary statement. This
                 local correctness condition ensures that the (merge
                 over all paths or fixpoint) global analysis of any
                 program is correct. Since isotony is not required for
                 approximate predicate transformers to be correct it is
                 shown that non-isotone program analysis frameworks are
                 manageable although it is later argued that the isotony
                 hypothesis is natural. We next show that among all
                 possible approximate predicate transformers which can
                 be used with a given space of approximate assertions
                 there exists a best one which provides the maximum
                 information relative to a program-wide analysis method.
                 The best approximate predicate transformer induced by a
                 space of approximate assertions turns out to be
                 isotone. Some interesting consequences of the existence
                 of a best predicate transformer are examined. One is
                 that we have in hand a formal specification of the
                 programs which have to be written in order to implement
                 a program
?? BibTeX string too long for field ``x-abstract''.
analysis
framework once a representation of the space of approximate
assertions has been chosen. Examples are given, including ones
where the semantics of programs is formalized using Hoare[78]'s
sets of traces.

In Section 8 we show that a hierarchy of approximate analyses
can be defined according to the fineness of the approximations
specified by a program analysis framework. Some elements of the
hierarchy are shortly exhibited and related to the relevant
literature.

In Section 9 we consider global program analysis methods. The
distinction between "distributive" and "non-distributive" program
analysis frameworks is studied. It is shown that when the best
approximate predicate transformer is considered the coincidence or
not of the merge over all paths and least fixpoint global analyses
of programs is a consequence of the choice of the space of
approximate assertions. It is shown that the space of approximate
assertions can always be refined so that the merge over all paths
analysis of a program can be defined by means of a least fixpoint
of isotone equations.

Section 10 is devoted to the combination of program analysis
frameworks. We study and examplify how to perform the "sum",
"product" and "power" of program analysis frameworks. It is shown
that combined analyses lead to more accurate information than the
conjunction of the corresponding separate analyses but this can
only be achieved by a new design of the approximate predicate
transformer induced by the combined program analysis
frameworks.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/567752.567778},
    x-series = {POPL '79},
    x-url = {http://dx.doi.org/10.1145/567752.567778},
    xpages = {269--282},
    year = {1979}
}

@Article{Wright1997Practical,
  author =       "Andrew K. Wright and Robert Cartwright",
  citeulike-article-id = "1400",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=239917",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/239912.239917",
  date-added =   "2012-11-14 05:22:32",
  journal =      "ACM Trans. Program. Lang. Syst.",
  month =        jan,
  number =       "1",
  priority =     "2",
  publisher =    "ACM",
  title =        "A practical soft type system for {Scheme}",
  volume =       "19",
  x-abstract =   "A soft type system infers types for the procedures and
                 data structures of dynamically typed programs. Like
                 conventional static types, soft types express program
                 invariants and thereby provide valuable information for
                 program optimization and debugging. A soft type checker
                 uses the types inferred by a soft type system to
                 eliminate run-time checks that are provably
                 unnecessary; any remaining run-time checks are flagged
                 as potential program errors. Soft Scheme is a practical
                 soft type checker for {R4RS} Scheme. Its underlying
                 type system generalizes conventional {Hindley-Milner}
                 type inference by incorporating recursive types and a
                 limited form of union type. Soft Scheme accommodates
                 all of {R4RS} Scheme including uncurried procedures of
                 fixed and variable arity, assignment, and
                 continuations.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/239912.239917",
  x-issn =       "0164-0925",
  x-url =        "http://dx.doi.org/10.1145/239912.239917",
  xpages =       "87--152",
  year =         "1997",
}

@InProceedings{Might2009Posteriori,
  author =       "Matthew Might and Panagiotis Manolios",
  booktitle =    "Proceedings of the 10th International Conference on
                 Verification, Model Checking, and Abstract
                 Interpretation",
  citeulike-article-id = "4838377",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1505362.1505387",
  citeulike-linkout-1 = "http://dx.doi.org/10.1007/978-3-540-93900-9\_22",
  date-added =   "2012-11-14 05:08:56",
  location =     "Savannah, GA",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "A Posteriori Soundness for Non-deterministic Abstract
                 Interpretations",
  x-abstract =   "An abstract interpretation's resource-allocation
                 policy (<em>e.g.</em> , one heap summary node per
                 allocation site) largely determines both its speed and
                 precision. Historically, context has driven allocation
                 policies, and as a result, these policies are said to
                 determine the {"}context-sensitivity{"} of the
                 analysis. This work gives analysis designers newfound
                 freedom to manipulate speed and precision by severing
                 the link between allocation policy and
                 context-sensitivity: abstract allocation policies may
                 be unhinged not only from context, but also from even a
                 predefined correspondence with a concrete allocation
                 policy. We do so by proving that abstract allocation
                 policies can be made non-deterministic without
                 sacrificing correctness; this non-determinism permits
                 precision-guided allocation policies previously assumed
                 to be unsafe. To prove correctness, we introduce the
                 notion of <em>a posteriori</em> soundness for an
                 analysis. A proof of <em>a posteriori</em> soundness
                 differs from a standard proof of soundness in that the
                 abstraction maps used in an <em>a posteriori</em> proof
                 cannot be constructed until <em>after</em> an analysis
                 has been run. Delaying construction allows them to be
                 built so as to justify the decisions made by
                 non-determinism. The crux of the <em>a posteriori</em>
                 soundness theorem is to demonstrate that a justifying
                 abstraction map can <em>always</em> be constructed.",
  x-address =    "Berlin, Heidelberg",
  x-doi =        "10.1007/978-3-540-93900-9\_22",
  x-isbn =       "978-3-540-93899-6",
  x-series =     "VMCAI '09",
  x-url =        "http://dx.doi.org/10.1007/978-3-540-93900-9\_22",
  xpages =       "260--274",
  year =         "2009",
}

@Article{Hartel1996Benchmarking,
  author =       "Pieter H. Hartel and Marc Feeley and Martin Alt and
                 Lennart Augustsson and Peter Baumann and Marcel
                 Beemster and Emmanuel Chailloux and Christine H. Flood
                 and Wolfgang Grieskamp and John H. G. Van Groningen and
                 Kevin Hammond and Bogumil Hausman and Melody Y. Ivory
                 and Richard E. Jones and Jasper Kamperman and Peter Lee
                 and Xavier Leroy and Rafael D. Lins and Sandra
                 Loosemore and Niklas R{\"{o}}jemo and Manuel Serrano
                 and Jean P. Talpin and Jon Thackray and Stephen Thomas
                 and Pum Walters and Pierre Weis and Peter Wentworth",
  citeulike-article-id = "11678765",
  citeulike-linkout-0 = "http://journals.cambridge.org/action/displayAbstract?fromPage=online\&aid=1349904",
  citeulike-linkout-1 = "http://dx.doi.org/10.1017/s0956796800001891",
  date-added =   "2012-11-12 20:57:35",
  journal =      "Journal of Functional Programming",
  number =       "04",
  priority =     "2",
  title =        "Benchmarking implementations of functional languages
                 with ``Pseudoknot'', a float-intensive benchmark",
  volume =       "6",
  x-abstract =   "Over 25 implementations of different functional
                 languages are benchmarked using the same program, a
                 floating-point intensive application taken from
                 molecular biology. The principal aspects studied are
                 compile time and execution time for the various
                 implementations that were benchmarked. An important
                 consideration is how the program can be modified and
                 tuned to obtain maximal performance on each language
                 implementation. With few exceptions, the compilers take
                 a significant amount of time to compile this program,
                 though most compilers were faster than the then current
                 {GNU} C compiler ({GCC} version 2.5.8). Compilers that
                 generate C or Lisp are often slower than those that
                 generate native code directly: the cost of compiling
                 the intermediate form is normally a large fraction of
                 the total compilation time. There is no clear
                 distinction between the runtime performance of eager
                 and lazy implementations when appropriate annotations
                 are used: lazy implementations have clearly come of age
                 when it comes to implementing largely strict
                 applications, such as the Pseudoknot program. The speed
                 of C can be approached by some implementations, but to
                 achieve this performance, special measures such as
                 strictness annotations are required by non-strict
                 implementations. The benchmark results have to be
                 interpreted with care. Firstly, a benchmark based on a
                 single program cannot cover a wide spectrum of
                 \^{a}typical\^{a} applications. Secondly, the compilers
                 vary in the kind and level of optimisations offered, so
                 the effort required to obtain an optimal version of the
                 program is similarly varied.",
  x-doi =        "10.1017/s0956796800001891",
  x-url =        "http://dx.doi.org/10.1017/s0956796800001891",
  xpages =       "621--655",
  year =         "1996",
}

@InProceedings{Might2011Family,
  author =       "Matthew Might and David Van Horn",
  booktitle =    "Static Analysis",
  chapter =      "16",
  citeulike-article-id = "11642508",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-642-23702-7\_16",
  citeulike-linkout-1 = "http://www.springerlink.com/content/j272827h5r088h78",
  citeulike-linkout-2 = "http://link.springer.com/chapter/10.1007/978-3-642-23702-7\_16",
  date-added =   "2012-11-09 04:07:30",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "A Family of Abstract Interpretations for Static
                 Analysis of Concurrent {Higher-Order} Programs",
  volume =       "6887",
  x-abstract =   "We develop a framework for computing two foundational
                 analyses for concurrent higher-order programs:
                 (control-)flow analysis ({CFA}) and
                 may-happen-in-parallel analysis ({MHP}). We pay special
                 attention to the unique challenges posed by the
                 unrestricted mixture of first-class continuations and
                 dynamically spawned threads. To set the stage, we
                 formulate a concrete model of concurrent higher-order
                 programs: the {P(CEK}*)S machine. We find that the
                 systematic abstract interpretation of this machine is
                 capable of computing both flow and {MHP} analyses. Yet,
                 a closer examination finds that the precision for {MHP}
                 is poor. As a remedy, we adapt a shape analytic
                 technique—singleton abstraction—to dynamically
                 spawned threads (as opposed to objects in the heap). We
                 then show that if {MHP} analysis is not of interest, we
                 can substantially accelerate the computation of flow
                 analysis alone by collapsing thread interleavings with
                 a second layer of abstraction.",
  x-address =    "Berlin, Heidelberg",
  x-doi =        "10.1007/978-3-642-23702-7\_16",
  x-editor =     "Yahav, Eran",
  x-isbn =       "978-3-642-23701-0",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-642-23702-7\_16",
  xpages =       "180--197",
  year =         "2011",
}

@InProceedings{TobinHochstadt2012Higherorder,
  author =       "Sam Tobin-Hochstadt and David {Van Horn}",
  booktitle =    "Proceedings of the ACM International Conference on
                 Object Oriented Programming Systems Languages and
                 Applications",
  citeulike-article-id = "11642456",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2384616.2384655",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2384616.2384655",
  date-added =   "2012-11-09 03:59:55",
  location =     "Tucson, Arizona, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "Higher-order symbolic execution via contracts",
  x-abstract =   "We present a new approach to automated reasoning about
                 higher-order programs by extending symbolic execution
                 to use behavioral contracts as symbolic values, thus
                 enabling symbolic approximation of higher-order
                 behavior. Our approach is based on the idea of an
                 abstract reduction semantics that gives an operational
                 semantics to programs with both concrete and symbolic
                 components. Symbolic components are approximated by
                 their contract and our semantics gives an operational
                 interpretation of contracts-as-values. The result is an
                 executable semantics that soundly predicts program
                 behavior, including contract failures, for all possible
                 instantiations of symbolic components. We show that our
                 approach scales to an expressive language of contracts
                 including arbitrary programs embedded as predicates,
                 dependent function contracts, and recursive contracts.
                 Supporting this rich language of specifications leads
                 to powerful symbolic reasoning using existing program
                 constructs. We then apply our approach to produce a
                 verifier for contract correctness of components,
                 including a sound and computable approximation to our
                 semantics that facilitates fully automated contract
                 verification. Our implementation is capable of
                 verifying contracts expressed in existing programs, and
                 of justifying contract-elimination optimizations.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2384616.2384655",
  x-isbn =       "978-1-4503-1561-6",
  x-series =     "OOPSLA",
  x-url =        "http://dx.doi.org/10.1145/2384616.2384655",
  xpages =       "537--554",
  year =         "2012",
}

@InProceedings{eli/stxparam,
  author =       "Eli Barzilay and Ryan Culpepper and Matthew Flatt",
  booktitle =    "Workshop on Scheme and Functional Programming",
  citeulike-article-id = "11599100",
  date-added =   "2012-11-09 03:52:34",
  keywords =     "macros, racket, syntax",
  priority =     "2",
  title =        "Keeping it Clean with Syntax Parameters",
  year =         "2011",
}

@InProceedings{Earl2012Introspective,
  author =       "Christopher Earl and Ilya Sergey and Matthew Might and
                 David Van{ }Horn",
  booktitle =    "Proceedings of the 17th ACM SIGPLAN International
                 Conference on Functional Programming",
  citeulike-article-id = "11463048",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2364576",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2364527.2364576",
  date-added =   "2012-10-14 18:58:47",
  location =     "Copenhagen, Denmark",
  priority =     "2",
  publisher =    "ACM",
  title =        "Introspective pushdown analysis of higher-order
                 programs",
  x-abstract =   "In the static analysis of functional programs,
                 pushdown flow analysis and abstract garbage collection
                 skirt just inside the boundaries of soundness and
                 decidability. Alone, each method reduces analysis times
                 and boosts precision by orders of magnitude. This work
                 illuminates and conquers the theoretical challenges
                 that stand in the way of combining the power of these
                 techniques. The challenge in marrying these techniques
                 is not subtle: computing the reachable control states
                 of a pushdown system relies on limiting access during
                 transition to the top of the stack; abstract garbage
                 collection, on the other hand, needs full access to the
                 entire stack to compute a root set, just as concrete
                 collection does. Introspective pushdown systems resolve
                 this conflict. Introspective pushdown systems provide
                 enough access to the stack to allow abstract garbage
                 collection, but they remain restricted enough to
                 compute control-state reachability, thereby enabling
                 the sound and precise product of pushdown analysis and
                 abstract garbage collection. Experiments reveal
                 synergistic interplay between the techniques, and the
                 fusion demonstrates {"}better-than-both-worlds{"}
                 precision.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2364527.2364576",
  x-isbn =       "978-1-4503-1054-3",
  x-series =     "ICFP '12",
  x-url =        "http://dx.doi.org/10.1145/2364527.2364576",
  xpages =       "177--188",
  year =         "2012",
}

@Article{VanHorn2012Systematic,
  author =       "David Van{ }Horn and Matthew Might",
  citeulike-article-id = "11463031",
  citeulike-linkout-0 = "http://journals.cambridge.org/action/displayAbstract?fromPage=online\&aid=8669075",
  citeulike-linkout-1 = "http://dx.doi.org/10.1017/s0956796812000238",
  date-added =   "2012-10-14 18:56:08",
  journal =      "Journal of Functional Programming",
  number =       "Special Issue 4-5",
  priority =     "2",
  title =        "Systematic abstraction of abstract machines",
  volume =       "22",
  x-doi =        "10.1017/s0956796812000238",
  x-url =        "http://dx.doi.org/10.1017/s0956796812000238",
  xpages =       "705--746",
  year =         "2012",
}

@Article{Feeley1987Using,
  author =       "Marc Feeley and Guy Lapalme",
  citeulike-article-id = "11462978",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=27476",
  citeulike-linkout-1 = "http://dx.doi.org/10.1016/0096-0551(87)90012-9",
  date-added =   "2012-10-14 18:47:33",
  journal =      "Comput. Lang.",
  month =        jan,
  number =       "1",
  priority =     "2",
  publisher =    "Pergamon Press, Inc.",
  title =        "Using closures for code generation",
  volume =       "12",
  x-abstract =   "An abstract is not available.",
  x-address =    "Tarrytown, NY, USA",
  x-doi =        "10.1016/0096-0551(87)90012-9",
  x-issn =       "0096-0551",
  x-url =        "http://dx.doi.org/10.1016/0096-0551(87)90012-9",
  xpages =       "47--66",
  year =         "1987",
}

@InProceedings{Boucher1996Abstract,
  author =       "Dominique Boucher and Marc Feeley",
  booktitle =    "Compiler Construction: 6th International Conference,
                 CC'96 Link{\"{o}}ping, Sweden",
  citeulike-article-id = "11462900",
  citeulike-linkout-0 = "http://link.springer.com/chapter/10.1007/3-540-61053-7\_62",
  date-added =   "2012-10-14 18:36:36",
  priority =     "0",
  title =        "Abstract compilation: {A} new implementation paradigm
                 for static analysis",
  x-editor =     "Gyim\'{o}thy, Tibor",
  x-url =        "http://link.springer.com/chapter/10.1007/3-540-61053-7\_62",
  xpages =       "192--207",
  year =         "1996",
}

@InProceedings{Pnueli1977Temporal,
  author =       "Amir Pnueli",
  booktitle =    "Proceedings of the 18th Annual Symposium on
                 Foundations of Computer Science",
  citeulike-article-id = "4406307",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1382534",
  citeulike-linkout-1 = "http://doi.ieeecomputersociety.org/10.1109/SFCS.1977.32",
  citeulike-linkout-2 = "http://dx.doi.org/10.1109/sfcs.1977.32",
  citeulike-linkout-3 = "http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4567924",
  date-added =   "2012-07-07 07:13:56",
  day =          "18",
  journal =      "Foundations of Computer Science, Annual IEEE Symposium
                 on",
  location =     "Providence, RI, USA",
  month =        oct,
  priority =     "2",
  publisher =    "IEEE Computer Society",
  title =        "The Temporal Logic of Programs",
  volume =       "0",
  x-abstract =   "A unified approach to program verification is
                 suggested, which applies to both sequential and
                 parallel programs. The main proof method suggested is
                 that of temporal reasoning in which the time dependence
                 of events is the basic concept. Two formal systems are
                 presented for providing a basis for temporal reasoning.
                 One forms a formalization of the method of intermittent
                 assertions, while the other is an adaptation of the
                 tense logic system Kb, and is particularly suitable for
                 reasoning about concurrent programs.",
  x-address =    "Washington, DC, USA",
  x-doi =        "10.1109/sfcs.1977.32",
  x-issn =       "0272-5428",
  x-series =     "SFCS '77",
  x-url =        "http://dx.doi.org/10.1109/sfcs.1977.32",
  xpages =       "46--57",
  year =         "1977",
}

@InProceedings{Rondon2008Liquid,
  author =       "Patrick M. Rondon and Ming Kawaguci and Ranjit Jhala",
  booktitle =    "Proceedings of the 2008 ACM SIGPLAN Conference on
                 Programming Language Design and Implementation",
  citeulike-article-id = "10857337",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1375581.1375602",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1375581.1375602",
  date-added =   "2012-07-04 21:31:01",
  location =     "Tucson, AZ, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "Liquid Types",
  x-abstract =   "We present Logically Qualified Data Types, abbreviated
                 to Liquid Types, a system that combines
                 {Hindley-Milner} type inference with Predicate
                 Abstraction to automatically infer dependent types
                 precise enough to prove a variety of safety properties.
                 Liquid types allow programmers to reap many of the
                 benefits of dependent types, namely static verification
                 of critical properties and the elimination of expensive
                 run-time checks, without the heavy price of manual
                 annotation. We have implemented liquid type inference
                 in {DSOLVE}, which takes as input an {OCAML} program
                 and a set of logical qualifiers and infers dependent
                 types for the expressions in the {OCAML} program. To
                 demonstrate the utility of our approach, we describe
                 experiments using {DSOLVE} to statically verify the
                 safety of array accesses on a set of {OCAML} benchmarks
                 that were previously annotated with dependent types as
                 part of the {DML} project. We show that when used in
                 conjunction with a fixed set of array bounds checking
                 qualifiers, {DSOLVE} reduces the amount of manual
                 annotation required for proving safety from 31\% of
                 program text to under 1\%.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1375581.1375602",
  x-isbn =       "978-1-59593-860-2",
  x-series =     "PLDI",
  x-url =        "http://dx.doi.org/10.1145/1375581.1375602",
  xpages =       "159--169",
  year =         "2008",
}

@InProceedings{Kobayashi2009Types,
  author =       "Naoki Kobayashi",
  booktitle =    "Proceedings of the 36th Annual ACM SIGPLAN-SIGACT
                 Symposium on Principles of Programming Languages",
  citeulike-article-id = "5154855",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1480881.1480933",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1480881.1480933",
  date-added =   "2012-07-04 21:21:43",
  location =     "Savannah, GA, USA",
  month =        jan,
  priority =     "2",
  publisher =    "ACM",
  title =        "Types and higher-order recursion schemes for
                 verification of higher-order programs",
  x-abstract =   "We propose a new verification method for temporal
                 properties of higher-order functional programs, which
                 takes advantage of Ong's recent result on the
                 decidability of the model-checking problem for
                 higher-order recursion schemes ({HORS}'s). A program is
                 transformed to an {HORS} that generates a tree
                 representing all the possible event sequences of the
                 program, and then the {HORS} is model-checked. Unlike
                 most of the previous methods for verification of
                 higher-order programs, our verification method is sound
                 and complete. Moreover, this new verification framework
                 allows a smooth integration of abstract model checking
                 techniques into verification of higher-order programs.
                 We also present a type-based verification algorithm for
                 {HORS}'s. The algorithm can deal with only a fragment
                 of the properties expressed by modal mu-calculus, but
                 the algorithm and its correctness proof are (arguably)
                 much simpler than those of Ong's game-semantics-based
                 algorithm. Moreover, while the {HORS} model checking
                 problem is {n-EXPTIME} in general, our algorithm is
                 linear in the size of {HORS}, under the assumption that
                 the sizes of types and specification formulas are
                 bounded by a constant.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1480881.1480933",
  x-isbn =       "978-1-60558-379-2",
  x-issn =       "0362-1340",
  x-series =     "POPL",
  x-url =        "http://dx.doi.org/10.1145/1480881.1480933",
  xpages =       "416--428",
  year =         "2009",
}

@InProceedings{Xu2012Hybrid,
  author =       "Dana N. Xu",
  booktitle =    "Proceedings of the ACM SIGPLAN 2012 Workshop on
                 Partial Evaluation and Program Manipulation",
  citeulike-article-id = "10365708",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2103767",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2103746.2103767",
  date-added =   "2012-07-04 21:08:20",
  location =     "Philadelphia, Pennsylvania, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "Hybrid contract checking via symbolic simplification",
  x-abstract =   "Program errors are hard to detect or prove absent.
                 Allowing programmers to write formal and precise
                 specifications, especially in the form of contracts, is
                 a popular approach to program verification and error
                 discovery. We formalize and implement a hybrid (static
                 and dynamic) contract checker for a subset of {OCaml}.
                 The key technique is symbolic simplification, which
                 makes integrating static and dynamic contract checking
                 easy and effective. Our technique statically checks
                 contract satisfaction or blames the function violating
                 the contract. When a contract satisfaction is
                 undecidable, it leaves residual code for dynamic
                 contract checking.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2103746.2103767",
  x-isbn =       "978-1-4503-1118-2",
  x-series =     "PEPM",
  x-url =        "http://dx.doi.org/10.1145/2103746.2103767",
  xpages =       "107--116",
  year =         "2012",
}

@Article{Plotkin1977LCF,
  author =       "G. D. Plotkin",
  citeulike-article-id = "5392255",
  citeulike-linkout-0 = "http://dx.doi.org/10.1016/0304-3975(77)90044-5",
  date-added =   "2012-02-18 18:56:57",
  journal =      "Theoretical Computer Science",
  month =        dec,
  number =       "3",
  priority =     "0",
  title =        "{LCF} considered as a programming language",
  volume =       "5",
  x-abstract =   "The paper studies connections between denotational and
                 operational semantics for a simple programming language
                 based on {LCF}. It begins with the connection between
                 the behaviour of a program and its denotation. It turns
                 out that a program denotes ⊥ in any of several
                 possible semantics if it does not terminate. From this
                 it follows that if two terms have the same denotation
                 in one of these semantics, they have the same behaviour
                 in all contexts. The converse fails for all the
                 semantics. If, however, the language is extended to
                 allow certain parallel facilities behavioural
                 equivalence does coincide with denotational equivalence
                 in one of the semantics considered, which may therefore
                 be called ” fully abstract”. Next a connection is
                 given which actually determines the semantics up to
                 isomorphism from the behaviour alone. Conversely, by
                 allowing further parallel facilities, every r.e.
                 element of the fully abstract semantics becomes
                 definable, thus characterising the programming
                 language, up to interdefinability, from the set of r.e.
                 elements of the domains of the semantics.",
  x-doi =        "10.1016/0304-3975(77)90044-5",
  x-issn =       "03043975",
  x-url =        "http://dx.doi.org/10.1016/0304-3975(77)90044-5",
  xpages =       "223--255",
  year =         "1977",
}

@InProceedings{Felleisen2009Functional,
  author =       "Matthias Felleisen and Robert B. Findler and Matthew
                 Flatt and Shriram Krishnamurthi",
  booktitle =    "ICFP '09 Proceedings of the 14th ACM SIGPLAN
                 International Conference on Functional programming",
  citeulike-article-id = "10143246",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1596561",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1631687.1596561",
  date-added =   "2011-12-19 16:14:53",
  month =        aug,
  priority =     "2",
  publisher =    "ACM",
  title =        "A functional {I/O} system or, fun for freshman kids",
  x-abstract =   "Functional programming languages ought to play a
                 central role in mathematics education for middle
                 schools (age range: 10-14). After all, functional
                 programming is a form of algebra and programming is a
                 creative activity about problem solving. Introducing it
                 into mathematics courses would make pre-algebra course
                 come alive. If input and output were invisible,
                 students could implement fun simulations, animations,
                 and even interactive and distributed games all while
                 using nothing more than plain mathematics. We have
                 implemented this vision with a simple framework for
                 purely functional {I/O}. Using this framework, students
                 design, implement, and test plain mathematical
                 functions over numbers, booleans, string, and images.
                 Then the framework wires them up to devices and
                 performs all the translation from external information
                 to internal data (and vice versa)--just like every
                 other operating system. Once middle school students are
                 hooked on this form of programming, our curriculum
                 provides a smooth path for them from pre-algebra to
                 freshman courses in college on object-oriented design
                 and theorem proving.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1631687.1596561",
  x-issn =       "0362-1340",
  x-url =        "http://dx.doi.org/10.1145/1631687.1596561",
  xpages =       "47--58",
  year =         "2009",
}

@InProceedings{Sheard2004Languages,
  author =       "Tim Sheard",
  booktitle =    "Companion to the 19th annual ACM SIGPLAN conference on
                 Object-oriented programming systems, languages, and
                 applications",
  citeulike-article-id = "891157",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1028711",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1028664.1028711",
  date-added =   "2011-12-18 14:21:04",
  location =     "Vancouver, BC, CANADA",
  priority =     "2",
  publisher =    "ACM",
  title =        "Languages of the future",
  x-abstract =   "This paper explores a new point in the design space of
                 formal reasoning systems - part programming language,
                 part logical framework. The system is built on a
                 programming language where the user expresses equality
                 constraints between types and the type checker then
                 enforces these constraints. This simple extension to
                 the type system allows the programmer to describe
                 properties of his program in the types of witness
                 objects which can be thought of as concrete evidence
                 that the program has the property desired. These
                 techniques and two other rich typing mechanisms,
                 {rank-N} polymorphism and extensible kinds, create a
                 powerful new programming idiom for writing programs
                 whose types enforce semantic properties. This kind of
                 synthesis between a practical programming language
                 <i>and</i> a logic creates a foundation for the design
                 of languages of the future.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1028664.1028711",
  x-isbn =       "1-58113-833-4",
  x-series =     "OOPSLA '04",
  x-url =        "http://dx.doi.org/10.1145/1028664.1028711",
  xpages =       "116--119",
  year =         "2004",
}

@Article{McBride2004View,
  author =       "Conor McBride and James McKinna",
  citeulike-article-id = "271357",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=967496",
  citeulike-linkout-1 = "http://journals.cambridge.org/action/displayAbstract?fromPage=online\&aid=192403",
  citeulike-linkout-2 = "http://dx.doi.org/10.1017/s0956796803004829",
  date-added =   "2011-12-18 14:18:52",
  journal =      "J. Funct. Program.",
  month =        jan,
  number =       "1",
  priority =     "2",
  publisher =    "Cambridge University Press",
  title =        "The view from the left",
  volume =       "14",
  x-abstract =   "Pattern matching has proved an extremely powerful and
                 durable notion in functional programming. This paper
                 contributes a new programming notation for type theory
                 which elaborates the notion in various ways. First, as
                 is by now quite well-known in the type theory
                 community, definition by pattern matching becomes a
                 more discriminating tool in the presence of dependent
                 types, since it refines the explanation of types as
                 well as values. This becomes all the more true in the
                 presence of the rich class of datatypes known as
                 inductive families (Dybjer, 1991). Secondly, as
                 proposed by Peyton Jones (1997) for Haskell, and
                 independently rediscovered by us, subsidiary case
                 analyses on the results of intermediate computations,
                 which commonly take place on the right-hand side of
                 definitions by pattern matching, should rather be
                 handled on the left. In simply-typed languages, this
                 subsumes the trivial case of Boolean guards; in our
                 setting it becomes yet more powerful. Thirdly,
                 elementary pattern matching decompositions have a
                 well-defined interface given by a dependent type; they
                 correspond to the statement of an induction principle
                 for the datatype. More general, user-definable
                 decompositions may be defined which also have types of
                 the same general form. Elementary pattern matching may
                 therefore be recast in abstract form, with a semantics
                 given by translation. Such abstract decompositions of
                 data generalize Wadler's (1987) notion of 'view'. The
                 programmer wishing to introduce a new view of a type
                 \$\mathit{T}\$, and exploit it directly in pattern
                 matching, may do so via a standard programming idiom.
                 The type theorist, looking through the Curry–Howard
                 lens, may see this as proving a theorem, one which
                 establishes the validity of a new induction principle
                 for \$\mathit{T}\$. We develop enough syntax and
                 semantics to account for this high-level style of
                 programming in dependent type theory. We close with the
                 development of a typechecker for the simply-typed
                 lambda calculus, which furnishes a view of raw terms as
                 either being well-typed, or containing an error. The
                 implementation of this view is ipso facto a proof that
                 typechecking is decidable.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1017/s0956796803004829",
  x-issn =       "0956-7968",
  x-url =        "http://dx.doi.org/10.1017/s0956796803004829",
  xpages =       "69--111",
  year =         "2004",
}

@InProceedings{Augustsson1998Cayennea,
  author =       "Lennart Augustsson",
  booktitle =    "ICFP '98 Proceedings of the third ACM SIGPLAN
                 International Conference on Functional Programming",
  citeulike-article-id = "10140986",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=291251.289451",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/291251.289451",
  date-added =   "2011-12-18 14:10:23",
  month =        sep,
  priority =     "2",
  publisher =    "ACM",
  title =        "Cayenne---a language with dependent types",
  volume =       "34",
  x-abstract =   "Cayenne is a Haskell-like language. The main
                 difference between Haskell and Cayenne is that Cayenne
                 has dependent types, i.e., the result type of a
                 function may depend on the argument value, and types of
                 record components (which can be types or values) may
                 depend on other components. Cayenne also combines the
                 syntactic categories for value expressions and type
                 expressions; thus reducing the number of language
                 {concepts.Having} dependent types and combined type and
                 value expressions makes the language very powerful. It
                 is powerful enough that a special module concept is
                 unnecessary; ordinary records suffice. It is also
                 powerful enough to encode predicate logic at the type
                 level, allowing types to be used as specifications of
                 programs. However, this power comes at a cost: type
                 checking of Cayenne is undecidable. While this may
                 appear to be a steep price to pay, it seems to work
                 well in practice.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/291251.289451",
  x-issn =       "0362-1340",
  x-url =        "http://dx.doi.org/10.1145/291251.289451",
  xpages =       "239--250",
  year =         "1998",
}

@InProceedings{Vardoulakis2011Pushdown,
  author =       "Dimitrios Vardoulakis and Olin Shivers",
  booktitle =    "Proceedings of the 16th ACM SIGPLAN International
                 Conference on Functional Programming",
  citeulike-article-id = "9814174",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2034785",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2034773.2034785",
  date-added =   "2011-12-17 22:09:40",
  location =     "Tokyo, Japan",
  priority =     "2",
  publisher =    "ACM",
  title =        "Pushdown flow analysis of first-class control",
  x-abstract =   "Pushdown models are better than control-flow graphs
                 for higher-order flow analysis. They faithfully model
                 the call/return structure of a program, which results
                 in fewer spurious flows and increased precision.
                 However, pushdown models require that calls and returns
                 in the analyzed program nest properly. As a result,
                 they cannot be used to analyze language constructs that
                 break call/return nesting such as generators,
                 coroutines, call/cc, etc. In this paper, we extend the
                 {CFA2} flow analysis to create the first pushdown flow
                 analysis for languages with first-class control. We
                 modify the abstract semantics of {CFA2} to allow
                 continuations to escape to, and be restored from, the
                 heap. We then present a summarization algorithm that
                 handles escaping continuations via a new kind of
                 summary edge. We prove that the algorithm is sound with
                 respect to the abstract semantics.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2034773.2034785",
  x-isbn =       "978-1-4503-0865-6",
  x-series =     "ICFP '11",
  x-url =        "http://dx.doi.org/10.1145/2034773.2034785",
  xpages =       "69--80",
  year =         "2011",
}

@InProceedings{Ahmed2011Blame,
  author =       "Amal Ahmed and Robert B. Findler and Jeremy G. Siek
                 and Philip Wadler",
  booktitle =    "POPL '11 Proceedings of the 38th annual ACM
                 SIGPLAN-SIGACT Symposium on Principles of Programming
                 Languages",
  citeulike-article-id = "9338783",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1925844.1926409",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1925844.1926409",
  date-added =   "2011-12-03 22:17:37",
  journal =      "SIGPLAN Not.",
  month =        jan,
  number =       "1",
  priority =     "2",
  publisher =    "ACM",
  title =        "Blame for All",
  volume =       "46",
  x-abstract =   "Several programming languages are beginning to
                 integrate static and dynamic typing, including Racket
                 (formerly {PLT} Scheme), Perl 6, and C\# 4.0 and the
                 research languages Sage (Gronski, Knowles, Tomb,
                 Freund, and Flanagan, 2006) and Thorn (Wrigstad,
                 Eugster, Field, Nystrom, and Vitek, 2009). However, an
                 important open question remains, which is how to add
                 parametric polymorphism to languages that combine
                 static and dynamic typing. We present a system that
                 permits a value of dynamic type to be cast to a
                 polymorphic type and vice versa, with relational
                 parametricity enforced by a kind of dynamic sealing
                 along the lines proposed by Matthews and Ahmed (2008)
                 and Neis, Dreyer, and Rossberg (2009). Our system
                 includes a notion of blame, which allows us to show
                 that when casting between a more-precise type and a
                 less-precise type, any cast failures are due to the
                 less-precisely-typed portion of the program. We also
                 show that a cast from a subtype to its supertype cannot
                 fail.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1925844.1926409",
  x-issn =       "0362-1340",
  x-url =        "http://dx.doi.org/10.1145/1925844.1926409",
  xpages =       "201--214",
  year =         "2011",
}

@InProceedings{Guha2007Relationallyparametric,
  author =       "Arjun Guha and Jacob Matthews and Robert B. Findler
                 and Shriram Krishnamurthi",
  booktitle =    "Proceedings of the 2007 symposium on Dynamic
                 languages",
  citeulike-article-id = "6414694",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1297081.1297089",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1297081.1297089",
  date-added =   "2011-12-03 22:12:17",
  location =     "Montreal, Quebec, Canada",
  priority =     "2",
  publisher =    "ACM",
  title =        "Relationally-parametric polymorphic contracts",
  x-abstract =   "The analogy between types and contracts raises the
                 question of how many features of static type systems
                 can be expressed as dynamic contracts. An important
                 feature missing in prior work on contracts is
                 parametricity, as represented by the polymorphic types
                 in languages like Standard {ML}. We present a contract
                 counterpart to parametricity. We explore multiple
                 designs for such a system and present one that is
                 simple and incurs minimal execution overhead. We show
                 how to extend the notion of contract blame to our
                 definition. We present a form of inference that can
                 often save programmers from having to explicitly
                 instantiate many parametric contracts. Finally, we
                 present several examples that illustrate how this
                 system mimics the feel and properties of parametric
                 polymorphism in typed languages.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1297081.1297089",
  x-isbn =       "978-1-59593-868-8",
  x-series =     "DLS '07",
  x-url =        "http://dx.doi.org/10.1145/1297081.1297089",
  xpages =       "29--40",
  year =         "2007",
}

@InProceedings{Flanagan2006Hybrid,
  author =       "Cormac Flanagan",
  booktitle =    "POPL '06: Conference record of the 33rd ACM
                 SIGPLAN-SIGACT Symposium on Principles of Programming
                 Languages",
  citeulike-article-id = "638089",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1111059",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1111037.1111059",
  date-added =   "2011-12-03 22:04:15",
  location =     "Charleston, South Carolina, USA",
  month =        jan,
  number =       "1",
  priority =     "2",
  publisher =    "ACM",
  title =        "Hybrid type checking",
  volume =       "41",
  x-abstract =   "Traditional static type systems are very effective for
                 verifying basic interface specifications, but are
                 somewhat limited in the kinds specifications they
                 support. Dynamically-checked contracts can enforce more
                 precise specifications, but these are not checked until
                 run time, resulting in incomplete detection of
                 {defects.Hybrid} type checking is a synthesis of these
                 two approaches that enforces precise interface
                 specifications, via static analysis where possible, but
                 also via dynamic checks where necessary. This paper
                 explores the key ideas and implications of hybrid type
                 checking, in the context of the simply-typed
                 λ-calculus with arbitrary refinements of base types.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1111037.1111059",
  x-isbn =       "1-59593-027-2",
  x-issn =       "0362-1340",
  x-series =     "POPL",
  x-url =        "http://dx.doi.org/10.1145/1111037.1111059",
  xpages =       "245--256",
  year =         "2006",
}

@InCollection{Findler2008Implementation,
  author =       "Robert B. Findler and Shu Y. Guo and Anne Rogers",
  booktitle =    "Implementation and Application of Functional
                 Languages",
  chapter =      "Lazy Contract Checking for Immutable Data Structures",
  citeulike-article-id = "6500117",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1425825",
  citeulike-linkout-1 = "http://dx.doi.org/10.1007/978-3-540-85373-2\_7",
  citeulike-linkout-2 = "http://www.springerlink.com/content/650xm483h1w14381",
  date-added =   "2011-12-03 21:44:00",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "Implementation and Application of Functional
                 Languages",
  x-abstract =   "Existing contract checkers for data structures force
                 programmers to choose between poor alternatives.
                 Contracts are either built into the functions that
                 construct the data structure, meaning that each object
                 can only be used with a single contract and that a data
                 structure with an invariant cannot be viewed as a
                 subtype of the data structure without the invariant
                 (thus inhibiting abstraction) or contracts are checked
                 eagerly when an operation on the data structure is
                 invoked, meaning that many redundant checks are
                 performed, potentially even changing the program's
                 asymptotic {complexity.We} explore the idea of adding a
                 small, controlled amount of laziness to contract
                 checkers so that the contracts on a data structure are
                 only checked as the program inspects the data
                 structure. Unlike contracts on the constructors, our
                 lazy contracts allow subtyping and thus preserve the
                 potential for abstraction. Unlike eagerly-checked
                 contracts, our contracts do not affect the asymptotic
                 behavior of the {program.This} paper presents our
                 implementation of these ideas, an optimization in our
                 implementation, performance measurements, and a
                 discussion of an extension to our implementation that
                 admits more expressive contracts by loosening the
                 strict asymptotic guarantees and only preserving the
                 amortized asymptotic complexity.",
  x-address =    "Berlin, Heidelberg",
  x-doi =        "10.1007/978-3-540-85373-2\_7",
  x-editor =     "Chitil, Olaf and Horv\'{a}th, Zolt\'{a}n and Zs\'{o}k,
                 Vikt\'{o}ria",
  x-isbn =       "978-3-540-85372-5",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-540-85373-2\_7",
  xpages =       "111--128",
  year =         "2008",
}

@InProceedings{Dimoulas2011Correct,
  author =       "Christos Dimoulas and Robert B. Findler and Cormac
                 Flanagan and Matthias Felleisen",
  booktitle =    "Proceedings of the 38th Annual ACM SIGPLAN-SIGACT
                 Symposium on Principles of Programming Languages",
  citeulike-article-id = "9525496",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1926410",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1925844.1926410",
  date-added =   "2011-12-03 20:50:36",
  journal =      "SIGPLAN Not.",
  location =     "Austin, Texas, USA",
  month =        jan,
  priority =     "2",
  publisher =    "ACM",
  title =        "Correct Blame for Contracts: No More Scapegoating",
  x-abstract =   "Behavioral software contracts supplement interface
                 information with logical assertions. A rigorous
                 enforcement of contracts provides useful feedback to
                 developers if it signals contract violations as soon as
                 they occur and if it assigns blame to violators with
                 preciseexplanations. Correct blame assignment gets
                 programmers started with the debugging process and can
                 significantly decrease the time needed to discover and
                 fix bugs. Sadly the literature on contracts lacks a
                 framework for making statements about the correctness
                 of blame assignment and for validating such statements.
                 This paper fills the gap and uses the framework to
                 demonstrate how one of the proposed semantics for
                 higher-order contracts satisfies this criteria and
                 another semantics occasionally assigns blame to the
                 wrong module. Concretely, the paper applies the
                 framework to the lax enforcement of dependent
                 higher-order contracts and the picky one. A
                 higher-order dependent contract specifies constraints
                 for the domain and range of higher-order functions and
                 also relates arguments and results in auxiliary
                 assertions. The picky semantics ensures that the use of
                 arguments in the auxiliary assertion satisfies the
                 domain contracts and the lax one does not. While the
                 picky semantics discovers more contract violations than
                 the lax one, it occasionally blames the wrong module.
                 Hence the paper also introduces a third semantics,
                 dubbed indy, which fixes the problems of the picky
                 semantics without giving up its advantages.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1925844.1926410",
  x-isbn =       "978-1-4503-0490-0",
  x-issn =       "0362-1340",
  x-series =     "POPL",
  x-url =        "http://dx.doi.org/10.1145/1925844.1926410",
  xpages =       "215--226",
  year =         "2011",
}

@Article{Dimoulas2011Contract,
  author =       "Christos Dimoulas and Matthias Felleisen",
  citeulike-article-id = "10091473",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2039348",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2039346.2039348",
  date-added =   "2011-12-03 20:49:52",
  journal =      "ACM Trans. Program. Lang. Syst.",
  month =        nov,
  priority =     "2",
  publisher =    "ACM",
  title =        "On contract satisfaction in a higher-order world",
  volume =       "33",
  x-abstract =   "Behavioral software contracts have become a popular
                 mechanism for specifying and ensuring logical claims
                 about a program's flow of values. While contracts for
                 first-order functions come with a natural
                 interpretation and are well understood, the various
                 incarnations of higher-order contracts adopt,
                 implicitly or explicitly, different views concerning
                 the meaning of contract satisfaction. In this article,
                 we define various notions of contract satisfaction in
                 terms of observational equivalence and compare them
                 with each other and notions in the literature.
                 Specifically, we introduce a small model language with
                 higher-order contracts and use it to formalize
                 different notions of contract satisfaction. Each of
                 them demands that the contract parties satisfy certain
                 observational equivalences.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2039346.2039348",
  x-issn =       "0164-0925",
  x-url =        "http://dx.doi.org/10.1145/2039346.2039348",
  year =         "2011",
}

@InProceedings{Disney2011Temporal,
  author =       "Tim Disney and Cormac Flanagan and Jay McCarthy",
  booktitle =    "ICFP '11 Proceeding of the 16th ACM SIGPLAN
                 International Conference on Functional Programming",
  citeulike-article-id = "10091438",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2034800",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2034574.2034800",
  date-added =   "2011-12-03 20:44:50",
  month =        sep,
  priority =     "2",
  publisher =    "ACM",
  title =        "Temporal Higher-order Contracts",
  x-abstract =   "Behavioral contracts are embraced by software
                 engineers because they document module interfaces,
                 detect interface violations, and help identify faulty
                 modules (packages, classes, functions, etc). This paper
                 extends prior higher-order contract systems to also
                 express and enforce temporal properties, which are
                 common in software systems with imperative state, but
                 which are mostly left implicit or are at best
                 informally specified. The paper presents both a
                 programmatic contract {API} as well as a temporal
                 contract language, and reports on experience and
                 performance results from implementing these contracts
                 in Racket. Our development formalizes module behavior
                 as a trace of events such as function calls and
                 returns. Our contract system provides both
                 non-interference (where contracts cannot influence
                 correct executions) and also a notion of completeness
                 (where contracts can enforce any decidable,
                 prefix-closed predicate on event traces).",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2034574.2034800",
  x-issn =       "0362-1340",
  x-series =     "ICFP",
  x-url =        "http://dx.doi.org/10.1145/2034574.2034800",
  xpages =       "176--188",
  year =         "2011",
}

@InCollection{Chitil2005Lazy,
  author =       "Olaf Chitil and Dan McNeill and Colin Runciman",
  chapter =      "1",
  citeulike-article-id = "10091423",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-540-27861-0\_1",
  citeulike-linkout-1 = "http://www.springerlink.com/content/vbqnja1exd9be0qu",
  date-added =   "2011-12-03 20:39:30",
  priority =     "2",
  publisher =    "Springer Berlin / Heidelberg",
  title =        "Lazy Assertions Implementation of Functional
                 Languages",
  volume =       "3145",
  x-address =    "Berlin, Heidelberg",
  x-doi =        "10.1007/978-3-540-27861-0\_1",
  x-editor =     "Trinder, Phil and Michaelson, Greg and Pe\~{n}a,
                 Ricardo",
  x-isbn =       "978-3-540-23727-3",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-540-27861-0\_1",
  xpages =       "1--19",
  year =         "2005",
}

@InProceedings{Austin2011Virtual,
  author =       "Thomas H. Austin and Tim Disney and Cormac Flanagan",
  booktitle =    "Proceedings of the 2011 ACM International Conference
                 on Object Oriented Programming Systems Languages and
                 Applications",
  citeulike-article-id = "10091422",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2048136",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/2048066.2048136",
  date-added =   "2011-12-03 20:36:31",
  location =     "Portland, Oregon, USA",
  month =        oct,
  priority =     "2",
  publisher =    "ACM",
  title =        "Virtual values for language extension",
  x-abstract =   "This paper focuses on extensibility, the ability of a
                 programmer using a particular language to extend the
                 expressiveness of that language. This paper explores
                 how to provide an interesting notion of extensibility
                 by virtualizing the interface between code and data. A
                 virtual value is a special value that supports
                 behavioral intercession. When a primitive operation is
                 applied to a virtual value, it invokes a trap on that
                 virtual value. A virtual value contains multiple traps,
                 each of which is a user-defined function that describes
                 how that operation should behave on that value. This
                 paper formalizes the semantics of virtual values, and
                 shows how they enable the definition of a variety of
                 language extensions, including additional numeric
                 types; delayed evaluation; taint tracking; contracts;
                 revokable membranes; and units of measure. We report on
                 our experience implementing virtual values for
                 Javascript within an extension for the Firefox
                 browser.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/2048066.2048136",
  x-isbn =       "978-1-4503-0940-0",
  x-issn =       "0362-1340",
  x-series =     "OOPSLA",
  x-url =        "http://dx.doi.org/10.1145/2048066.2048136",
  xpages =       "921--938",
  year =         "2011",
}

@Article{Parnas1972Technique,
  author =       "D. L. Parnas",
  citeulike-article-id = "7021330",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=361309",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/355602.361309",
  date-added =   "2011-12-03 19:40:14",
  journal =      "Commun. ACM",
  month =        may,
  number =       "5",
  priority =     "2",
  publisher =    "ACM",
  title =        "A technique for software module specification with
                 examples",
  volume =       "15",
  x-abstract =   "This paper presents an approach to writing
                 specifications for parts of software systems. The main
                 goal is to provide specifications sufficiently precise
                 and complete that other pieces of software can be
                 written to interact with the piece specified without
                 additional information. The secondary goal is to
                 include in the specification no more information than
                 necessary to meet the first goal. The technique is
                 illustrated by means of a variety of examples from a
                 tutorial system.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/355602.361309",
  x-issn =       "0001-0782",
  x-url =        "http://dx.doi.org/10.1145/355602.361309",
  xpages =       "330--336",
  year =         "1972",
}

@InCollection{America1991Designing,
  author =       "Pierre America",
  booktitle =    "Foundations of Object-Oriented Languages",
  chapter =      "2",
  citeulike-article-id = "10091302",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/bfb0019440",
  citeulike-linkout-1 = "http://www.springerlink.com/content/w025h3gr7gh65q01",
  date-added =   "2011-12-03 19:34:44",
  priority =     "2",
  publisher =    "Springer Berlin / Heidelberg",
  title =        "Designing an object-oriented programming language with
                 behavioural subtyping Foundations of {Object-Oriented}
                 Languages",
  volume =       "489",
  x-abstract =   "This paper describes the design of the parallel
                 object-oriented programming language {POOL}-I. We
                 concentrate on the type system of the language and
                 specifically on the aspects of subtyping and
                 genericity. {POOL}-I is the first language we know of
                 that includes subtyping and inheritance as completely
                 separate language mechanisms. By decoupling these two,
                 which have been strongly tied together in other
                 statically typed object-oriented languages with
                 inheritance, a much cleaner language design can be
                 obtained and a much more flexible use of both
                 mechanisms can be made in actual programs.",
  x-address =    "Berlin/Heidelberg",
  x-doi =        "10.1007/bfb0019440",
  x-editor =     "de Bakker, J. and de Roever, W. and Rozenberg, G.",
  x-isbn =       "3-540-53931-X",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/bfb0019440",
  xpages =       "60--90",
  year =         "1991",
}

@InProceedings{Flanagan2002Extended,
  author =       "Cormac Flanagan and Rustan and Mark Lillibridge and
                 Greg Nelson and James B. Saxe and Raymie Stata",
  booktitle =    "PLDI '02 Proceedings of the ACM SIGPLAN 2002
                 Conference on Programming Language Design and
                 Implementation",
  citeulike-article-id = "514997",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=543552.512558",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/543552.512558",
  date-added =   "2011-08-29 21:55:55",
  month =        may,
  number =       "5",
  priority =     "2",
  publisher =    "ACM",
  title =        "Extended static checking for {J}ava",
  volume =       "37",
  x-abstract =   "Software development and maintenance are costly
                 endeavors. The cost can be reduced if more software
                 defects are detected earlier in the development cycle.
                 This paper introduces the Extended Static Checker for
                 Java ({ESC}/Java), an experimental compile-time program
                 checker that finds common programming errors. The
                 checker is powered by verification-condition generation
                 and automatic theorem-proving techniques. It provides
                 programmers with a simple annotation language with
                 which programmer design decisions can be expressed
                 formally. {ESC}/Java examines the annotated software
                 and warns of inconsistencies between the design
                 decisions recorded in the annotations and the actual
                 code, and also warns of potential runtime errors in the
                 code. This paper gives an overview of the checker
                 architecture and annotation language and describes our
                 experience applying the checker to tens of thousands of
                 lines of Java programs.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/543552.512558",
  x-isbn =       "1581134630",
  x-issn =       "0362-1340",
  x-url =        "http://dx.doi.org/10.1145/543552.512558",
  xpages =       "234--245",
  year =         "2002",
}

@InCollection{Findler2004Semantic,
  author =       "Robert B. Findler and Matthew Flatt and Matthias
                 Felleisen",
  booktitle =    "ECOOP 2004 – Object-Oriented Programming",
  chapter =      "17",
  citeulike-article-id = "8063104",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-540-24851-4\_17",
  citeulike-linkout-1 = "http://www.springerlink.com/content/3fj7h458njr0768k",
  date-added =   "2011-08-29 21:54:14",
  priority =     "2",
  publisher =    "Springer Berlin / Heidelberg",
  title =        "Semantic Casts: Contracts and Structural Subtyping in
                 a Nominal World",
  volume =       "3086",
  x-abstract =   "Nominal subtyping forces programmers to explicitly
                 state all of the subtyping relationships in the
                 program. This limits component reuse, because
                 programmers cannot anticipate all of the contexts in
                 which a particular class might be used. In contrast,
                 structural subtyping implicitly allows any type with
                 appropriate structure to be used in a given context.
                 Languagues with contracts exacerbate the problem. Since
                 contracts are typically expressed as refinements of
                 types, contracts in nominally typed languages introduce
                 additional obstacles to reuse. To overcome this problem
                 we show how to extend a nominally typed language with
                 semantic casts that introduce a limited form of
                 structural subtyping. The new language must dynamically
                 monitor contracts, as new subtyping relationships are
                 exploited via semantic casts. In addition, it must also
                 track the casts to properly assign blame in case
                 interface contract are violated.",
  x-address =    "Berlin, Heidelberg",
  x-doi =        "10.1007/978-3-540-24851-4\_17",
  x-editor =     "Odersky,, Martin",
  x-isbn =       "978-3-540-22159-3",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-540-24851-4\_17",
  xpages =       "614--639",
  year =         "2004",
}

@TechReport{plt-tr2009-reference-v4.2.1,
  author =       "Matthew Flatt and T. Pl",
  citeulike-article-id = "5917463",
  citeulike-linkout-0 = "http://download.plt-scheme.org/doc/4.2.1/pdf/reference.pdf",
  date-added =   "2011-08-29 21:46:33",
  institution =  "PLT Scheme Inc.",
  month =        jul,
  number =       "PLT-TR2009-reference-v4.2.1",
  priority =     "2",
  title =        "Reference: {PLT} Scheme",
  type =         "Reference Manual",
  x-url =        "http://download.plt-scheme.org/doc/4.2.1/pdf/reference.pdf",
  year =         "2009",
}

@Book{meyer-eiffel,
  author =       "Bertrand Meyer",
  citeulike-article-id = "9524408",
  citeulike-linkout-0 = "http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0132479257",
  citeulike-linkout-1 = "http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0132479257",
  citeulike-linkout-2 = "http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0132479257",
  citeulike-linkout-3 = "http://www.amazon.jp/exec/obidos/ASIN/0132479257",
  citeulike-linkout-4 = "http://www.amazon.co.uk/exec/obidos/ASIN/0132479257/citeulike00-21",
  citeulike-linkout-5 = "http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0132479257",
  citeulike-linkout-6 = "http://www.worldcat.org/isbn/0132479257",
  citeulike-linkout-7 = "http://books.google.com/books?vid=ISBN0132479257",
  citeulike-linkout-8 = "http://www.amazon.com/gp/search?keywords=0132479257\&index=books\&linkCode=qs",
  citeulike-linkout-9 = "http://www.librarything.com/isbn/0132479257",
  date-added =   "2011-08-29 21:38:20",
  day =          "01",
  howpublished = "Paperback",
  month =        oct,
  priority =     "2",
  publisher =    "Prentice Hall",
  title =        "Eiffel : The Language",
  x-isbn =       "0132479257",
  x-url =        "http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0132479257",
  year =         "1991",
}

@Article{VanHorn2011Abstracting,
  author =       "David Van{ }Horn and Matthew Might",
  citeulike-article-id = "9723179",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1995400",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1995376.1995400",
  date-added =   "2011-08-28 21:53:26",
  journal =      "Communications of the ACM",
  month =        sep,
  priority =     "2",
  publisher =    "ACM",
  title =        "Abstracting abstract machines: a systematic approach
                 to higher-order program analysis",
  volume =       "54",
  x-abstract =   "Predictive models are fundamental to engineering
                 reliable software systems. However, designing
                 conservative, computable approximations for the
                 behavior of programs (static analyses) remains a
                 difficult and error-prone process for modern high-level
                 programming languages. What analysis designers need is
                 a principled method for navigating the gap between
                 semantics and analytic models: analysis designers need
                 a method that tames the interaction of complex
                 languages features such as higher-order functions,
                 recursion, exceptions, continuations, objects and
                 dynamic allocation. We contribute a systematic approach
                 to program analysis that yields novel and transparently
                 sound static analyses. Our approach relies on existing
                 derivational techniques to transform high-level
                 language semantics into low-level deterministic
                 state-transition systems (with potentially infinite
                 state spaces). We then perform a series of simple
                 machine refactorings to obtain a sound, computable
                 approximation, which takes the form of a
                 non-deterministic state-transition systems with finite
                 state spaces. The approach scales up uniformly to
                 enable program analysis of realistic language features,
                 including higher-order functions, tail calls,
                 conditionals, side effects, exceptions, first-class
                 continuations, and even garbage collection.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1995376.1995400",
  x-issn =       "0001-0782",
  x-url =        "http://dx.doi.org/10.1145/1995376.1995400",
  xpages =       "101--109",
  year =         "2011",
}

@InProceedings{TobinHochstadt2011Semantic,
  archiveprefix = "arXiv",
  author =       "Sam Tobin-Hochstadt and David Van Horn",
  booktitle =    "FIT Session, The ACM SIGPLAN 2011 Conference on
                 Programming Language Design and Implementation
                 (PLDI'11)",
  citeulike-article-id = "9723173",
  citeulike-linkout-0 = "http://arxiv.org/abs/1105.0106",
  citeulike-linkout-1 = "http://arxiv.org/pdf/1105.0106",
  date-added =   "2011-08-28 21:40:55",
  day =          "30",
  eprint =       "1105.0106",
  location =     "San Jose, California",
  month =        jun,
  priority =     "2",
  title =        "Semantic Solutions to Program Analysis Problems",
  x-abstract =   "Problems in program analysis can be solved by
                 developing novel program semantics and deriving
                 abstractions conventionally. For over thirty years,
                 higher-order program analysis has been sold as a hard
                 problem. Its solutions have required ingenuity and
                 complex models of approximation. We claim that this
                 difficulty is due to premature focus on abstraction and
                 propose a new approach that emphasizes semantics. Its
                 simplicity enables new analyses that are beyond the
                 current state of the art.",
  x-url =        "http://arxiv.org/abs/1105.0106",
  year =         "2011",
}

@InProceedings{Findler2001Contract,
  author =       "Robert B. Findler and Matthias Felleisen",
  booktitle =    "Proceedings of the 16th ACM SIGPLAN Conference on
                 Object-oriented Programming, Systems, Languages, and
                 Applications",
  citeulike-article-id = "4868",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=504283",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/504282.504283",
  date-added =   "2011-08-27 17:20:11",
  location =     "Tampa Bay, FL, USA",
  month =        nov,
  number =       "11",
  priority =     "2",
  publisher =    "ACM",
  title =        "Contract Soundness for object-oriented languages",
  volume =       "36",
  x-abstract =   "Checking pre- and post-conditions of procedures and
                 methods at runtime helps improve software reliability.
                 In the procedural world, pre- and post-conditions have
                 a straightforward interpretation. If a procedure's
                 pre-condition doesn't hold, the caller failed to
                 establish the proper context. If a post-condition
                 doesn't hold, the caller failed to establish the proper
                 context. If a post-condition doesn't hold, the
                 procedure failed to compute the expected result. In the
                 object-oriented world, checking pre- and
                 post-conditions for methods, often called contracts in
                 this context, poses complex problems. Because methods
                 may be overridden, it is not sufficient to check only
                 pre- and post-conditions. In addition, the contract
                 hierarchy must be checked to ensure that the contracts
                 on overridden methods are properly related to the
                 contracts on overriding methods. Otherwise, a class
                 hierarchy may violate the substitution principle, that
                 is, it may no longer be true that an instance of a
                 class is substitutable for objects of the super-class.
                 In this paper, we study the problem of contract
                 enforcement in an object-oriented world from a
                 foundational perspective. More specifically, we study
                 contracts as refinements of types. Pushing the analogy
                 further, we state and prove a contract soundness
                 theorem that captures the essential properties of
                 contract enforcement. We use the theorem to illustrate
                 how most existing tools suffer from a fundamental flaw
                 and how they can be improved.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/504282.504283",
  x-isbn =       "1-58113-335-9",
  x-series =     "OOPSLA '01",
  x-url =        "http://dx.doi.org/10.1145/504282.504283",
  xpages =       "1--15",
  year =         "2001",
}

@InProceedings{Findler2001Behavioral,
  author =       "Robert B. Findler and Mario Latendresse and Matthias
                 Felleisen",
  booktitle =    "Proceedings of the 8th European Software Engineering
                 Conference held jointly with 9th ACM SIGSOFT
                 International Symposium on Foundations of Software
                 Engineering",
  citeulike-article-id = "4865",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=503240",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/503209.503240",
  date-added =   "2011-08-27 17:18:41",
  location =     "Vienna, Austria",
  month =        sep,
  number =       "5",
  priority =     "2",
  publisher =    "ACM",
  title =        "Behavioral contracts and behavioral subtyping",
  volume =       "26",
  x-abstract =   "Component-based software manufacturing has the
                 potential to bring division-of-labor benefits to the
                 world of software engineering. In order to make a
                 market of software components viable, however,
                 producers and consumers must agree on enforceable
                 software contracts. In this paper, we show how to
                 enforce contracts if components are manufactured from
                 class and interface hierarchies. In particular, we
                 focus on one style of contract: pre- and
                 post-conditions. Programmers annotate class and
                 interface methods with pre- and post-conditions and the
                 run-time system checks these conditions during
                 evaluation. These contracts guarantee that methods are
                 called properly and provide appropriate results. In
                 procedural languages, the use of pre- and
                 post-condition contracts is well-established and
                 studies have demonstrated its value. In object-oriented
                 languages, however, assigning blame for pre- and
                 post-condition failures poses subtle and complex
                 problems. Specifically, assigning blame for malformed
                 class and interface hierarchies is so difficult that
                 none of the existing contract monitoring tools
                 correctly assign blame for these failures. In this
                 paper, we show how to overcome these problems in the
                 context of Java. Our work is based on the notion of
                 behavioral subtyping.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/503209.503240",
  x-isbn =       "1-58113-390-1",
  x-series =     "ESEC/FSE-9",
  x-url =        "http://dx.doi.org/10.1145/503209.503240",
  xpages =       "229--236",
  year =         "2001",
}

@InProceedings{Kobayashi2011Predicate,
  author =       "Naoki Kobayashi and Ryosuke Sato and Hiroshi Unno",
  booktitle =    "Proceedings of the 32nd ACM SIGPLAN Conference on
                 Programming Language Design and Implementation",
  citeulike-article-id = "9524695",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1993525",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1993316.1993525",
  date-added =   "2011-07-12 22:26:41",
  month =        jun,
  priority =     "2",
  publisher =    "ACM",
  title =        "Predicate abstraction and {CEGAR} for higher-order
                 model checking",
  x-abstract =   "Higher-order model checking (more precisely, the model
                 checking of higher-order recursion schemes) has been
                 extensively studied recently, which can automatically
                 decide properties of programs written in the
                 simply-typed λ-calculus with recursion and finite data
                 domains. This paper formalizes predicate abstraction
                 and counterexample-guided abstraction refinement
                 ({CEGAR}) for higher-order model checking, enabling
                 automatic verification of programs that use infinite
                 data domains such as integers. A prototype verifier for
                 higher-order functional programs based on the
                 formalization has been implemented and tested for
                 several programs.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1993316.1993525",
  x-issn =       "0362-1340",
  x-series =     "PLDI",
  x-url =        "http://dx.doi.org/10.1145/1993316.1993525",
  xpages =       "222--233",
  year =         "2011",
}

@InProceedings{Fahndrich2011Static,
  author =       "Manuel F{\"{a}}hndrich and Francesco Logozzo",
  booktitle =    "Proceedings of the 2010 International Conference on
                 Formal Verification of Object-Oriented Software",
  citeulike-article-id = "9539828",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1949305",
  date-added =   "2011-07-12 21:23:10",
  location =     "Paris, France",
  priority =     "2",
  publisher =    "Springer",
  title =        "Static contract checking with abstract
                 interpretation",
  x-abstract =   "We present an overview of Clousot, our current tool to
                 statically check {CodeContracts}. {CodeContracts}
                 enable a compiler and language-independent
                 specification of Contracts (precondition,
                 postconditions and object invariants). Clousot checks
                 every method in isolation using an assume/guarantee
                 reasoning: For each method under analysis Clousot
                 assumes its precondition and asserts the postcondition.
                 For each invoked method, Clousot asserts its
                 precondition and assumes the postcondition. Clousot
                 also checks the absence of common runtime errors, such
                 as null-pointer errors, buffer or array overruns,
                 divisions by zero, as well as less common ones such as
                 checked integer overflows or floating point precision
                 mismatches in comparisons. At the core of Clousot there
                 is an abstract interpretation engine which infers
                 program facts. Facts are used to discharge the
                 assertions. The use of abstract interpretation (vs
                 usual weakest precondition-based checkers) has two main
                 advantages: (i) the checker automatically infers loop
                 invariants letting the user focus only on boundary
                 specifications; (ii) the checker is deterministic in
                 its behavior (which abstractly mimics the flowof the
                 program) and it can be tuned for precision and cost.
                 Clousot embodies other techniques, such as iterative
                 domain refinement, goal-directed backward propagation,
                 precondition and postcondition inference, and message
                 prioritization.",
  x-address =    "Berlin, Heidelberg",
  x-isbn =       "3-642-18069-8, 978-3-642-18069-9",
  x-series =     "FoVeOOS",
  x-url =        "http://portal.acm.org/citation.cfm?id=1949305",
  xpages =       "10--30",
  year =         "2011",
}

@InProceedings{Hinze2006Typed,
  author =       "Ralf Hinze and Johan Jeuring and Andres L{\"{o}}h",
  booktitle =    "Proceedings of the 8th international conference on
                 Functional and Logic Programming",
  chapter =      "15",
  citeulike-article-id = "661450",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2100093",
  citeulike-linkout-1 = "http://dx.doi.org/10.1007/11737414\_15",
  citeulike-linkout-2 = "http://www.springerlink.com/content/w01115742074578r",
  comment =      "FLOPS'10",
  date-added =   "2011-07-12 21:05:09",
  journal =      "Lecture Notes in Computer Science",
  location =     "Fuji-Susono, Japan",
  month =        jan,
  priority =     "2",
  publisher =    "Springer",
  title =        "Typed contracts for functional programming",
  volume =       "3945",
  x-abstract =   "A robust software component fulfills a contract: it
                 expects data satisfying a certain property and promises
                 to return data satisfying another property. The
                 object-oriented community uses the design-by-contract
                 approach extensively. Proposals for language extensions
                 that add contracts to higher-order functional
                 programming have appeared recently. In this paper we
                 propose an embedded domain-specific language for typed,
                 higher-order and first-class contracts, which is both
                 more expressive than previous proposals, and allows for
                 a more informative blame assignment. We take some first
                 steps towards an algebra of contracts, and we show how
                 to define a generic contract combinator for arbitrary
                 algebraic data types. The contract language is
                 implemented as a library in Haskell using the concept
                 of generalised algebraic data types.",
  x-address =    "Berlin, Heidelberg",
  x-doi =        "10.1007/11737414\_15",
  x-editor =     "Hagiya, Masami and Wadler, Philip",
  x-isbn =       "3-540-33438-6, 978-3-540-33438-5",
  x-series =     "LNCS",
  x-url =        "http://dx.doi.org/10.1007/11737414\_15",
  xpages =       "208--225",
  year =         "2006",
}

@Article{Vardoulakis2011CFA2,
  author =       "Dimitrios Vardoulakis and Olin Shivers",
  citeulike-article-id = "9468449",
  citeulike-linkout-0 = "http://www.lmcs-online.org/ojs/viewarticle.php?id=705",
  date-added =   "2011-06-28 04:38:52",
  day =          "1",
  journal =      "Logical Methods in Computer Science",
  month =        may,
  number =       "2",
  priority =     "2",
  title =        "{CFA2}: a {Context-Free} Approach to {Control-Flow}
                 Analysis",
  volume =       "7",
  x-url =        "http://www.lmcs-online.org/ojs/viewarticle.php?id=705",
  year =         "2011",
}

@InProceedings{Morrisett1995Abstract,
  author =       "Greg Morrisett and Matthias Felleisen and Robert
                 Harper",
  booktitle =    "Proceedings of the Seventh International Conference on
                 Functional Programming Languages and Computer
                 Architecture",
  citeulike-article-id = "103133",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=224182",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/224164.224182",
  date-added =   "2011-06-14 00:49:26",
  location =     "La Jolla, California, USA",
  priority =     "0",
  publisher =    "ACM",
  title =        "Abstract Models of Memory Management",
  x-abstract =   "An abstract is not available.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/224164.224182",
  x-isbn =       "0-89791-719-7",
  x-series =     "FPCA '95",
  x-url =        "http://dx.doi.org/10.1145/224164.224182",
  xpages =       "66--77",
  year =         "1995",
}

@Article{TobinHochstadt2012HigherorderArXiv,
  archiveprefix = "arXiv",
  author =       "Sam Tobin-Hochstadt and David Van Horn",
  citeulike-article-id = "9268598",
  citeulike-linkout-0 = "http://arxiv.org/abs/1103.1362",
  citeulike-linkout-1 = "http://arxiv.org/pdf/1103.1362",
  date-added =   "2011-05-09 17:19:43",
  day =          "26",
  eprint =       "1103.1362",
  month =        apr,
  priority =     "2",
  title =        "{Higher-Order} Symbolic Execution via Contracts",
  x-abstract =   "We present a new approach to automated reasoning about
                 higher-order programs by extending symbolic execution
                 to use behavioral contracts as symbolic values,
                 enabling symbolic approximation of higher-order
                 behavior. Our approach is based on the idea of an
                 abstract reduction semantics that gives an operational
                 semantics to programs with both concrete and symbolic
                 components. Symbolic components are approximated by
                 their contract and our semantics gives an operational
                 interpretation of contracts-as-values. The result is a
                 executable semantics that soundly predicts program
                 behavior, including contract failures, for all possible
                 instantiations of symbolic components. We show that our
                 approach scales to an expressive language of contracts
                 including arbitrary programs embedded as predicates,
                 dependent function contracts, and recursive contracts.
                 Supporting this feature-rich language of specifications
                 leads to powerful symbolic reasoning using existing
                 program assertions. We then apply our approach to
                 produce a verifier for contract correctness of
                 components, including a sound and computable
                 approximation to our semantics that facilitates fully
                 automated contract verification. Our implementation is
                 capable of verifying contracts expressed in existing
                 programs, and of justifying valuable
                 contract-elimination optimizations.",
  x-url =        "http://arxiv.org/abs/1103.1362",
  year =         "2012",
}

@Article{Spoonhower2010Space,
  author =       "Daniel Spoonhower and Guy E. Blelloch and Robert
                 Harper and Phillip B. Gibbons",
  citeulike-article-id = "9217818",
  citeulike-linkout-0 = "http://journals.cambridge.org/action/displayAbstract?fromPage=online\&aid=8209504",
  citeulike-linkout-1 = "http://dx.doi.org/10.1017/s0956796810000146",
  date-added =   "2011-04-27 22:05:30",
  journal =      "Journal of Functional Programming",
  number =       "Special Issue 5-6",
  priority =     "2",
  title =        "Space profiling for parallel functional programs",
  volume =       "20",
  x-abstract =   "We present a semantic space profiler for parallel
                 functional programs. Building on previous work in
                 sequential profiling, our tools help programmers to
                 relate runtime resource use back to program source
                 code. Unlike many profiling tools, our profiler is
                 based on a cost semantics. This provides a means to
                 reason about performance without requiring a detailed
                 understanding of the compiler or runtime system. It
                 also provides a specification for language
                 implementers. This is critical in that it enables us to
                 separate cleanly the performance of the application
                 from that of the language implementation. Some aspects
                 of the implementation can have significant effects on
                 performance. Our cost semantics enables programmers to
                 understand the impact of different scheduling policies
                 while hiding many of the details of their
                 implementations. We show applications where the choice
                 of scheduling policy has asymptotic effects on space
                 use. We explain these use patterns through a
                 demonstration of our tools. We also validate our
                 methodology by observing similar performance in our
                 implementation of a parallel extension of Standard
                 {ML}.",
  x-doi =        "10.1017/s0956796810000146",
  x-url =        "http://dx.doi.org/10.1017/s0956796810000146",
  xpages =       "417--461",
  year =         "2010",
}

@InProceedings{Kodumal2004Set,
  author =       "John Kodumal and Alex Aiken",
  booktitle =    "PLDI '04: Proceedings of the ACM SIGPLAN 2004
                 Conference on Programming Language Design and
                 Implementation",
  citeulike-article-id = "6938153",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=996841.996867",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/996841.996867",
  date-added =   "2011-04-14 16:50:47",
  location =     "Washington DC, USA",
  month =        jun,
  priority =     "2",
  publisher =    "ACM",
  title =        "The set {constraint/CFL} reachability connection in
                 practice",
  x-abstract =   "Many program analyses can be reduced to graph
                 reachability problems involving a limited form of
                 context-free language reachability called {Dyck-CFL}
                 reachability. We show a new reduction from {Dyck-CFL}
                 reachability to set constraints that can be used in
                 practice to solve these problems. Our reduction is much
                 simpler than the general reduction from context-free
                 language reachability to set constraints. We have
                 implemented our reduction on top of a set constraints
                 toolkit and tested its performance on a substantial
                 polymorphic flow analysis application.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/996841.996867",
  x-isbn =       "1-58113-807-5",
  x-issn =       "0362-1340",
  x-url =        "http://dx.doi.org/10.1145/996841.996867",
  xpages =       "207--218",
  year =         "2004",
}

@Article{Schmidt2007Statetransition,
  author =       "David A. Schmidt",
  citeulike-article-id = "9122654",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1325150",
  date-added =   "2011-04-08 19:31:12",
  journal =      "Higher Order Symbol. Comput.",
  month =        sep,
  priority =     "2",
  publisher =    "Kluwer Academic Publishers",
  title =        "State-transition machines, revisited",
  volume =       "20",
  x-abstract =   "History and context are given regarding the
                 development of the {WNF}-machine, the first example of
                 a Krivine machine.",
  x-address =    "Hingham, MA, USA",
  x-issn =       "1388-3690",
  x-url =        "http://portal.acm.org/citation.cfm?id=1325150",
  xpages =       "333--335",
  year =         "2007",
}

@Article{Wallach2000SAFKASI,
  author =       "Dan S. Wallach and Andrew W. Appel and Edward W.
                 Felten",
  citeulike-article-id = "1403630",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=363520",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/363516.363520",
  date-added =   "2011-04-07 02:13:09",
  journal =      "ACM Trans. Softw. Eng. Methodol.",
  month =        oct,
  number =       "4",
  priority =     "2",
  publisher =    "ACM",
  title =        "{SAFKASI}: a security mechanism for language-based
                 systems",
  volume =       "9",
  x-abstract =   "In order to run untrusted code in the same process as
                 trusted code, there must be a mechanism to allow
                 dangerous calls to determine if their caller is
                 authorized to exercise the privilege of using the
                 dangerous routine. Java systems have adopted a
                 technique called stack inspection to address this
                 concern. But its original definition, in terms of
                 searching stack frames, had an unclear relationship to
                 the actual achievement of security, overconstrained the
                 implementation of a Java system, limited many desirable
                 optimizations such as method inlining and tail
                 recursion, and generally interfered with
                 interprocedural optimization. We present a new
                 semantics for stack inspection based on a belief logic
                 and its implementation using the calculus of
                 security-passing style which addresses the concerns of
                 traditional stack inspection. With security-passing
                 style, we can efficiently represent the security
                 context for any method activation, and we can build a
                 new implementation strictly by rewriting the Java
                 bytecodes before they are loaded by the system. No
                 changes to the {JVM} or bytecode semantics are
                 necessary. With a combination of static analysis and
                 runtime optimizations, our prototype implementation
                 showes reasonable performance (although traditional
                 stack inspection is still faster), and is easier to
                 consider for languages beyond Java. We call our system
                 {SAFKASI} (the Security Architecture Formerly Known as
                 Stack Inspection).",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/363516.363520",
  x-issn =       "1049-331X",
  x-url =        "http://dx.doi.org/10.1145/363516.363520",
  xpages =       "341--378",
  year =         "2000",
}

@InProceedings{Clinger1998Proper,
  author =       "William D. Clinger",
  booktitle =    "Proceedings of the ACM SIGPLAN 1998 Conference on
                 Programming Language Design and Implementation",
  citeulike-article-id = "1350",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=277719",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/277650.277719",
  date-added =   "2011-04-07 02:00:26",
  month =        may,
  priority =     "2",
  publisher =    "ACM",
  title =        "Proper tail recursion and space efficiency",
  x-abstract =   "The {IEEE}/{ANSI} standard for Scheme requires
                 implementations to be properly tail recursive. This
                 ensures that portable code can rely upon the space
                 efficiency of continuation-passing style and other
                 idioms. On its face, proper tail recursion concerns the
                 efficiency of procedure calls that occur within a tail
                 context. When examined closely, proper tail recursion
                 also depends upon the fact that garbage collection can
                 be asymptotically more space-efficient than Algol-like
                 stack {allocation.Proper} tail recursion is not the
                 same as ad hoc tail call optimization in stack-based
                 languages. Proper tail recursion often precludes stack
                 allocation of variables, but yields a well-defined
                 asymptotic space complexity that can be relied upon by
                 portable {programs.This} paper offers a formal and
                 implementation-independent definition of proper tail
                 recursion for Scheme. It also shows how an entire
                 family of reference implementations can be used to
                 characterize related safe-for-space properties, and
                 proves the asymptotic inequalities that hold between
                 them.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/277650.277719",
  x-issn =       "0362-1340",
  x-url =        "http://dx.doi.org/10.1145/277650.277719",
  xpages =       "174--185",
  year =         "1998",
}

@InProceedings{Agesen1995Cartesian,
  author =       "Ole Agesen",
  booktitle =    "Proceedings of the 9th European Conference on
                 Object-Oriented Programming",
  citeulike-article-id = "276694",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=679533",
  date-added =   "2011-04-06 21:52:29",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "The Cartesian Product Algorithm: Simple and Precise
                 Type Inference Of Parametric Polymorphism",
  x-abstract =   "Concrete types and abstract types are different and
                 serve different purposes. Concrete types, the focus of
                 this paper, are essential to support compilation,
                 application delivery, and debugging in object-oriented
                 environments. Concrete types should not be obtained
                 from explicit type declarations because their presence
                 limits polymorphism unacceptably. This leaves us with
                 type inference. Unfortunately, while polymorphism
                 demands the use of type inference, it has also been the
                 hardest challenge for type {inference.We} review
                 previous type inference algorithms that analyze code
                 with parametric polymorphism and then present a new
                 one: the cartesian product algorithm. It improves
                 precision and efficiency over previous algorithms and
                 deals directly with inheritance, rather than relying on
                 a preprocessor to expand it away. Last, but not least,
                 it is conceptually {simple.The} cartesian product
                 algorithm has been used in the Self system since late
                 1993. We present measurements to document its
                 performance and compare it against several previous
                 algorithms.",
  x-address =    "London, UK, UK",
  x-isbn =       "3-540-60160-0",
  x-series =     "ECOOP '95",
  x-url =        "http://portal.acm.org/citation.cfm?id=679533",
  xpages =       "2--26",
  year =         "1995",
}

@Article{Curien1991Abstract,
  author =       "P. L. Curien",
  citeulike-article-id = "9103710",
  citeulike-linkout-0 = "http://dx.doi.org/10.1016/0304-3975(91)90230-y",
  date-added =   "2011-04-06 07:17:15",
  day =          "31",
  journal =      "Theoretical Computer Science",
  month =        may,
  number =       "2",
  priority =     "2",
  title =        "An abstract framework for environment machines",
  volume =       "82",
  x-doi =        "10.1016/0304-3975(91)90230-y",
  x-issn =       "03043975",
  x-url =        "http://dx.doi.org/10.1016/0304-3975(91)90230-y",
  xpages =       "389--402",
  year =         "1991",
}

@Misc{1999ECMAScript,
  citeulike-article-id = "9095178",
  date-added =   "2011-04-04 03:51:16",
  edition =      "3",
  priority =     "2",
  title =        "{ECMAScript} language specification, Stardard
                 {ECMA}-262",
  year =         "1999",
}

@InProceedings{Maffeis2008Operational,
  author =       "Sergio Maffeis and John C. Mitchell and Ankur Taly",
  booktitle =    "Proceedings of the 6th Asian Symposium on Programming
                 Languages and Systems",
  citeulike-article-id = "3775653",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1485368",
  citeulike-linkout-1 = "http://dx.doi.org/10.1007/978-3-540-89330-1\_22",
  citeulike-linkout-2 = "http://www.springerlink.com/content/q54rt98v8374h9k1",
  date-added =   "2011-04-04 03:21:42",
  journal =      "Programming Languages and Systems",
  location =     "Bangalore, India",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "An Operational Semantics for {JavaScript}",
  x-abstract =   "We define a small-step operational semantics for the
                 {ECMAScript} standard language corresponding to
                 {JavaScript}, as a basis for analyzing security
                 properties of web applications and mashups. The
                 semantics is based on the language standard and a
                 number of experiments with different implementations
                 and browsers. Some basic properties of the semantics
                 are proved, including a soundness theorem and a
                 characterization of the reachable portion of the
                 heap.",
  x-address =    "Berlin, Heidelberg",
  x-doi =        "10.1007/978-3-540-89330-1\_22",
  x-isbn =       "978-3-540-89329-5",
  x-series =     "APLAS '08",
  x-url =        "http://dx.doi.org/10.1007/978-3-540-89330-1\_22",
  xpages =       "307--325",
  year =         "2008",
}

@InCollection{Balakrishnan2006RecencyAbstraction,
  author =       "Gogul Balakrishnan and Thomas Reps",
  booktitle =    "Proceedings of the 13th international conference on
                 Static Analysis",
  chapter =      "15",
  citeulike-article-id = "5154774",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=2090894",
  citeulike-linkout-1 = "http://dx.doi.org/10.1007/11823230\_15",
  citeulike-linkout-2 = "http://www.springerlink.com/content/g857n7xn2751624q",
  date-added =   "2011-04-04 02:53:29",
  journal =      "Static Analysis",
  location =     "Seoul, Korea",
  priority =     "2",
  publisher =    "Springer Berlin / Heidelberg",
  title =        "{Recency-Abstraction} for {Heap-Allocated} Storage
                 Static Analysis",
  volume =       "4134",
  x-abstract =   "In this paper, we present an abstraction for
                 heap-allocated storage, called the recency-abstraction,
                 that allows abstract-interpretation algorithms to
                 recover some non-trivial information for heap-allocated
                 data objects. As an application of the
                 recency-abstraction, we show how it can resolve
                 virtual-function calls in stripped executables (i.e.,
                 executables from which debugging information has been
                 removed). This approach succeeded in resolving 55\% of
                 virtual-function call-sites, whereas previous tools for
                 analyzing executables fail to resolve any of the
                 virtual-function call-sites.",
  x-address =    "Berlin, Heidelberg",
  x-doi =        "10.1007/11823230\_15",
  x-editor =     "Yi, Kwangkeun",
  x-isbn =       "978-3-540-37756-6",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/11823230\_15",
  xpages =       "221--239",
  year =         "2006",
}

@Article{Biernacka2007Syntactic,
  author =       "Magorzata Biernacka and Olivier Danvy",
  citeulike-article-id = "9080306",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1236111",
  citeulike-linkout-1 = "http://dx.doi.org/10.1016/j.tcs.2006.12.028",
  date-added =   "2011-03-30 16:44:35",
  journal =      "Theor. Comput. Sci.",
  month =        apr,
  number =       "1-3",
  priority =     "2",
  publisher =    "Elsevier Science Publishers Ltd.",
  title =        "A syntactic correspondence between context-sensitive
                 calculi and abstract machines",
  volume =       "375",
  x-abstract =   "We present a systematic construction of
                 environment-based abstract machines from
                 context-sensitive calculi of explicit substitutions,
                 and we illustrate it with ten calculi and machines for
                 applicative order with an abort operation, normal order
                 with generalized reduction and call/cc, the
                 lambda-mu-calculus, delimited continuations, stack
                 inspection, proper tail-recursion, and lazy evaluation.
                 Most of the machines already exist but they have been
                 obtained independently and are only indirectly related
                 to the corresponding calculi. All of the calculi are
                 new and they make it possible directly to reason about
                 the execution of the corresponding machines.",
  x-address =    "Essex, UK",
  x-doi =        "10.1016/j.tcs.2006.12.028",
  x-issn =       "0304-3975",
  x-url =        "http://dx.doi.org/10.1016/j.tcs.2006.12.028",
  xpages =       "76--108",
  year =         "2007",
}

@Proceedings{AFP:08,
  booktitle =    "Advanced Functional Programming, Sixth International
                 School",
  citeulike-article-id = "9073949",
  date-added =   "2011-03-29 02:41:00",
  month =        may,
  number =       "5382",
  priority =     "2",
  publisher =    "Springer",
  title =        "Advanced Functional Programming, Sixth International
                 School",
  x-address =    "Nijmegen, The Netherlands",
  x-editor =     "Koopman, Pieter and Plasmeijer, Rinus and Swierstra,
                 Doaitse",
  year =         "2008",
}

@InProceedings{Danvy:AFP08,
  author =       "Olivier Danvy",
  booktitle =    "Advanced Functional Programming, Sixth International
                 School",
  citeulike-article-id = "9073948",
  comment =      "Lecture notes including 70+ exercises",
  date-added =   "2011-03-29 02:41:00",
  month =        may,
  number =       "5382",
  priority =     "2",
  publisher =    "Springer",
  title =        "From {Reduction-Based} to {Reduction-Free}
                 Normalization",
  x-address =    "Nijmegen, The Netherlands",
  x-editor =     "Koopman, Pieter and Plasmeijer, Rinus and Swierstra,
                 Doaitse",
  xpages =       "66--164",
  year =         "2008",
}

@InProceedings{Chugh2009Staged,
  author =       "Ravi Chugh and Jeffrey A. Meister and Ranjit Jhala and
                 Sorin Lerner",
  booktitle =    "Proceedings of the 2009 ACM SIGPLAN conference on
                 Programming language design and implementation",
  citeulike-article-id = "8322026",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1542483",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1543135.1542483",
  date-added =   "2011-03-29 02:18:38",
  journal =      "PLDI '09 Proceedings of the 2009 ACM SIGPLAN
                 Conference on Programming Language Design and
                 Implementation",
  location =     "Dublin, Ireland",
  month =        jun,
  priority =     "2",
  publisher =    "ACM",
  title =        "Staged information flow for {JavaScript}",
  x-abstract =   "Modern websites are powered by {JavaScript}, a
                 flexible dynamic scripting language that executes in
                 client browsers. A common paradigm in such websites is
                 to include third-party {JavaScript} code in the form of
                 libraries or advertisements. If this code were
                 malicious, it could read sensitive information from the
                 page or write to the location bar, thus redirecting the
                 user to a malicious page, from which the entire machine
                 could be compromised. We present an information-flow
                 based approach for inferring the effects that a piece
                 of {JavaScript} has on the website in order to ensure
                 that key security properties are not violated. To
                 handle dynamically loaded and generated {JavaScript},
                 we propose a framework for staging information flow
                 properties. Our framework propagates information flow
                 through the currently known code in order to compute a
                 minimal set of syntactic residual checks that are
                 performed on the remaining code when it is dynamically
                 loaded. We have implemented a prototype framework for
                 staging information flow. We describe our techniques
                 for handling some difficult features of {JavaScript}
                 and evaluate our system's performance on a variety of
                 large real-world websites. Our experiments show that
                 static information flow is feasible and efficient for
                 {JavaScript}, and that our technique allows the
                 enforcement of information-flow policies with almost no
                 run-time overhead.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1543135.1542483",
  x-isbn =       "978-1-60558-392-1",
  x-issn =       "0362-1340",
  x-series =     "PLDI '09",
  x-url =        "http://dx.doi.org/10.1145/1543135.1542483",
  xpages =       "50--62",
  year =         "2009",
}

@InProceedings{Richards2010Analysis,
  author =       "Gregor Richards and Sylvain Lebresne and Brian Burg
                 and Jan Vitek",
  booktitle =    "Proceedings of the 2010 ACM SIGPLAN Conference on
                 Programming Language Design and Implementation",
  citeulike-article-id = "7560428",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1806598",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1806596.1806598",
  date-added =   "2011-03-29 02:07:26",
  location =     "Toronto, Ontario, Canada",
  priority =     "2",
  publisher =    "ACM",
  title =        "An analysis of the dynamic behavior of {JavaScript}
                 programs",
  x-abstract =   "The {JavaScript} programming language is widely used
                 for web programming and, increasingly, for general
                 purpose computing. As such, improving the correctness,
                 security and performance of {JavaScript} applications
                 has been the driving force for research in type
                 systems, static analysis and compiler techniques for
                 this language. Many of these techniques aim to reign in
                 some of the most dynamic features of the language, yet
                 little seems to be known about how programmers actually
                 utilize the language or these features. In this paper
                 we perform an empirical study of the dynamic behavior
                 of a corpus of widely-used {JavaScript} programs, and
                 analyze how and why the dynamic features are used. We
                 report on the degree of dynamism that is exhibited by
                 these {JavaScript} programs and compare that with
                 assumptions commonly made in the literature and
                 accepted industry benchmark suites.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1806596.1806598",
  x-isbn =       "978-1-4503-0019-3",
  x-series =     "PLDI '10",
  x-url =        "http://dx.doi.org/10.1145/1806596.1806598",
  xpages =       "1--12",
  year =         "2010",
}

@InProceedings{Guha2009Using,
  author =       "Arjun Guha and Shriram Krishnamurthi and Trevor Jim",
  booktitle =    "Proceedings of the 18th international conference on
                 World wide web",
  citeulike-article-id = "5310250",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1526709.1526785",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1526709.1526785",
  date-added =   "2011-03-29 02:06:46",
  location =     "Madrid, Spain",
  priority =     "2",
  publisher =    "ACM",
  title =        "Using static analysis for Ajax intrusion detection",
  x-abstract =   "We present a static control-flow analysis for
                 {JavaScript} programs running in a web browser. Our
                 analysis tackles numerous challenges posed by modern
                 web applications including asynchronous communication,
                 frameworks, and dynamic code generation. We use our
                 analysis to extract a model of expected client behavior
                 as seen from the server, and build an
                 intrusion-prevention proxy for the server: the proxy
                 intercepts client requests and disables those that do
                 not meet the expected behavior. We insert random
                 asynchronous requests to foil mimicry attacks. Finally,
                 we evaluate our technique against several real
                 applications and show that it protects against an
                 attack in a widely-used web application.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1526709.1526785",
  x-isbn =       "978-1-60558-487-4",
  x-series =     "WWW '09",
  x-url =        "http://dx.doi.org/10.1145/1526709.1526785",
  xpages =       "561--570",
  year =         "2009",
}

@InCollection{Jensen2011Interprocedural,
  author =       "Simon Jensen and Anders M{\o}ller and Peter Thiemann",
  booktitle =    "Static Analysis",
  chapter =      "20",
  citeulike-article-id = "9073897",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-642-15769-1\_20",
  citeulike-linkout-1 = "http://www.springerlink.com/content/a72x80355r124764",
  date-added =   "2011-03-29 02:03:14",
  priority =     "2",
  publisher =    "Springer Berlin / Heidelberg",
  title =        "Interprocedural Analysis with Lazy Propagation",
  volume =       "6337",
  x-abstract =   "We propose lazy propagation as a technique for flow-
                 and context-sensitive interprocedural analysis of
                 programs with objects and first-class functions where
                 transfer functions may not be distributive. The
                 technique is described formally as a systematic
                 modification of a variant of the monotone framework and
                 its theoretical properties are shown. It is implemented
                 in a type analysis tool for {JavaScript} where it
                 results in a significant improvement in performance.",
  x-address =    "Berlin, Heidelberg",
  x-doi =        "10.1007/978-3-642-15769-1\_20",
  x-editor =     "Cousot, Radhia and Martel, Matthieu",
  x-isbn =       "978-3-642-15768-4",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-642-15769-1\_20",
  xpages =       "320--339",
  year =         "2011",
}

@InProceedings{Jensen2009Type,
  author =       "Simon H. Jensen and Anders M{\o}ller and Peter
                 Thiemann",
  booktitle =    "Proceedings of the 16th International Symposium on
                 Static Analysis",
  chapter =      "17",
  citeulike-article-id = "7228966",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1615441.1615460",
  citeulike-linkout-1 = "http://dx.doi.org/10.1007/978-3-642-03237-0\_17",
  citeulike-linkout-2 = "http://www.springerlink.com/content/yv60v168w42k2484",
  date-added =   "2011-03-29 01:56:46",
  location =     "Los Angeles, CA",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "Type Analysis for {JavaScript}",
  volume =       "5673",
  x-abstract =   "{JavaScript} is the main scripting language for Web
                 browsers, and it is essential to modern Web
                 applications. Programmers have started using it for
                 writing complex applications, but there is still little
                 tool support available during development. We present a
                 static program analysis infrastructure that can infer
                 detailed and sound type information for {JavaScript}
                 programs using abstract interpretation. The analysis is
                 designed to support the full language as defined in the
                 {ECMAScript} standard, including its peculiar object
                 model and all built-in functions. The analysis results
                 can be used to detect common programming errors --- or
                 rather, prove their absence, and for producing type
                 information for program comprehension. Preliminary
                 experiments conducted on real-life {JavaScript} code
                 indicate that the approach is promising regarding
                 analysis precision on small and medium size programs,
                 which constitute the majority of {JavaScript}
                 applications. With potential for further improvement,
                 we propose the analysis as a foundation for building
                 tools that can aid {JavaScript} programmers.",
  x-address =    "Berlin, Heidelberg",
  x-doi =        "10.1007/978-3-642-03237-0\_17",
  x-isbn =       "978-3-642-03236-3",
  x-series =     "SAS '09",
  x-url =        "http://dx.doi.org/10.1007/978-3-642-03237-0\_17",
  xpages =       "238--255",
  year =         "2009",
}

@InCollection{Thiemann2005Towards,
  author =       "Peter Thiemann",
  booktitle =    "Programming Languages and Systems",
  chapter =      "28",
  citeulike-article-id = "2973885",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-540-31987-0\_28",
  citeulike-linkout-1 = "http://www.springerlink.com/content/nudp8rmw194glhqc",
  citeulike-linkout-2 = "http://link.springer.com/chapter/10.1007/978-3-540-31987-0\_28",
  date-added =   "2011-03-29 01:54:53",
  journal =      "Programming Languages and Systems",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "Towards a Type System for Analyzing {JavaScript}
                 Programs",
  volume =       "3444",
  x-abstract =   "{JavaScript} is a popular language for client-side web
                 scripting. It has a dubious reputation among
                 programmers for two reasons. First, many {JavaScript}
                 programs are written against a rapidly evolving {API}
                 whose implementations are sometimes contradictory and
                 idiosyncratic. Second, the language is only weakly
                 typed and comes virtually without development tools.
                 The present work is a first attempt to address the
                 second point. It does so by defining a type system that
                 tracks the possible traits of an object and flags
                 suspicious type conversions. Because {JavaScript} is a
                 classless, object-based language with first-class
                 functions, the type system must include singleton
                 types, subtyping, and first class record labels. The
                 type system covers a representative subset of the
                 language and there is a type soundness proof with
                 respect to an operational semantics.",
  x-address =    "Berlin, Heidelberg",
  x-doi =        "10.1007/978-3-540-31987-0\_28",
  x-editor =     "Sagiv, Mooly",
  x-isbn =       "978-3-540-25435-5",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-540-31987-0\_28",
  xpages =       "408--422",
  year =         "2005",
}

@InCollection{Heidegger2010Recency,
  author =       "Phillip Heidegger and Peter Thiemann",
  booktitle =    "ECOOP 2010 – Object-Oriented Programming",
  chapter =      "10",
  citeulike-article-id = "9073874",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-642-14107-2\_10",
  citeulike-linkout-1 = "http://www.springerlink.com/content/13845531617t1083",
  date-added =   "2011-03-29 01:48:25",
  priority =     "2",
  publisher =    "Springer Berlin / Heidelberg",
  title =        "Recency Types for Analyzing Scripting Languages",
  volume =       "6183",
  x-abstract =   "With the current surge of scripting technologies,
                 large programs are being built with dynamically typed
                 languages. As these programs grow in size,
                 semantics-based tools gain importance for detecting
                 programming errors as well as for program
                 understanding. As a basis for such tools, we propose a
                 descriptive type system for an imperative call-by-value
                 lambda calculus with objects. The calculus models
                 essential features of {JavaScript}, a widely used
                 dynamically-typed language: first-class functions,
                 objects as property maps, and prototypes. Our type
                 system infers precise singleton object types for
                 recently allocated objects. These object types are
                 handled flow-sensitively and change during the objects'
                 initialization phase. The notion of recency provides an
                 automatic criterion to subsume these precise object
                 types to summary object types, which are handled
                 flow-insensitively. The criterion applies on a
                 per-object basis. Thus, the type system identifies a
                 generalized initialization phase for each object during
                 which the change of its value is precisely reflected in
                 the change of its type. Unlike with linear types,
                 summary types may refer to singleton types and vice
                 versa. We prove the soundness of the type system and
                 present a constraint-based inference algorithm. An
                 implementation is available on the web.",
  x-address =    "Berlin, Heidelberg",
  x-doi =        "10.1007/978-3-642-14107-2\_10",
  x-editor =     "D'Hondt, Theo",
  x-isbn =       "978-3-642-14106-5",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-642-14107-2\_10",
  xpages =       "200--224",
  year =         "2010",
}

@Article{Queinnec2004Continuations,
  author =       "Christian Queinnec",
  citeulike-article-id = "116706",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/s10990-004-4866-z",
  citeulike-linkout-1 = "http://www.ingentaconnect.com/content/klu/lisp/2004/00000017/00000004/00004866",
  date-added =   "2011-03-26 20:17:57",
  journal =      "Higher-Order and Symbolic Computation",
  month =        dec,
  number =       "4",
  priority =     "2",
  publisher =    "Kluwer Academic Publishers",
  title =        "Continuations and Web Servers",
  volume =       "17",
  x-doi =        "10.1007/s10990-004-4866-z",
  x-issn =       "1388-3690",
  x-url =        "http://dx.doi.org/10.1007/s10990-004-4866-z",
  xpages =       "277--295",
  year =         "2004",
}

@TechReport{Danvy-Nielsen:RS-04-26,
  author =       "Olivier Danvy and Lasse R. Nielsen",
  citeulike-article-id = "9028092",
  comment =      "A preliminary version appeared in the informal
                 proceedings of the Second International Workshop on
                 Rule-Based Programming (RULE 2001), Electronic Notes in
                 Theoretical Computer Science, Vol.\~{}59.4",
  date-added =   "2011-03-19 17:01:00",
  institution =  "Department of Computer Science, Aarhus University",
  month =        nov,
  number =       "BRICS RS-04-26",
  priority =     "2",
  title =        "Refocusing in Reduction Semantics",
  type =         "Research Report",
  x-address =    "Aarhus, Denmark",
  year =         "2004",
}

@Book{Neilson:1999,
  author =       "Flemming Nielson and Hanne R. Nielson and Chris
                 Hankin",
  citeulike-article-id = "9026861",
  date-added =   "2011-03-19 07:14:25",
  keywords =     "cfa",
  priority =     "0",
  publisher =    "Springer-Verlag",
  title =        "Principles of Program Analysis",
  x-address =    "Secaucus, NJ, USA",
  x-isbn =       "3540654100",
  year =         "1999",
}

@Book{Sperber2010Revised,
  author =       "Michael Sperber and R. Kent Dybvig and Matthew Flatt
                 and Anton van Straaten and Robby Findler and Jacob
                 Matthews",
  citeulike-article-id = "9026826",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1830448",
  date-added =   "2011-03-19 05:55:09",
  priority =     "2",
  publisher =    "Cambridge University Press",
  title =        "Revised [6] Report on the Algorithmic Language
                 Scheme",
  x-abstract =   "Programming languages should be designed not by piling
                 feature on top of feature, but by removing the
                 weaknesses and restrictions that make additional
                 features appear necessary. Scheme demonstrates that a
                 very small number of rules for forming expressions,
                 with no restrictions on how they are composed, are
                 enough to form a practical and efficient programming
                 language that is flexible enough to support most of the
                 major programming paradigms in use today. This book
                 contains the three parts comprising '{R6RS}', the sixth
                 revision of a series of reports describing the
                 programming language Scheme. The book is divided into
                 parts: a description of the language itself, a
                 description of the standard libraries and non-normative
                 appendices. Early chapters introduce Scheme and later
                 chapters act as a reference manual. This is an
                 important report for programmers that work with or want
                 to learn about the Scheme language.",
  x-address =    "New York, NY, USA",
  x-isbn =       "0521193990, 9780521193993",
  x-url =        "http://portal.acm.org/citation.cfm?id=1830448",
  year =         "2010",
}

@Article{TobinHochstadt2011Modular,
  archiveprefix = "arXiv",
  author =       "Sam Tobin-Hochstadt and David Van{ }Horn",
  citeulike-article-id = "8997639",
  citeulike-linkout-0 = "http://arxiv.org/abs/1103.1362v1",
  citeulike-linkout-1 = "http://arxiv.org/pdf/1103.1362v1",
  date-added =   "2011-03-15 20:38:25",
  day =          "7",
  eprint =       "1103.1362v1",
  month =        mar,
  priority =     "2",
  title =        "Modular Analysis via Abstract Reduction Semantics",
  x-abstract =   "Modular static analysis requires treating some portion
                 of the program opaquely. To enable such analysis, we
                 introduce a notion of abstract reduction semantics.
                 Opaque components are approximated by their
                 specifications, which in turn are treated as abstract
                 values during reduction. We demonstrate the technique
                 by applying it to two kinds of specifications for
                 higher-order languages: types and first-class
                 contracts, showing that each soundly approximates
                 opaque components. Finally, we derive modular static
                 analyzers from these semantics, soundly predicting
                 evaluation, contract violations, and blame
                 assignment.",
  x-url =        "http://arxiv.org/abs/1103.1362v1",
  year =         "2011",
}

@InProceedings{Guha2010Javascript,
  author =       "Arjun Guha and Claudiu Saftoiu and Shriram
                 Krishnamurthi",
  booktitle =    "Proceedings of the 24th European conference on
                 Object-oriented programming",
  citeulike-article-id = "8499950",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1883988",
  date-added =   "2011-02-27 22:07:23",
  location =     "Maribor, Slovenia",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "The essence of {J}ava{S}cript",
  x-abstract =   "We reduce {JavaScript} to a core calculus structured
                 as a small-step operational semantics. We present
                 several peculiarities of the language and show that our
                 calculus models them. We explicate the desugaring
                 process that turns {JavaScript} programs into ones in
                 the core. We demonstrate faithfulness to {JavaScript}
                 using real-world test suites. Finally, we illustrate
                 utility by defining a security property, implementing
                 it as a type system on the core, and extending it to
                 the full language.",
  x-address =    "Berlin, Heidelberg",
  x-isbn =       "3-642-14106-4, 978-3-642-14106-5",
  x-series =     "ECOOP'10",
  x-url =        "http://portal.acm.org/citation.cfm?id=1883988",
  xpages =       "126--150",
  year =         "2010",
}

@Article{BarnettEA10,
  author =       "M. Barnett and M. F{\"{a}}hndrich and K. R. M. Leino
                 and P. M{\"{u}}ller and W. Schulte and H. Venter",
  citeulike-article-id = "7965335",
  comment =      "To appear",
  date-added =   "2010-10-09 01:52:55",
  journal =      "Comm. of the ACM",
  priority =     "2",
  publisher =    "ACM",
  title =        "Specification and Verification: The {S}pec\#
                 Experience",
  year =         "2010",
}

@Article{Barnett2004Verification,
  author =       "Mike Barnett and Robert DeLine and Manuel
                 F{\"{a}}hndrich and Leino and Wolfram Schulte",
  citeulike-article-id = "7965276",
  date-added =   "2010-10-09 01:43:11",
  journal =      "Journal of Object Technology",
  month =        jun,
  number =       "6",
  priority =     "2",
  title =        "Verification of object-oriented programs with
                 invariants",
  volume =       "3",
  xpages =       "27--56",
  year =         "2004",
}

@InBook{Barnett2005Spec,
  author =       "Mike Barnett and Leino and Wolfram Schulte",
  booktitle =    "Construction and Analysis of Safe, Secure, and
                 Interoperable Smart Devices",
  chapter =      "3",
  citeulike-article-id = "1550097",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-540-30569-9\_3",
  citeulike-linkout-1 = "http://www.springerlink.com/content/0m789xre652nuv06",
  date-added =   "2010-10-09 01:36:02",
  journal =      "Construction and Analysis of Safe, Secure, and
                 Interoperable Smart Devices",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "The Spec\# Programming System: An Overview",
  volume =       "3362",
  x-abstract =   "The Spec\# programming system is a new attempt at a
                 more cost effective way to develop and maintain
                 high-quality software. This paper describes the goals
                 and architecture of the Spec\# programming system,
                 consisting of the object-oriented Spec\# programming
                 language, the Spec\# compiler, and the Boogie static
                 program verifier. The language includes constructs for
                 writing specifications that capture programmer
                 intentions about how methods and data are to be used,
                 the compiler emits run-time checks to enforce these
                 specifications, and the verifier can check the
                 consistency between a program and its specifications.",
  x-address =    "Berlin, Heidelberg",
  x-doi =        "10.1007/978-3-540-30569-9\_3",
  x-editor =     "Barthe, Gilles and Burdy, Lilian and Huisman, Marieke
                 and Lanet, Jean-Louis and Muntean, Traian",
  x-isbn =       "978-3-540-24287-1",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-540-30569-9\_3",
  xpages =       "49--69",
  year =         "2005",
}

@InProceedings{Fahndrich2010Embedded,
  author =       "Manuel F{\"{a}}hndrich and Michael Barnett and
                 Francesco Logozzo",
  booktitle =    "Proceedings of the 2010 ACM Symposium on Applied
                 Computing",
  citeulike-article-id = "7965240",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1774531",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1774088.1774531",
  comment =      "SAC'10",
  date-added =   "2010-10-09 01:25:44",
  location =     "Sierre, Switzerland",
  priority =     "2",
  publisher =    "ACM",
  title =        "Embedded contract languages",
  x-abstract =   "Specifying application interfaces ({APIs}) with
                 information that goes beyond method argument and return
                 types is a long-standing quest of programming language
                 researchers and practitioners. The number of type
                 system extensions or specification languages is a
                 testament to that. Unfortunately, the number of such
                 systems is also roughly equal to the number of tools
                 that consume them. In other words, every tool comes
                 with its own specification language. In this paper we
                 argue that for modern object-oriented languages, using
                 an embedding of contracts as code is a better approach.
                 We exemplify our embedding of Code Contracts on the
                 Microsoft managed execution platform (.{NET}) using the
                 C\# programming language. The embedding works as well
                 in Visual Basic. We discuss the numerous advantages of
                 our approach and the technical challenges, as well as
                 the status of tools that consume the embedded
                 contracts.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1774088.1774531",
  x-isbn =       "978-1-60558-639-7",
  x-series =     "",
  x-url =        "http://dx.doi.org/10.1145/1774088.1774531",
  xpages =       "2103--2110",
  year =         "2010",
}

@InProceedings{VanHorn2010Abstracting,
  author =       "David Van{ }Horn and Matthew Might",
  booktitle =    "Proceedings of the 15th ACM SIGPLAN International
                 Conference on Functional Programming",
  citeulike-article-id = "7956643",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1863543.1863553",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1863543.1863553",
  date-added =   "2010-10-07 22:11:30",
  location =     "Baltimore, Maryland, USA",
  month =        sep,
  priority =     "2",
  publisher =    "ACM",
  title =        "Abstracting Abstract Machines",
  x-abstract =   "We describe a derivational approach to abstract
                 interpretation that yields novel and transparently
                 sound static analyses when applied to well-established
                 abstract machines. To demonstrate the technique and
                 support our claim, we transform the {CEK} machine of
                 Felleisen and Friedman, a lazy variant of Krivine's
                 machine, and the stack-inspecting {CM} machine of
                 Clements and Felleisen into abstract interpretations of
                 themselves. The resulting analyses bound temporal
                 ordering of program events; predict return-flow and
                 stack-inspection behavior; and approximate the flow and
                 evaluation of by-need parameters. For all of these
                 machines, we find that a series of well-known concrete
                 machine refactorings, plus a technique we call
                 store-allocated continuations, leads to machines that
                 abstract into static analyses simply by bounding their
                 stores. We demonstrate that the technique scales up
                 uniformly to allow static analysis of realistic
                 language features, including tail calls, conditionals,
                 side effects, exceptions, first-class continuations,
                 and even garbage collection.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1863543.1863553",
  x-isbn =       "978-1-60558-794-3",
  x-issn =       "0362-1340",
  x-series =     "ICFP",
  x-url =        "http://dx.doi.org/10.1145/1863543.1863553",
  xpages =       "51--62",
  year =         "2010",
}

@InProceedings{Xu2009Static,
  author =       "Dana N. Xu and Simon {Peyton Jones} and Simon
                 Claessen",
  booktitle =    "POPL '09: Proceedings of the 36th Annual ACM
                 SIGPLAN-SIGACT Symposium on Principles of Programming
                 Languages",
  citeulike-article-id = "6647620",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1480881.1480889",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1480881.1480889",
  date-added =   "2010-10-06 23:27:55",
  location =     "Savannah, GA, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "Static contract checking for {H}askell",
  x-abstract =   "Program errors are hard to detect and are costly both
                 to programmers who spend significant efforts in
                 debugging, and for systems that are guarded by runtime
                 checks. Static verification techniques have been
                 applied to imperative and object-oriented languages,
                 like Java and C\#, but few have been applied to a
                 higher-order lazy functional language, like Haskell. In
                 this paper, we describe a sound and automatic static
                 verification framework for Haskell, that is based on
                 contracts and symbolic execution. Our approach is
                 modular and gives precise blame assignments at
                 compile-time in the presence of higher-order functions
                 and laziness.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1480881.1480889",
  x-isbn =       "978-1-60558-379-2",
  x-series =     "POPL",
  x-url =        "http://dx.doi.org/10.1145/1480881.1480889",
  xpages =       "41--52",
  year =         "2009",
}

@InCollection{Tov2010Stateful,
  author =       "Jesse Tov and Riccardo Pucella",
  booktitle =    "Programming Languages and Systems",
  chapter =      "",
  citeulike-article-id = "7952300",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-642-11957-6\_29",
  citeulike-linkout-1 = "http://www.springerlink.com/content/bx1885218203p580",
  date-added =   "2010-10-06 13:02:59",
  priority =     "2",
  publisher =    "Springer",
  title =        "Stateful Contracts for Affine Types",
  volume =       "6012",
  x-abstract =   "Affine type systems manage resources by preventing
                 some values from being used more than once. This offers
                 expressiveness and performance benefits, but difficulty
                 arises in interacting with components written in a
                 conventional language whose type system provides no way
                 to maintain the affine type system\^{a}s aliasing
                 invariants. We propose and implement a technique that
                 uses behavioral contracts to mediate between code
                 written in an affine language and code in a
                 conventional typed language. We formalize our approach
                 via a typed calculus with both affine-typed and
                 conventionally-typed modules. We show how to preserve
                 the guarantees of both type systems despite both
                 languages being able to call into each other and
                 exchange higher-order values.",
  x-address =    "Berlin, Heidelberg",
  x-doi =        "10.1007/978-3-642-11957-6\_29",
  x-editor =     "Gordon, Andrew",
  x-isbn =       "978-3-642-11956-9",
  x-series =     "LNCS",
  x-url =        "http://dx.doi.org/10.1007/978-3-642-11957-6\_29",
  xpages =       "550--569",
  year =         "2010",
}

@InCollection{Birkedal2008Simple,
  author =       "Lars Birkedal and Bernhard Reus and Jan Schwinghammer
                 and Hongseok Yang",
  booktitle =    "Automata, Languages and Programming",
  citeulike-article-id = "7943640",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1427987.1428024",
  citeulike-linkout-1 = "http://dx.doi.org/10.1007/978-3-540-70583-3\_29",
  citeulike-linkout-2 = "http://link.springer.com/chapter/10.1007/978-3-540-70583-3\_29",
  date-added =   "2010-10-04 01:30:39",
  location =     "Reykjavik, Iceland",
  priority =     "2",
  publisher =    "Springer Berlin Heidelberg",
  title =        "A Simple Model of Separation Logic for {Higher-Order}
                 Store",
  volume =       "5126",
  x-abstract =   "Separation logic is a Hoare-style logic for reasoning
                 about pointer-manipulating programs. Its core ideas
                 have recently been extended from low-level to richer,
                 high-level languages. In this paper we develop a new
                 semantics of the logic for a programming language where
                 code can be stored (i.e., with higher-order store). The
                 main improvement on previous work is the simplicity of
                 the model. As a consequence, several restrictions
                 imposed by the semantics are removed, leading to a
                 considerably more natural assertion language with a
                 powerful specification logic.",
  x-address =    "Berlin, Heidelberg",
  x-doi =        "10.1007/978-3-540-70583-3\_29",
  x-editor =     "Aceto, Luca and Damg\r{a}rd, Ivan and Goldberg,
                 LeslieAnn and Halld\'{o}rsson, Magn\'{u}sM and
                 Ing\'{o}lfsd\'{o}ttir, Anna and Walukiewicz, Igor",
  x-isbn =       "978-3-540-70582-6",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-540-70583-3\_29",
  xpages =       "348--360",
  year =         "2008",
}

@Article{Streicher1998Classical,
  author =       "Thomas Streicher and Bernhard Reus",
  citeulike-article-id = "7943637",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=969601",
  citeulike-linkout-1 = "http://journals.cambridge.org/action/displayAbstract?fromPage=online\&aid=44197",
  citeulike-linkout-2 = "http://dx.doi.org/10.1017/s0956796898003141",
  date-added =   "2010-10-04 01:25:35",
  journal =      "J. Funct. Program.",
  number =       "6",
  priority =     "2",
  publisher =    "Cambridge University Press",
  title =        "Classical logic, continuation semantics and abstract
                 machines",
  volume =       "8",
  x-abstract =   "One of the goals of this paper is to demonstrate that
                 denotational semantics is useful for operational issues
                 like implementation of functional languages by abstract
                 machines. This is exemplified in a tutorial way by
                 studying the case of extensional untyped call-by-name
                 λ-calculus with Felleisen's control operator \&Cscr;.
                 We derive the transition rules for an abstract machine
                 from a continuation semantics which appears as a
                 generalization of the ¬¬-translation known from
                 logic. The resulting abstract machine appears as an
                 extension of Krivine's machine implementing head
                 reduction. Though the result, namely Krivine's machine,
                 is well known our method of deriving it from
                 continuation semantics is new and applicable to other
                 languages (as e.g. call-by-value variants). Further new
                 results are that Scott's D ∞ -models are all
                 instances of continuation models. Moreover, we extend
                 our continuation semantics to Parigot's λμ-calculus
                 from which we derive an extension of Krivine's machine
                 for λμ-calculus. The relation between continuation
                 semantics and the abstract machines is made precise by
                 proving computational adequacy results employing an
                 elegant method introduced by Pitts.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1017/s0956796898003141",
  x-issn =       "0956-7968",
  x-url =        "http://dx.doi.org/10.1017/s0956796898003141",
  xpages =       "543--572",
  year =         "1998",
}

@InProceedings{Greenberg2010Contracts,
  author =       "Michael Greenberg and Benjamin C. Pierce and Stephanie
                 Weirich",
  booktitle =    "POPL '10: Proceedings of the 37th annual ACM
                 SIGPLAN-SIGACT Symposium on Principles of Programming
                 Languages",
  citeulike-article-id = "7937685",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1706299.1706341",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1706299.1706341",
  comment =      "POPL '10",
  date-added =   "2010-10-01 22:32:44",
  location =     "Madrid, Spain",
  priority =     "2",
  publisher =    "ACM",
  title =        "Contracts made manifest",
  x-abstract =   "Since Findler and Felleisen introduced higher-order
                 contracts , many variants have been proposed. Broadly,
                 these fall into two groups: some follow Findler and
                 Felleisen in using latent contracts, purely dynamic
                 checks that are transparent to the type system; others
                 use manifest contracts, where refinement types record
                 the most recent check that has been applied to each
                 value. These two approaches are commonly assumed to be
                 equivalent---different ways of implementing the same
                 idea, one retaining a simple type system, and the other
                 providing more static information. Our goal is to
                 formalize and clarify this folklore understanding. Our
                 work extends that of Gronski and Flanagan, who defined
                 a latent calculus λ C and a manifest calculus λ H ,
                 gave a translation φ from λ C to λ H , and proved
                 that, if a λ C term reduces to a constant, then so
                 does its φ-image. We enrich their account with a
                 translation Ψ from λ H to λ C and prove an analogous
                 theorem. We then generalize the whole framework to
                 dependent contracts , whose predicates can mention free
                 variables. This extension is both pragmatically
                 crucial, supporting a much more interesting range of
                 contracts, and theoretically challenging. We define
                 dependent versions of λ H and two dialects ({"}lax{"}
                 and {"}picky{"}) of λ C , establish type soundness---a
                 substantial result in itself, for λ H ---and extend φ
                 and Ψ accordingly. Surprisingly, the intuition that
                 the latent and manifest systems are equivalent now
                 breaks down: the extended translations preserve
                 behavior in one direction but, in the other, sometimes
                 yield terms that blame more.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1706299.1706341",
  x-isbn =       "978-1-60558-479-9",
  x-series =     "POPL '10",
  x-url =        "http://dx.doi.org/10.1145/1706299.1706341",
  xpages =       "353--364",
  year =         "2010",
}

@Article{Biernacka2007Concrete,
  author =       "Malgorzata Biernacka and Olivier Danvy",
  citeulike-article-id = "7916623",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1297658.1297664",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1297658.1297664",
  date-added =   "2010-09-28 16:20:35",
  journal =      "ACM Trans. Comput. Logic",
  number =       "1",
  priority =     "2",
  publisher =    "ACM",
  title =        "A concrete framework for environment machines",
  volume =       "9",
  x-abstract =   "We materialize the common understanding that calculi
                 with explicit substitutions provide an intermediate
                 step between an abstract specification of substitution
                 in the lambda-calculus and its concrete
                 implementations. To this end, we go back to Curien's
                 original calculus of closures (an early calculus with
                 explicit substitutions), we extend it minimally so that
                 it can also express one-step reduction strategies, and
                 we methodically derive a series of environment machines
                 from the specification of two one-step reduction
                 strategies for the lambda-calculus: normal order and
                 applicative order. The derivation extends Danvy and
                 Nielsen's refocusing-based construction of abstract
                 machines with two new steps: one for coalescing two
                 successive transitions into one, and the other for
                 unfolding a closure into a term and an environment in
                 the resulting abstract machine. The resulting
                 environment machines include both the Krivine machine
                 and the original version of Krivine's machine,
                 Felleisen et al.'s {CEK} machine, and Leroy's Zinc
                 abstract machine.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1297658.1297664",
  x-issn =       "1529-3785",
  x-url =        "http://dx.doi.org/10.1145/1297658.1297664",
  xpages =       "1--30",
  year =         "2007",
}

@Book{RalphJohan1998Refinement,
  author =       "Ralph Johan and Abo Akademi and J. Von Wright",
  citeulike-article-id = "3574348",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=551462",
  date-added =   "2010-09-23 17:06:51",
  priority =     "2",
  publisher =    "Springer-Verlag New York, Inc.",
  title =        "Refinement Calculus: {A} Systematic Introduction",
  x-abstract =   "From the Publisher: The authors begin with a
                 presentation of a new foundation for the refinement
                 calculus based on lattice theory and higher order
                 logic, together with a simple theory of program
                 variables. The second part of the book describes the
                 predicate transformer approach to programming logic and
                 program semantics as well as the refinement calculus.
                 The authors examine contracts, games, and program
                 statements and show how their operational semantics is
                 related to their predicate transformer interpretation.
                 The third part of the book shows how to handle
                 recursion and iteration in the refinement calculus and
                 also describes how to use the calculus to reason about
                 two-person games. Also presented are case studies of
                 program refinement. In the final part, the book
                 addresses specific issues related to program
                 refinement, such as implementing specification
                 statements, making refinements in context, and
                 transforming iterative structures in a correctness
                 preserving way. The book is intended for graduate and
                 advanced undergraduate students interested in the
                 mathematics and logic of systematic program
                 construction as well as for programmers and researchers
                 interested in a deeper understanding of these issues.",
  x-address =    "Secaucus, NJ, USA",
  x-editor =     "Schneider, F. B. and Gries, D.",
  x-isbn =       "0387984178",
  x-url =        "http://portal.acm.org/citation.cfm?id=551462",
  year =         "1998",
}

@Book{milner97:ml-definition,
  author =       "Robin Milner and Mads Tofte and Robert Harper and
                 David MacQueen",
  citeulike-article-id = "113339",
  citeulike-linkout-0 = "http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0262631814",
  citeulike-linkout-1 = "http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0262631814",
  citeulike-linkout-2 = "http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0262631814",
  citeulike-linkout-3 = "http://www.amazon.jp/exec/obidos/ASIN/0262631814",
  citeulike-linkout-4 = "http://www.amazon.co.uk/exec/obidos/ASIN/0262631814/citeulike00-21",
  citeulike-linkout-5 = "http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0262631814",
  citeulike-linkout-6 = "http://www.worldcat.org/isbn/0262631814",
  citeulike-linkout-7 = "http://books.google.com/books?vid=ISBN0262631814",
  citeulike-linkout-8 = "http://www.amazon.com/gp/search?keywords=0262631814\&index=books\&linkCode=qs",
  citeulike-linkout-9 = "http://www.librarything.com/isbn/0262631814",
  date-added =   "2010-09-22 21:51:18",
  day =          "15",
  edition =      "Revised",
  howpublished = "Paperback",
  month =        may,
  priority =     "2",
  publisher =    "The MIT Press",
  title =        "The Definition of Standard {ML}",
  x-abstract =   "Standard {ML} is a general-purpose programming
                 language designed for large projects. This book
                 provides a formal definition of Standard {ML} for the
                 benefit of all concerned with the language, including
                 users and implementers. Because computer programs are
                 increasingly required to withstand rigorous analysis,
                 it is all the more important that the language in which
                 they are written be defined with full {rigor.One}
                 purpose of a language definition is to establish a
                 theory of meanings upon which the understanding of
                 particular programs may rest. To properly define a
                 programming language, it is necessary to use some form
                 of notation other than a programming language. Given a
                 concern for rigor, mathematical notation is an obvious
                 choice. The authors have defined their semantic objects
                 in mathematical notation that is completely independent
                 of Standard {ML}.In defining a language one must also
                 define the rules of evaluation precisely--that is,
                 define what meaning results from evaluating any phrase
                 of the language. The definition thus constitutes a
                 formal specification for an implementation. The authors
                 have developed enough of their theory to give sense to
                 their rules of {evaluation.The} Definition of Standard
                 {ML} is the essential point of reference for Standard
                 {ML}. Since its publication in 1990, the implementation
                 technology of the language has advanced enormously and
                 the number of users has grown. The revised edition
                 includes a number of new features, omits little-used
                 features, and corrects mistakes of definition.",
  x-isbn =       "0262631814",
  x-url =        "http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0262631814",
  year =         "1997",
}

@TechReport{plt-tr1,
  author =       "Matthew Flatt and {PLT}",
  citeulike-article-id = "7870581",
  comment =      "\url{http://racket-lang.org/tr1/}",
  date-added =   "2010-09-21 19:30:32",
  institution =  "PLT Inc.",
  number =       "PLT-TR-2010-1",
  priority =     "2",
  title =        "Reference: Racket",
  year =         "2010",
}

@Book{StoyDenotational,
  author =       "Joseph Stoy",
  citeulike-article-id = "542159",
  citeulike-linkout-0 = "http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0262191474",
  citeulike-linkout-1 = "http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0262191474",
  citeulike-linkout-2 = "http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0262191474",
  citeulike-linkout-3 = "http://www.amazon.co.uk/exec/obidos/ASIN/0262191474/citeulike00-21",
  citeulike-linkout-4 = "http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0262191474",
  citeulike-linkout-5 = "http://www.worldcat.org/isbn/262191474",
  citeulike-linkout-6 = "http://books.google.com/books?vid=ISBN262191474",
  citeulike-linkout-7 = "http://www.amazon.com/gp/search?keywords=262191474\&index=books\&linkCode=qs",
  citeulike-linkout-8 = "http://www.librarything.com/isbn/262191474",
  date-added =   "2010-09-13 21:11:49",
  howpublished = "{Unknown Binding}",
  priority =     "2",
  publisher =    "{MIT Press}",
  title =        "Denotational semantics: The {Scott-Strachey} approach
                 to programming language theory",
  x-abstract =   "{"First book-length exposition of the denotational (or
                 `mathematical' or `functional') approach to the formal
                 semantics of programming languages (in contrast to
                 `operational' and `axiomatic' approaches). Treats
                 various kinds of languages, beginning with the
                 pure-lambda-calculus and progressing through languages
                 with states, commands, jumps, and assignments. This
                 somewhat discursive account is a valuable compilation
                 of results not otherwise available in a single
                 source."<br /> -- <i>American Mathematical
                 Monthly</i>}",
  x-isbn =       "262191474",
  x-url =        "http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0262191474",
}

@TechReport{Plotkin1981Structural,
  author =       "G. D. Plotkin",
  citeulike-article-id = "1437",
  citeulike-linkout-0 = "http://citeseer.ist.psu.edu/plotkin81structural.html",
  citeulike-linkout-1 = "http://citeseer.lcs.mit.edu/plotkin81structural.html",
  citeulike-linkout-2 = "http://citeseer.ifi.unizh.ch/plotkin81structural.html",
  citeulike-linkout-3 = "http://citeseer.comp.nus.edu.sg/plotkin81structural.html",
  date-added =   "2010-09-13 21:07:15",
  number =       "DAIMI FN-19",
  priority =     "2",
  title =        "A Structural Approach to Operational Semantics",
  x-abstract =   "Syntax of a very simple programming language called L.
                 What is abstract about it will be discussed a little
                 here and later at greater length. For us syntax is a
                 collection of syntactic sets of phrases; each set
                 corresponds to a different type of phrase. Some of
                 these sets are very simple and can be taken as given:
                 Truthvalues This is the set T = ftt; ffg and is ranged
                 over by (the metavariable) t (and we also happily
                 employ for this (and any other) metavariable sub- and
                 super-scripts to...",
  x-address =    "University of Aarhus",
  x-url =        "http://citeseer.ist.psu.edu/plotkin81structural.html",
  year =         "1981",
}

@PhdThesis{Felleisen1987Calculi,
  author =       "Matthias Felleisen",
  citeulike-article-id = "7818882",
  date-added =   "2010-09-13 21:02:44",
  priority =     "2",
  school =       "Indiana University",
  title =        "The Calculi of {Lambda-v-CS} Conversion: {A} Syntactic
                 Theory of Control and State in Imperative
                 {Higher-Order} Programming Languages",
  year =         "1987",
}

@InProceedings{Felleisen1986Control,
  author =       "Matthias Felleisen and Daniel P. Friedman",
  booktitle =    "Proc. of the IFIP TC 2/WG2. 2 Working Conf. on Formal
                 Description of Programming Concepts Part III",
  citeulike-article-id = "7818856",
  date-added =   "2010-09-13 20:58:16",
  location =     "Ebberup, Denmark",
  month =        aug,
  priority =     "2",
  title =        "Control Operators, the {SECD}-Machine, and the
                 {Lambda-Calculus}",
  xpages =       "193--219",
  year =         "1986",
}

@InProceedings{Klein2009Randomized,
  author =       "Casey Klein and Robert B. Findler",
  booktitle =    "Workshop on Scheme and Functional Programming",
  citeulike-article-id = "7801538",
  date-added =   "2010-09-08 22:05:52",
  priority =     "2",
  title =        "Randomized Testing in {PLT} Redex",
  year =         "2009",
}

@Book{Krishnamurthi2007Programming,
  author =       "Shriram Krishnamurthi",
  citeulike-article-id = "7801512",
  date-added =   "2010-09-08 21:50:55",
  month =        apr,
  priority =     "2",
  title =        "Programming Languages: Application and
                 Interpretation",
  year =         "2007",
}

@Book{Felleisen2001How,
  author =       "Matthias Felleisen and Robert B. Findler and Matthew
                 Flatt and Shriram Krishnamurthi",
  citeulike-article-id = "1396",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=369273",
  date-added =   "2010-09-08 21:48:55",
  priority =     "0",
  publisher =    "MIT Press",
  title =        "How to design programs: an introduction to programming
                 and computing",
  x-address =    "Cambridge, MA, USA",
  x-isbn =       "0-262-06218-6",
  x-url =        "http://portal.acm.org/citation.cfm?id=369273",
  year =         "2001",
}

@InProceedings{Krishnaswami2010Verifying,
  author =       "Neel R. Krishnaswami and Lars Birkedal and Jonathan
                 Aldrich",
  booktitle =    "TLDI '10: Proceedings of the 5th ACM SIGPLAN Workshop
                 on Types in Language Design and Implementation",
  citeulike-article-id = "7801150",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1708016.1708025",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1708016.1708025",
  date-added =   "2010-09-08 16:50:16",
  location =     "Madrid, Spain",
  priority =     "2",
  publisher =    "ACM",
  title =        "Verifying Event-driven Programs Using Ramified Frame
                 Properties",
  x-abstract =   "Interactive programs, such as {GUIs} or spreadsheets,
                 often maintain dependency information over
                 dynamically-created networks of objects. That is, each
                 imperative object tracks not only the objects its own
                 invariant depends on, but also all of the objects which
                 depend upon it, in order to notify them when it
                 changes. These bidirectional linkages pose a serious
                 challenge to verification, because their correctness
                 relies upon a global invariant over the object graph.
                 We show how to modularly verify programs written using
                 dynamically-generated bidirectional dependency
                 information. The critical idea is to distinguish
                 between the footprint of a command, and the state whose
                 invariants depends upon the footprint. To do so, we
                 define an application-specific semantics of updates,
                 and introduce the concept of a ramification operator to
                 explain how local changes can alter our knowledge of
                 the rest of the heap. We illustrate the applicability
                 of this style of proof with a case study from
                 functional reactive programming, and formally justify
                 reasoning about an extremely imperative implementation
                 as if it were pure.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1708016.1708025",
  x-isbn =       "978-1-60558-891-9",
  x-series =     "TLDI '10",
  x-url =        "http://dx.doi.org/10.1145/1708016.1708025",
  xpages =       "63--76",
  year =         "2010",
}

@Article{Biering2007BIhyperdoctrines,
  author =       "Bodil Biering and Lars Birkedal and Noah T. Smith",
  citeulike-article-id = "2424543",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1275499",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1275497.1275499",
  date-added =   "2010-09-08 16:47:20",
  journal =      "ACM Trans. Program. Lang. Syst.",
  month =        aug,
  number =       "5",
  priority =     "2",
  publisher =    "ACM",
  title =        "{BI}-hyperdoctrines, higher-order separation logic,
                 and abstraction",
  volume =       "29",
  x-abstract =   "We present a precise correspondence between separation
                 logic and a simple notion of predicate {BI}, extending
                 the earlier correspondence given between part of
                 separation logic and propositional {BI}. Moreover, we
                 introduce the notion of a {BI} hyperdoctrine, show that
                 it soundly models classical and intuitionistic first-
                 and higher-order predicate {BI}, and use it to show
                 that we may easily extend separation logic to
                 higher-order . We also demonstrate that this extension
                 is important for program proving, since it provides
                 sound reasoning principles for data abstraction in the
                 presence of aliasing.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1275497.1275499",
  x-issn =       "0164-0925",
  x-url =        "http://dx.doi.org/10.1145/1275497.1275499",
  xpages =       "24+",
  year =         "2007",
}

@InProceedings{Turon2010Separation,
  author =       "Aaron Turon and Mitchell Wand",
  booktitle =    "Submitted to POPL '11",
  citeulike-article-id = "7800775",
  citeulike-linkout-0 = "http://www.ccs.neu.edu/home/turon/sepref/",
  date-added =   "2010-09-08 15:02:18",
  priority =     "2",
  title =        "A separation logic for refining concurrent objects",
  x-url =        "http://www.ccs.neu.edu/home/turon/sepref/",
  year =         "2010",
}

@Article{Findler2002DrScheme,
  author =       "Robert B. Findler and John Clements and Cormac
                 Flanagan and Matthew Flatt and Shriram Krishnamurthi
                 and Paul Steckler and Matthias Felleisen",
  citeulike-article-id = "1383",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=968413.968416",
  citeulike-linkout-1 = "http://journals.cambridge.org/action/displayAbstract?fromPage=online\&aid=100085",
  citeulike-linkout-2 = "http://dx.doi.org/10.1017/s0956796801004208",
  date-added =   "2010-09-08 07:17:47",
  journal =      "JFP",
  month =        mar,
  number =       "02",
  priority =     "2",
  publisher =    "Cambridge University Press",
  title =        "DrScheme: a programming environment for {S}cheme",
  volume =       "12",
  x-abstract =   "{DrScheme} is a programming environment for Scheme. It
                 fully integrates a graphics-enriched editor, a parser
                 for multiple variants of Scheme, a functional
                 read-eval-print loop, and an algebraic printer. The
                 environment is especially useful for students, because
                 it has a tower of syntactically restricted variants of
                 Scheme that are designed to catch typical student
                 mistakes and explain them in terms the students
                 understand. The environment is also useful for
                 professional programmers, due to its sophisticated
                 programming tools, such as the static debugger, and its
                 advanced language features, such as units and mixins.
                 Beyond the ordinary programming environment tools,
                 {DrScheme} provides an algebraic stepper, a
                 context-sensitive syntax checker, and a static
                 debugger. The stepper reduces Scheme programs to
                 values, according to the reduction semantics of Scheme.
                 It is useful for explaining the semantics of linguistic
                 facilities and for studying the behavior of small
                 programs. The syntax checker annotates programs with
                 font and color changes based on the syntactic structure
                 of the program. On demand, it draws arrows that point
                 from bound to binding occurrences of identifiers. It
                 also supports α-renaming. Finally, the static debugger
                 provides a type inference system that explains specific
                 inferences in terms of a value-flow graph, selectively
                 overlaid on the program text.",
  x-doi =        "10.1017/s0956796801004208",
  x-issn =       "0956-7968",
  x-url =        "http://dx.doi.org/10.1017/s0956796801004208",
  xpages =       "159--182",
  year =         "2002",
}

@InProceedings{Bourdoncle1993Abstract,
  author =       "Fran\c{c}ois Bourdoncle",
  booktitle =    "PLDI '93: Proceedings of the ACM SIGPLAN 1993
                 Conference on Programming Language Design and
                 Implementation",
  citeulike-article-id = "7796677",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=155090.155095",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/155090.155095",
  date-added =   "2010-09-08 07:11:28",
  location =     "Albuquerque, New Mexico, United States",
  priority =     "2",
  publisher =    "ACM",
  title =        "Abstract debugging of higher-order imperative
                 languages",
  x-abstract =   "Abstract interpretation is a formal method that
                 enables the static determination (i.e. at compile-time)
                 of the dynamic properties (i.e. at run-time) of
                 programs. We present an abstract interpretation-based
                 method, called abstract debugging , which enables the
                 static and formal debugging of programs, prior to their
                 execution, by finding the origin of potential bugs as
                 well as necessary conditions for these bugs not to
                 occur at run-time. We show how invariant assertions and
                 intermittent assertions , such as termination, can be
                 used to formally debug programs. Finally, we show how
                 abstract debugging can be effectively and efficiently
                 applied to higher-order imperative programs with
                 exceptions and jumps to non-local labels, and present
                 the Syntox system that enables the abstract debugging
                 of the Pascal language by the determination of the
                 range of the scalar variables of programs.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/155090.155095",
  x-isbn =       "0-89791-598-4",
  x-url =        "http://dx.doi.org/10.1145/155090.155095",
  xpages =       "46--55",
  year =         "1993",
}

@InProceedings{Flanagan1996Catching,
  author =       "Cormac Flanagan and Matthew Flatt and Shriram
                 Krishnamurthi and Stephanie Weirich and Matthias
                 Felleisen",
  booktitle =    "PLDI '96: Proceedings of the ACM SIGPLAN 1996
                 Conference on Programming Language Design and
                 Implementation",
  citeulike-article-id = "4156",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=231387",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/231379.231387",
  date-added =   "2010-09-08 06:52:44",
  location =     "Philadelphia, Pennsylvania, United States",
  month =        may,
  priority =     "2",
  publisher =    "ACM",
  title =        "Catching bugs in the web of program invariants",
  x-abstract =   "{MrSpidey} is a user-friendly, interactive static
                 debugger for Scheme. A static debugger supplements the
                 standard debugger by analyzing the program and
                 pinpointing those program operations that may cause
                 run-time errors such as dereferencing the null pointer
                 or applying non-functions. The program analysis of
                 {MrSpidey} computes value set descriptions for each
                 term in the program and constructs a value flow graph
                 connecting the set descriptions. Using the set
                 descriptions, {MrSpidey} can identify and highlight
                 potentially erroneous program operations, whose cause
                 the programmer can then explore by selectively exposing
                 portions of the value flow graph.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/231379.231387",
  x-isbn =       "0-89791-795-2",
  x-issn =       "0362-1340",
  x-series =     "PLDI",
  x-url =        "http://dx.doi.org/10.1145/231379.231387",
  xpages =       "23--32",
  year =         "1996",
}

@InProceedings{Jackson2000Finding,
  author =       "Daniel Jackson and Mandana Vaziri",
  booktitle =    "ISSTA '00: Proceedings of the 2000 ACM SIGSOFT
                 International Symposium on Software Testing and
                 Analysis",
  citeulike-article-id = "801513",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=383378",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/347324.383378",
  date-added =   "2010-09-08 06:47:42",
  location =     "Portland, Oregon, United States",
  priority =     "2",
  publisher =    "ACM",
  title =        "Finding bugs with a constraint solver",
  x-abstract =   "Note: {OCR} errors may be found in this Reference List
                 extracted from the full text article. {ACM} has opted
                 to expose the complete List rather than only correct
                 and linked references.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/347324.383378",
  x-isbn =       "1-58113-266-2",
  x-url =        "http://dx.doi.org/10.1145/347324.383378",
  xpages =       "14--25",
  year =         "2000",
}

@InProceedings{Wrigstad2010Integrating,
  author =       "Tobias Wrigstad and Francesco Z. Nardelli and Sylvain
                 Lebresne and Johan {\"{O}}stlund and Jan Vitek",
  booktitle =    "POPL '10: Proceedings of the 37th annual ACM
                 SIGPLAN-SIGACT symposium on Principles of programming
                 languages",
  citeulike-article-id = "6614670",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1706299.1706343",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1706299.1706343",
  date-added =   "2010-09-08 06:24:27",
  location =     "Madrid, Spain",
  priority =     "2",
  publisher =    "ACM",
  title =        "Integrating typed and untyped code in a scripting
                 language",
  x-abstract =   "Many large software systems originate from untyped
                 scripting language code. While good for initial
                 development, the lack of static type annotations can
                 impact code-quality and performance in the long run. We
                 present an approach for integrating untyped code and
                 typed code in the same system to allow an initial
                 prototype to smoothly evolve into an efficient and
                 robust program. We introduce like types , a novel
                 intermediate point between dynamic and static typing.
                 Occurrences of like types variables are checked
                 statically within their scope but, as they may be bound
                 to dynamic values, their usage is checked dynamically.
                 Thus like types provide some of the benefits of static
                 typing without decreasing the expressiveness of the
                 language. We provide a formal account of like types in
                 a core object calculus and evaluate their applicability
                 in the context of a new scripting language.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1706299.1706343",
  x-isbn =       "978-1-60558-479-9",
  x-url =        "http://dx.doi.org/10.1145/1706299.1706343",
  xpages =       "377--388",
  year =         "2010",
}

@InProceedings{Felleisen2010Adding,
  author =       "Matthias Felleisen",
  booktitle =    "TLDI '10: Proceedings of the 5th ACM SIGPLAN workshop
                 on Types in language design and implementation",
  citeulike-article-id = "7796653",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1708017",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1708016.1708017",
  date-added =   "2010-09-08 06:24:05",
  location =     "Madrid, Spain",
  priority =     "2",
  publisher =    "ACM",
  title =        "Adding types to untyped languages",
  x-abstract =   "Over the last 15 years, we have experienced a
                 programming language renaissance. Numerous scripting
                 languages have become widely used in industrial and
                 open-source projects. They have supplemented the
                 existing mainstream {languages--C}++ and Java--and, in
                 contexts such as systems administration and web
                 programming, they have started to play a dominant
                 role.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1708016.1708017",
  x-isbn =       "978-1-60558-891-9",
  x-url =        "http://dx.doi.org/10.1145/1708016.1708017",
  xpages =       "1--2",
  year =         "2010",
}

@Book{Morgan1990Programming,
  author =       "Carroll Morgan",
  citeulike-article-id = "891640",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=95423",
  date-added =   "2010-09-08 05:49:34",
  priority =     "2",
  publisher =    "Prentice-Hall, Inc.",
  title =        "Programming from specifications",
  x-address =    "Upper Saddle River, NJ, USA",
  x-isbn =       "0-13-726225-6",
  x-url =        "http://portal.acm.org/citation.cfm?id=95423",
  year =         "1990",
}

@Article{Matthews2009Operational,
  author =       "Jacob Matthews and Robert B. Findler",
  citeulike-article-id = "6347224",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1498926.1498930",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1498926.1498930",
  date-added =   "2010-09-08 05:39:22",
  journal =      "ACM Trans. Program. Lang. Syst.",
  number =       "3",
  priority =     "2",
  publisher =    "ACM",
  title =        "Operational semantics for multi-language programs",
  volume =       "31",
  x-abstract =   "Interoperability is big business, a fact to which
                 .{NET}, the {JVM}, and {COM} can attest. Language
                 designers are well aware of this, and they are
                 designing programming languages that reflect
                 it\&mdash;for instance, {SML}.{NET}, F\&num;, Mondrian,
                 and Scala all treat interoperability as a central
                 design feature. Still, current multi-language research
                 tends not to focus on the semantics of these features,
                 but only on how to implement them efficiently. In this
                 article, we attempt to rectify that by giving a
                 technique for specifying the operational semantics of a
                 multi-language system as a composition of the models of
                 its constituent languages. Our technique abstracts away
                 the low-level details of interoperability like garbage
                 collection and representation coherence, and lets us
                 focus on semantic properties like type-safety,
                 equivalence, and termination behavior. In doing so it
                 allows us to adapt standard theoretical techniques such
                 as subject-reduction, logical relations, and
                 operational equivalence for use on multi-language
                 systems. Generally speaking, our proofs of properties
                 in a multi-language context are mutually referential
                 versions of their single language counterparts.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1498926.1498930",
  x-issn =       "0164-0925",
  x-url =        "http://dx.doi.org/10.1145/1498926.1498930",
  xpages =       "1--44",
  year =         "2009",
}

@PhdThesis{Clements2006Portable,
  author =       "John Clements",
  citeulike-article-id = "7796622",
  date-added =   "2010-09-08 05:19:26",
  month =        feb,
  priority =     "2",
  school =       "Northeastern University",
  title =        "Portable and {High-Level} Access to the Stack with
                 Continuation Marks",
  year =         "2006",
}

@InCollection{VanHorn2008Flow,
  author =       "David Van{ }Horn and Harry G. Mairson",
  booktitle =    "Static Analysis",
  chapter =      "17",
  citeulike-article-id = "5141450",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-540-69166-2\_17",
  citeulike-linkout-1 = "http://www.springerlink.com/content/x1n1193817682237",
  date-added =   "2010-09-08 05:09:07",
  journal =      "Static Analysis",
  priority =     "2",
  publisher =    "Springer Berlin / Heidelberg",
  title =        "Flow Analysis, Linearity, and {PTIME}",
  volume =       "5079",
  x-abstract =   "Flow analysis is a ubiquitous and much-studied
                 component of compiler technology\^{a}and its variations
                 abound. Amongst the most well known is Shivers\^{a}
                 {0CFA}; however, the best known algorithm for {0CFA}
                 requires time cubic in the size of the analyzed program
                 and is unlikely to be improved. Consequently, several
                 analyses have been designed to approximate {0CFA} by
                 trading precision for faster computation.
                 Henglein\^{a}s simple closure analysis, for example,
                 forfeits the notion of directionality in flows and
                 enjoys an almost linear time algorithm. But in making
                 trade-offs between precision and complexity, what has
                 been given up and what has been gained? Where do these
                 analyses differ and where do they coincide? We identify
                 a core language\^{a}the linear
                 \^{I}»-calculus\^{a}where {0CFA}, simple closure
                 analysis, and many other known approximations or
                 restrictions to {0CFA} are rendered identical.
                 Moreover, for this core language, analysis corresponds
                 with (instrumented) evaluation. Because analysis
                 faithfully captures evaluation, and because the linear
                 \^{I}»-calculus is complete for ptime, we derive
                 ptime-completeness results for all of these analyses.",
  x-address =    "Berlin, Heidelberg",
  x-doi =        "10.1007/978-3-540-69166-2\_17",
  x-editor =     "Alpuente, Mar\'{\i}a and Vidal, Germ\'{a}n",
  x-isbn =       "978-3-540-69163-1",
  x-issn =       "0302-9743",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-540-69166-2\_17",
  xpages =       "255-269--269",
  year =         "2008",
}

@Book{Meyer1997Objectoriented,
  author =       "Bertrand Meyer",
  citeulike-article-id = "1334997",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=261119",
  date-added =   "2010-09-08 04:43:06",
  priority =     "2",
  publisher =    "Prentice-Hall, Inc.",
  title =        "Object-oriented software construction (2nd ed.)",
  x-abstract =   "An abstract is not available.",
  x-address =    "Upper Saddle River, NJ, USA",
  x-isbn =       "0-13-629155-4",
  x-url =        "http://portal.acm.org/citation.cfm?id=261119",
  year =         "1997",
}

@PhdThesis{Findler2002Behavioral,
  author =       "Robert B. Findler",
  citeulike-article-id = "7796576",
  date-added =   "2010-09-08 04:31:47",
  month =        apr,
  priority =     "2",
  school =       "Rice University",
  title =        "Behavioral Software Contracts",
  year =         "2002",
}

@InProceedings{TobinHochstadt2006Interlanguage,
  author =       "Sam Tobin-Hochstadt and Matthias Felleisen",
  booktitle =    "OOPSLA '06: Companion to the 21st ACM SIGPLAN
                 Symposium on Object-oriented Programming Systems,
                 Languages, and Applications",
  citeulike-article-id = "2898851",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1176617.1176755",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1176617.1176755",
  date-added =   "2010-09-08 04:06:24",
  location =     "Portland, Oregon, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "Interlanguage migration: from scripts to programs",
  x-abstract =   "As scripts grow into full-fledged applications,
                 programmers should want to port portions of their
                 programs from scripting languages to languages with
                 sound and rich type systems. This form of interlanguage
                 migration ensures type-safety and provides minimal
                 guarantees for reuse in other applications, {too.In}
                 this paper, we present a framework for expressing this
                 form of interlanguage migration. Given a program that
                 consists of modules in the untyped lambda calculus, we
                 prove that rewriting one of them in a simply typed
                 lambda calculus produces an equivalent program and adds
                 the expected amount of type safety, i.e., code in typed
                 modules can't go wrong . To ensure these guarantees,
                 the migration process infers constraints from the
                 statically typed module and imposes them on the
                 dynamically typed modules in the form of behavioral
                 contracts.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1176617.1176755",
  x-isbn =       "1-59593-491-X",
  x-url =        "http://dx.doi.org/10.1145/1176617.1176755",
  xpages =       "964--974",
  year =         "2006",
}

@InProceedings{TobinHochstadt2010Logical,
  author =       "Sam Tobin-Hochstadt and Matthias Felleisen",
  booktitle =    "ICFP '10: International Conference on Functional
                 Programming",
  citeulike-article-id = "7796548",
  date-added =   "2010-09-08 04:04:27",
  month =        sep,
  priority =     "2",
  publisher =    "ACM",
  title =        "Logical Types for Untyped Languages",
  x-series =     "ICFP",
  year =         "2010",
}

@PhdThesis{TobinHochstadt2010Typed,
  author =       "Sam Tobin-Hochstadt",
  citeulike-article-id = "7796546",
  date-added =   "2010-09-08 04:01:17",
  month =        jan,
  priority =     "2",
  school =       "Northeastern University",
  title =        "Typed Scheme: From Scripts to Programs",
  year =         "2010",
}

@InProceedings{Dimoulas2009Future,
  author =       "Christos Dimoulas and Riccardo Pucella and Matthias
                 Felleisen",
  booktitle =    "PPDP '09: Proceedings of the 11th ACM SIGPLAN
                 Conference on Principles and Practice of Declarative
                 Programming",
  citeulike-article-id = "7796542",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1599410.1599435",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1599410.1599435",
  date-added =   "2010-09-08 03:56:11",
  location =     "Coimbra, Portugal",
  priority =     "2",
  publisher =    "ACM",
  title =        "Future contracts",
  x-abstract =   "Many recent research projects focus on language
                 support for behavioral software contracts, that is,
                 assertions that govern the boundaries between software
                 building blocks such as procedures, classes, or
                 modules. Contracts primarily help locate bugs in
                 programs, but they also tend to affect the performance
                 of the program, especially as they become complex.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1599410.1599435",
  x-isbn =       "978-1-60558-568-0",
  x-url =        "http://dx.doi.org/10.1145/1599410.1599435",
  xpages =       "195--206",
  year =         "2009",
}

@Article{Flanagan1999Semantics,
  author =       "C. Flanagan and M. Felleisen",
  citeulike-article-id = "7796538",
  citeulike-linkout-0 = "http://journals.cambridge.org/action/displayAbstract?fromPage=online\&aid=44231",
  citeulike-linkout-1 = "http://dx.doi.org/10.1017/s0956796899003329",
  date-added =   "2010-09-08 03:52:19",
  journal =      "Journal of Functional Programming",
  number =       "01",
  priority =     "2",
  title =        "The semantics of future and an application",
  volume =       "9",
  x-abstract =   "The future annotation of {MultiLisp} provides a simple
                 method for taming the implicit parallelism of
                 functional programs. Prior research on future has
                 concentrated on implementation and design issues, and
                 has largely ignored the development of a semantic
                 characterization of future. This paper considers an
                 idealized functional language with futures and presents
                 a series of operational semantics with increasing
                 degrees of intensionality. The first semantics defines
                 future to be a semantically transparent annotation. The
                 second semantics interprets a future expression as a
                 potentially parallel task. The third semantics
                 explicates the coordination of parallel tasks by
                 introducing placeholder objects and touch
                 {operations.We} use the last semantics to derive a
                 program analysis algorithm and an optimization
                 algorithm that removes provably redundant touch
                 operations. Experiments with the Gambit compiler
                 indicate that this optimization significantly reduces
                 the overhead imposed by touch operations.",
  x-doi =        "10.1017/s0956796899003329",
  x-url =        "http://dx.doi.org/10.1017/s0956796899003329",
  xpages =       "1--31",
  year =         "1999",
}

@InProceedings{Lerner2002Composing,
  author =       "Sorin Lerner and David Grove and Craig Chambers",
  booktitle =    "POPL '02: Proceedings of the 29th ACM SIGPLAN-SIGACT
                 Symposium on Principles of Programming Languages",
  citeulike-article-id = "225304",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=503298",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/503272.503298",
  date-added =   "2010-09-08 03:41:56",
  location =     "Portland, Oregon",
  month =        jan,
  number =       "1",
  priority =     "2",
  publisher =    "ACM",
  title =        "Composing dataflow analyses and transformations",
  volume =       "37",
  x-abstract =   "Dataflow analyses can have mutually beneficial
                 interactions. Previous efforts to exploit these
                 interactions have either (1) iteratively performed each
                 individual analysis until no further improvements are
                 discovered or (2) developed {"}super-analyses{"} that
                 manually combine conceptually separate analyses. We
                 have devised a new approach that allows analyses to be
                 defined independently while still enabling them to be
                 combined automatically and profitably. Our approach
                 avoids the loss of precision associated with iterating
                 individual analyses and the implementation difficulties
                 of manually writing a super-analysis. The key to our
                 approach is a novel method of implicit communication
                 between the individual components of a super-analysis
                 based on graph transformations. In this paper, we
                 precisely define our approach; we demonstrate that it
                 is sound and it terminates; finally we give
                 experimental results showing that in practice (1) our
                 framework produces results at least as precise as
                 iterating the individual analyses while compiling at
                 least 5 times faster, and (2) our framework achieves
                 the same precision as a manually written super-analysis
                 while incurring a compile-time overhead of less than
                 20\%.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/503272.503298",
  x-isbn =       "1-58113-450-9",
  x-url =        "http://dx.doi.org/10.1145/503272.503298",
  xpages =       "270--282",
  year =         "2002",
}

@PhdThesis{VanHorn2009Complexity,
  author =       "David Van{ }Horn",
  citeulike-article-id = "7796521",
  date-added =   "2010-09-08 03:28:14",
  month =        aug,
  priority =     "2",
  school =       "Brandeis University",
  title =        "The Complexity of Flow Analysis in {Higher-Order}
                 Languages",
  year =         "2009",
}

@TechReport{Earl2011StackSummarizing,
  author =       "Christopher Earl and Matt Might and David Van Horn",
  citeulike-article-id = "7796516",
  date-added =   "2010-09-08 03:18:43",
  priority =     "2",
  title =        "{Stack-Summarizing} {Control-Flow} Analysis of
                 {Higher-Order} Programs",
  year =         "2011",
}

@InProceedings{Chang2010Evaluating,
  author =       "Stephen Chang and David Van{ }Horn and Matthias
                 Felleisen",
  booktitle =    "Trends in Functional Programming",
  citeulike-article-id = "7796514",
  date-added =   "2010-09-08 03:14:41",
  priority =     "2",
  title =        "Evaluating Call By Need on the Control Stack",
  x-series =     "LNCS",
  year =         "2010",
}

@InProceedings{Earl2010Pushdown,
  author =       "Christopher Earl and Matthew Might and David Van
                 Horn",
  booktitle =    "Workshop on Scheme and Functional Programming",
  citeulike-article-id = "7750284",
  date-added =   "2010-08-31 18:27:47",
  priority =     "2",
  title =        "Pushdown control-flow analysis of higher-order
                 programs",
  year =         "2010",
}

@InCollection{Navabi2009Exceptionally,
  author =       "Armand Navabi and Suresh Jagannathan",
  booktitle =    "Coordination Models and Languages",
  chapter =      "3",
  citeulike-article-id = "7750280",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/978-3-642-02053-7\_3",
  citeulike-linkout-1 = "http://www.springerlink.com/content/n2780775v1545662",
  date-added =   "2010-08-31 18:23:22",
  priority =     "2",
  publisher =    "Springer Berlin / Heidelberg",
  title =        "Exceptionally Safe Futures",
  volume =       "5521",
  x-abstract =   "A future is a well-known programming construct used to
                 introduce concurrency to sequential programs.
                 Computations annotated as futures are executed
                 asynchronously and run concurrently with their
                 continuations. Typically, futures are not transparent
                 annotations: a program with futures need not produce
                 the same result as the sequential program from which it
                 was derived. Safe futures guarantee a future-annotated
                 program produce the same result as its sequential
                 counterpart. Ensuring safety is especially challenging
                 in the presence of constructs such as exceptions that
                 permit the expression of non-local control-flow. For
                 example, a future may raise an exception whose handler
                 is in its continuation. To ensure safety, we must
                 guarantee the continuation does not discard this
                 handler regardless of the continuation's own internal
                 control-flow (e.g. exceptions it raises or futures it
                 spawns). In this paper, we present a formulation of
                 safe futures for a higher-order functional language
                 with first-class exceptions. Safety can be guaranteed
                 dynamically by stalling the execution of a continuation
                 that has an exception handler potentially required by
                 its future until the future completes. To enable
                 greater concurrency, we develop a static analysis and
                 instrumentation and formalize the runtime behavior for
                 instrumented programs that allows execution to discard
                 handlers precisely when it is safe to do so.",
  x-address =    "Berlin, Heidelberg",
  x-doi =        "10.1007/978-3-642-02053-7\_3",
  x-editor =     "Field, John and Vasconcelos, Vasco",
  x-isbn =       "978-3-642-02052-0",
  x-series =     "Lecture Notes in Computer Science",
  x-url =        "http://dx.doi.org/10.1007/978-3-642-02053-7\_3",
  xpages =       "47--65",
  year =         "2009",
}

@Article{Debray1997Interprocedural,
  author =       "Saumya K. Debray and Todd A. Proebsting",
  citeulike-article-id = "7736808",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=262004.262006",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/262004.262006",
  date-added =   "2010-08-30 04:38:54",
  journal =      "ACM Trans. Program. Lang. Syst.",
  number =       "4",
  priority =     "2",
  publisher =    "ACM",
  title =        "Interprocedural control flow analysis of first-order
                 programs with tail-call optimization",
  volume =       "19",
  x-abstract =   "Knowledge of low-level control flow is essential for
                 many compiler optimizations. In systems with tail-call
                 optimization, the determination of interprocedural
                 control flow is complicated by the fact that because of
                 tail-call optimization, control flow at procedure
                 returns is not readily evident from the call graph of
                 the program. This article shows how interprocedural
                 control-flow analysis of first-order programs can be
                 carried out using well-known concepts from parsing
                 theory. In particular, we show that context-insensitive
                 ( or zeroth-order) control-flow analysis corresponds to
                 the notion of {FOLLOW} sets in context-free grammars,
                 while context-sensitive (or first-order) control-flow
                 analysis corresponds to the notion of {LR}(1) items.
                 The control-flow information so obtained can be used to
                 improve the precision of interprocedural dataflow
                 analyses as well as to extend certain low-level code
                 optimizations across procedure boundaries.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/262004.262006",
  x-issn =       "0164-0925",
  x-url =        "http://dx.doi.org/10.1145/262004.262006",
  xpages =       "568--585",
  year =         "1997",
}

@InProceedings{Serrano1995Control,
  author =       "Manuel Serrano",
  booktitle =    "SAC '95: Proceedings of the 1995 ACM Symposium on
                 Applied Computing",
  citeulike-article-id = "7630241",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=315891.315934",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/315891.315934",
  comment =      "SAC '95",
  date-added =   "2010-08-13 01:58:30",
  location =     "Nashville, Tennessee, United States",
  priority =     "0",
  publisher =    "ACM",
  title =        "Control flow analysis: a functional languages
                 compilation paradigm",
  x-abstract =   "Note: {OCR} errors may be found in this Reference List
                 extracted from the full text article. {ACM} has opted
                 to expose the complete List rather than only correct
                 and linked references.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/315891.315934",
  x-isbn =       "0-89791-658-1",
  x-url =        "http://dx.doi.org/10.1145/315891.315934",
  xpages =       "118--122",
  year =         "1995",
}

@Article{Felleisen1992Revised,
  author =       "M. Felleisen",
  citeulike-article-id = "1373",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=136293.136297",
  citeulike-linkout-1 = "http://dx.doi.org/10.1016/0304-3975(92)90014-7",
  date-added =   "2010-07-29 21:29:00",
  day =          "14",
  journal =      "Theoretical Computer Science",
  month =        sep,
  number =       "2",
  priority =     "2",
  publisher =    "Elsevier Science Publishers Ltd.",
  title =        "The revised report on the syntactic theories of
                 sequential control and state",
  volume =       "103",
  x-abstract =   "The syntactic theories of control and state are
                 conservative extensions of the λ υ -calculus for
                 equational reasoning about imperative programming
                 facilities in higher-order languages. Unlike the simple
                 λ υ -calculus, the extended theories are mixtures of
                 equivalence relations and compatible congruence
                 relations on the term language, which significantly
                 complicates the reasoning process. In this paper we
                 develop fully compatible equational theories of the
                 same imperative higher-order programming languages. The
                 new theories subsume the original calculi of control
                 and state and satisfy the usual {Church–Rosser} and
                 Standardization Theorems. With the new calculi,
                 equational reasoning about imperative programs becomes
                 as simple as reasoning about functional programs.",
  x-doi =        "10.1016/0304-3975(92)90014-7",
  x-issn =       "03043975",
  x-url =        "http://dx.doi.org/10.1016/0304-3975(92)90014-7",
  xpages =       "235--271",
  year =         "1992",
}

@Article{Wright1994Syntactic,
  author =       "Andrew K. Wright and Matthias Felleisen",
  citeulike-article-id = "1374",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=191905.191909",
  citeulike-linkout-1 = "http://dx.doi.org/10.1006/inco.1994.1093",
  date-added =   "2010-07-28 21:39:27",
  day =          "15",
  journal =      "Information and Computation",
  month =        nov,
  number =       "1",
  priority =     "2",
  publisher =    "Academic Press, Inc.",
  title =        "A Syntactic Approach to Type Soundness",
  volume =       "115",
  x-abstract =   "We present a new approach to proving type soundness
                 for {Hindley/Milner}-style polymorphic type systems.
                 The keys to our approach are (1) an adaptation of
                 subject reduction theorems from combinatory logic to
                 programming languages, and (2) the use of rewriting
                 techniques for the specification of the language
                 semantics. The approach easily extends from polymorphic
                 functional languages to imperative languages that
                 provide references, exceptions, continuations, and
                 similar features. We illustrate the technique with a
                 type soundness theorem for the core of Standard {ML},
                 which includes the first type soundness proof for
                 polymorphic exceptions and continuations.",
  x-doi =        "10.1006/inco.1994.1093",
  x-issn =       "08905401",
  x-url =        "http://dx.doi.org/10.1006/inco.1994.1093",
  xpages =       "38--94",
  year =         "1994",
}

@PhdThesis{Flanagan1997Effective,
  author =       "Cormac Flanagan",
  citeulike-article-id = "7546648",
  date-added =   "2010-07-28 01:46:46",
  month =        may,
  priority =     "2",
  school =       "Rice University",
  title =        "Effective Static Debugging via Componential
                 {Set-Based} Analysis",
  year =         "1997",
}

@PhdThesis{Meunier2006Diss,
  author =       "Philippe Meunier",
  citeulike-article-id = "7544563",
  date-added =   "2010-07-27 15:18:41",
  month =        may,
  priority =     "2",
  school =       "Northeastern University",
  title =        "Modular {Set-Based} Analysis from Contracts",
  year =         "2006",
}

@Article{Lee2002Proof,
  author =       "Oukseh Lee and Kwangkeun Yi and Yunheung Paek",
  citeulike-article-id = "7537317",
  date-added =   "2010-07-24 18:48:22",
  journal =      "IPL",
  priority =     "2",
  publisher =    "Elsevier",
  title =        "A proof method for the correctness of modularized
                 {0CFA}",
  volume =       "81",
  xpages =       "179--185",
  year =         "2002",
}

@Article{Cousot2002Constructive,
  author =       "Patrick Cousot",
  citeulike-article-id = "4298357",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=567195.567197",
  citeulike-linkout-1 = "http://dx.doi.org/10.1016/s0304-3975(00)00313-3",
  date-added =   "2010-07-24 18:03:11",
  day =          "28",
  journal =      "Theor. Comput. Sci.",
  month =        apr,
  number =       "1-2",
  priority =     "2",
  publisher =    "Elsevier Science Publishers Ltd.",
  title =        "Constructive design of a hierarchy of semantics of a
                 transition system by abstract interpretation",
  volume =       "277",
  x-abstract =   "We construct a hierarchy of semantics by successive
                 abstract interpretations. Starting from the maximal
                 trace semantics of a transition system, we derive the
                 big-step semantics, termination and nontermination
                 semantics, Plotkin's natural, Smyth's demoniac and
                 Hoare's angelic relational semantics and equivalent
                 nondeterministic denotational semantics (with
                 alternative powerdomains to the {Egli-Milner} and Smyth
                 constructions), D. Scott's deterministic denotational
                 semantics, the generalized and Dijkstra's
                 conservative/liberal predicate transformer semantics,
                 the generalized/total and Hoare's partial correctness
                 axiomatic semantics and the corresponding proof
                 methods. All the semantics are presented in a uniform
                 fixpoint form and the correspondences between these
                 semantics are established through composable Galois
                 connections, each semantics being formally calculated
                 by abstract interpretation of a more concrete one using
                 Kleene and/or Tarski fixpoint approximation transfer
                 theorems. Copyright 2002 Elsevier Science {B.V}.",
  x-address =    "Essex, UK",
  x-doi =        "10.1016/s0304-3975(00)00313-3",
  x-issn =       "0304-3975",
  x-url =        "http://dx.doi.org/10.1016/s0304-3975(00)00313-3",
  xpages =       "47--103",
  year =         "2002",
}

@Article{Cousot2007Biinductive,
  author =       "P. Cousot and R. Cousot",
  citeulike-article-id = "7537287",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1298822",
  citeulike-linkout-1 = "http://dx.doi.org/10.1016/j.entcs.2007.08.015",
  date-added =   "2010-07-24 17:35:44",
  day =          "24",
  journal =      "Electron. Notes Theor. Comput. Sci.",
  month =        oct,
  number =       "1",
  priority =     "2",
  publisher =    "Elsevier Science Publishers B. V.",
  title =        "Bi-inductive Structural Semantics (Extended
                 Abstract)",
  volume =       "192",
  x-abstract =   "We propose a simple order-theoretic generalization of
                 set-theoretic inductive definitions. This
                 generalization covers inductive, co-inductive and
                 bi-inductive definitions and is preserved by
                 abstraction. This allows the structural operational
                 semantics to describe simultaneously the
                 finite/terminating and infinite/diverging behaviors of
                 programs. This is illustrated on the structural
                 bifinitary small/big-step trace/relational/operational
                 semantics of the call-by-value @l-calculus.",
  x-address =    "Amsterdam, The Netherlands, The Netherlands",
  x-doi =        "10.1016/j.entcs.2007.08.015",
  x-issn =       "1571-0661",
  x-url =        "http://dx.doi.org/10.1016/j.entcs.2007.08.015",
  xpages =       "29--44",
  year =         "2007",
}

@Article{Jensen2002Types,
  author =       "Thomas Jensen",
  citeulike-article-id = "7537279",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=860267",
  date-added =   "2010-07-24 17:22:23",
  priority =     "2",
  publisher =    "Springer-Verlag New York, Inc.",
  title =        "Types in program analysis",
  x-abstract =   "This paper surveys type-based program analysis with an
                 emphasis on the polyvariant program analyses that can
                 be obtained using conjunctive (or intersection) types
                 and parametric polymorphism. In particular, we show 1)
                 how binding-time analysis and strictness analysis are
                 variations of a common framework based on conjunctive
                 types, 2) that the standard abstract interpretation
                 used for strictness analysis is equivalent to the
                 type-based analysis, and 3) that the conjunctive
                 strictness analysis can be made more modular by
                 blending conjunctions with parametric polymorphism.",
  x-address =    "New York, NY, USA",
  x-isbn =       "3-540-00326-6",
  x-url =        "http://portal.acm.org/citation.cfm?id=860267",
  xpages =       "204--222",
  year =         "2002",
}

@InProceedings{Reppy2006Typesensitive,
  author =       "John Reppy",
  booktitle =    "ML '06: Proceedings of the 2006 Workshop on ML",
  citeulike-article-id = "1352870",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1159888",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1159876.1159888",
  comment =      "ML '06",
  date-added =   "2010-07-24 17:20:49",
  location =     "Portland, Oregon, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "Type-sensitive control-flow analysis",
  x-abstract =   "Higher-order typed languages, such as {ML}, provide
                 strong support for data and type abstraction. While
                 such abstraction is often viewed as costing
                 performance, there are situations where it may provide
                 opportunities for more aggressive program optimization.
                 Specifically, we can exploit the fact that type
                 abstraction guarantees representation independence,
                 which allows the compiler to specialize data
                 representations. This paper describes a first step in
                 supporting such optimizations; namely a control-flow
                 analysis that uses the program's type information to
                 compute more precise results. We present our algorithm
                 as an extension of Serrano's version of {0-CFA} and we
                 show that it respects types. We also discuss
                 applications of the analysis with examples of
                 optimizations enabled by the analysis that would not be
                 possible using normal {CFA}.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1159876.1159888",
  x-isbn =       "1-59593-483-9",
  x-url =        "http://dx.doi.org/10.1145/1159876.1159888",
  xpages =       "74--83",
  year =         "2006",
}

@InProceedings{Cousot1997Types,
  author =       "Patrick Cousot",
  booktitle =    "POPL '97: Proceedings of the 24th ACM SIGPLAN-SIGACT
                 Symposium on Principles of Programming Languages",
  citeulike-article-id = "2805371",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=263744",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/263699.263744",
  comment =      "POPL '97",
  date-added =   "2010-07-24 17:01:41",
  location =     "Paris, France",
  priority =     "0",
  publisher =    "ACM",
  title =        "Types as abstract interpretations",
  x-abstract =   "Note: {OCR} errors may be found in this Reference List
                 extracted from the full text article. {ACM} has opted
                 to expose the complete List rather than only correct
                 and linked references.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/263699.263744",
  x-isbn =       "0-89791-853-3",
  x-url =        "http://dx.doi.org/10.1145/263699.263744",
  xpages =       "316--331",
  year =         "1997",
}

@InProceedings{Shao1994Spaceefficient,
  author =       "Zhong Shao and Andrew W. Appel",
  booktitle =    "LFP '94: Proceedings of the 1994 ACM Conference on
                 LISP and Functional Programming",
  citeulike-article-id = "7536656",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=182409.156783",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/182409.156783",
  date-added =   "2010-07-24 02:08:41",
  location =     "Orlando, Florida, United States",
  priority =     "0",
  publisher =    "ACM",
  title =        "Space-efficient closure representations",
  x-abstract =   "Many modern compilers implement function calls (or
                 returns) in two steps: first, a closure environment is
                 properly installed to provide access for free variables
                 in the target program fragment; second, the control is
                 transferred to the target by a ” jump with arguments
                 (or results)”. Closure conversion , which decides
                 where and how to represent closures at runtime, is a
                 crucial step in compilation of functional languages. We
                 have a new algorithm that exploits the use of
                 compile-time control and data flow information to
                 optimize closure representations. By extensive closure
                 sharing and allocating as many closures in registers as
                 possible, our new closure conversion algorithm reduces
                 heap allocation by 36\% and memory fetches for
                 local/global variables by 43\%; and improves the
                 already-efficient code generated by the Standard {ML}
                 of New Jersey compiler by about 17\% on a {DECstation}
                 5000. Moreover, unlike most other approaches, our new
                 closure allocation scheme satisfies the strong ” safe
                 for space complexity” rule, thus achieving good
                 asymptotic space usage.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/182409.156783",
  x-isbn =       "0-89791-643-3",
  x-series =     "LFP '94",
  x-url =        "http://dx.doi.org/10.1145/182409.156783",
  xpages =       "150--161",
  year =         "1994",
}

@InProceedings{Stefanescu1994Equational,
  author =       "Dan Stefanescu and Yuli Zhou",
  booktitle =    "LFP '94: Proceedings of the 1994 ACM conference on
                 LISP and functional programming",
  citeulike-article-id = "7536649",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=182409.182497",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/182409.182497",
  date-added =   "2010-07-24 01:46:12",
  location =     "Orlando, Florida, United States",
  priority =     "2",
  publisher =    "ACM",
  title =        "An equational framework for the flow analysis of
                 higher order functional programs",
  x-abstract =   "We present a simple method for the general flow
                 analysis of high-order functional programs. The method
                 computes an abstraction of the program's runtime
                 environment via a system of monotonic equations. As the
                 environment can grow unbounded, we exploit patterns in
                 the program's control structure (i.e., the call-tree)
                 to determine some static partition of the environment,
                 and merge points in the environment belonging to the
                 same equivalent-class. High order functions are handled
                 by embedding control information into closures. The
                 method is proven correct with respect to a rewriting
                 system based operational semantics. Various
                 implementation issues are also considered.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/182409.182497",
  x-isbn =       "0-89791-643-3",
  x-url =        "http://dx.doi.org/10.1145/182409.182497",
  xpages =       "318--327",
  year =         "1994",
}

@InProceedings{Jones1982Flexible,
  author =       "Neil D. Jones and Steven S. Muchnick",
  booktitle =    "POPL '82: Proceedings of the 9th ACM SIGPLAN-SIGACT
                 Symposium on Principles of Programming Languages",
  citeulike-article-id = "1567509",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=582161",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/582153.582161",
  date-added =   "2010-07-23 23:50:09",
  location =     "Albuquerque, New Mexico",
  priority =     "0",
  publisher =    "ACM",
  title =        "A flexible approach to interprocedural data flow
                 analysis and programs with recursive data structures",
  x-abstract =   "A new approach to data flow analysis of procedural
                 programs and programs with recursive data structures is
                 described. The method depends on simulation of the
                 interpreter for the subject programming language using
                 a retrieval function to approximate a program's data
                 structures.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/582153.582161",
  x-isbn =       "0-89791-065-6",
  x-series =     "POPL '82",
  x-url =        "http://dx.doi.org/10.1145/582153.582161",
  xpages =       "66--74",
  year =         "1982",
}

@PhdThesis{Danvy:DSc,
  author =       "Olivier Danvy",
  citeulike-article-id = "7531722",
  date-added =   "2010-07-23 01:44:36",
  month =        oct,
  priority =     "0",
  school =       "Department of Computer Science, Aarhus University",
  title =        "An Analytical Approach to Program as Data Objects",
  type =         "{DSc} thesis",
  x-address =    "Aarhus, Denmark",
  year =         "2006",
}

@InProceedings{Clements2001Modeling,
  author =       "John Clements and Matthew Flatt and Matthias
                 Felleisen",
  booktitle =    "ESOP '01: Proceedings of the 10th European Symposium
                 on Programming Languages and Systems",
  citeulike-article-id = "7531167",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=645395.651947",
  date-added =   "2010-07-22 16:51:36",
  priority =     "0",
  publisher =    "Springer-Verlag",
  title =        "Modeling an Algebraic Stepper",
  x-address =    "London, UK",
  x-isbn =       "3-540-41862-8",
  x-url =        "http://portal.acm.org/citation.cfm?id=645395.651947",
  xpages =       "320--334",
  year =         "2001",
}

@Article{Cousot1992Abstract,
  author =       "Patrick Cousot and Radhia Cousot",
  citeulike-article-id = "4253516",
  citeulike-linkout-0 = "http://dx.doi.org/10.1093/logcom/2.4.511",
  citeulike-linkout-1 = "http://logcom.oxfordjournals.org/cgi/content/abstract/2/4/511",
  date-added =   "2010-07-19 06:01:12",
  day =          "1",
  journal =      "J Logic Computation",
  month =        aug,
  number =       "4",
  priority =     "2",
  title =        "Abstract Interpretation Frameworks",
  volume =       "2",
  x-abstract =   "We introduce abstract interpretation frameworks which
                 are variations on the archetypal framework using Galois
                 connections between concrete and abstract semantics,
                 widenings and narrowings and are obtained by relaxation
                 of the original hypotheses. We consider various ways of
                 establishing the correctness of an abstract
                 interpretation depending on how the relation between
                 the concrete and abstract semantics is denned. We
                 insist upon those correspondences allowing for the
                 inducing of the approximate abstract semantics from the
                 concrete one. Furthermore we study various notions of
                 widening and narrowing as a means of obtaining
                 convergence in the iterations used in abstract
                 interpretation. 10.1093/logcom/2.4.511",
  x-doi =        "10.1093/logcom/2.4.511",
  x-url =        "http://dx.doi.org/10.1093/logcom/2.4.511",
  xpages =       "511--547",
  year =         "1992",
}

@InProceedings{DBLP:conf/esop/VardoulakisS10,
  author =       "Dimitrios Vardoulakis and Olin Shivers",
  booktitle =    "European Symposium on Programming (ESOP)",
  citeulike-article-id = "6865796",
  date-added =   "2010-07-18 16:37:39",
  priority =     "0",
  publisher =    "Springer",
  title =        "{CFA2}: a {C}ontext-{F}ree {A}pproach to
                 {C}ontrol-{F}low {A}nalysis",
  volume =       "6012",
  x-issn =       "0302-9743",
  x-series =     "LNCS",
  xpages =       "570--589",
  year =         "2010",
}

@InProceedings{Ong2006ModelChecking,
  author =       "C. H. Luke Ong",
  booktitle =    "21st Annual IEEE Symposium on Logic in Computer
                 Science (LICS'06)",
  citeulike-article-id = "6941050",
  citeulike-linkout-0 = "http://doi.ieeecomputersociety.org/10.1109/LICS.2006.38",
  citeulike-linkout-1 = "http://dx.doi.org/10.1109/lics.2006.38",
  citeulike-linkout-2 = "http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1691219",
  date-added =   "2010-07-18 16:08:34",
  journal =      "Logic in Computer Science, Symposium on",
  location =     "Seattle, WA, USA",
  priority =     "2",
  publisher =    "IEEE",
  title =        "On {Model-Checking} Trees Generated by {Higher-Order}
                 Recursion Schemes",
  x-abstract =   "We prove that the modal mu-calculus model-checking
                 problem for (ranked and ordered) node-labelled trees
                 that are generated by order-n recursion schemes
                 (whether safe or not, and whether homogeneously typed
                 or not) is {n-EXPTIME} complete, for every nges0. It
                 follows that the monadic second-order theories of these
                 trees are decidable. There are three major ingredients.
                 The first is a certain transference principle from the
                 tree generated by the scheme - the value tree - to an
                 auxiliary computation tree, which is itself a tree
                 generated by a related order-0 recursion scheme
                 (equivalently, a regular tree). Using innocent game
                 semantics in the sense of Hyland and Ong, we establish
                 a strong correspondence between paths in the value tree
                 and traversals in the computation tree. This allows us
                 to prove that a given alternating parity tree automaton
                 ({APT}) has an (accepting) run-tree over the value tree
                 iff it has an (accepting) traversal-tree over the
                 computation tree. The second ingredient is the
                 simulation of an (accepting) traversal-tree by a
                 certain set of annotated paths over the computation
                 tree; we introduce traversal-simulating {APT} as a
                 recognising device for the latter. Finally, for the
                 complexity result, we prove that traversal-simulating
                 {APT} enjoy a succinctness property: for deciding
                 acceptance, it is enough to consider run-trees that
                 have a reduced branching factor. The desired bound is
                 then obtained by analysing the complexity of solving an
                 associated (finite) acceptance parity game",
  x-address =    "Los Alamitos, CA, USA",
  x-doi =        "10.1109/lics.2006.38",
  x-isbn =       "0-7695-2631-4",
  x-issn =       "1043-6871",
  x-series =     "LICS",
  x-url =        "http://dx.doi.org/10.1109/lics.2006.38",
  xpages =       "81--90",
  year =         "2006",
}

@InProceedings{Findler2002Contracts,
  author =       "Robert B. Findler and Matthias Felleisen",
  booktitle =    "ICFP '02: Proceedings of the seventh ACM SIGPLAN
                 International Conference on Functional Programming",
  citeulike-article-id = "1362",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=581484",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/581478.581484",
  date-added =   "2010-07-09 01:23:47",
  location =     "Pittsburgh, PA, USA",
  month =        sep,
  priority =     "0",
  publisher =    "ACM",
  title =        "Contracts for higher-order functions",
  x-abstract =   "Assertions play an important role in the construction
                 of robust software. Their use in programming languages
                 dates back to the 1970s. Eiffel, an object-oriented
                 programming language, wholeheartedly adopted assertions
                 and developed the {"}Design by Contract{"} philosophy.
                 Indeed, the entire object-oriented community recognizes
                 the value of assertion-based contracts on {methods.In}
                 contrast, languages with higher-order functions do not
                 support assertion-based contracts. Because predicates
                 on functions are, in general, undecidable, specifying
                 such predicates appears to be meaningless. Instead, the
                 functional languages community developed type systems
                 that statically approximate interesting {predicates.In}
                 this paper, we show how to support higher-order
                 function contracts in a theoretically well-founded and
                 practically viable manner. Specifically, we introduce
                 λ con , a typed lambda calculus with assertions for
                 higher-order functions. The calculus models the
                 assertion monitoring system that we employ in
                 {DrScheme}. We establish basic properties of the model
                 (type soundness, etc.) and illustrate the usefulness of
                 contract checking with examples from {DrScheme}'s code
                 {base.We} believe that the development of an assertion
                 system for higher-order functions serves two purposes.
                 On one hand, the system has strong practical potential
                 because existing type systems simply cannot express
                 many assertions that programmers would like to state.
                 On the other hand, an inspection of a large base of
                 invariants may provide inspiration for the direction of
                 practical future type system research.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/581478.581484",
  x-isbn =       "1-58113-487-8",
  x-issn =       "0362-1340",
  x-series =     "ICFP",
  x-url =        "http://dx.doi.org/10.1145/581478.581484",
  xpages =       "48--59",
  year =         "2002",
}

@InProceedings{Meunier2006Modular,
  author =       "Philippe Meunier and Robert B. Findler and Matthias
                 Felleisen",
  booktitle =    "POPL '06: Conference record of the 33rd ACM
                 SIGPLAN-SIGACT Symposium on Principles of Programming
                 Languages",
  citeulike-article-id = "524959",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1111057",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1111037.1111057",
  comment =      "POPL '06",
  date-added =   "2010-07-08 22:56:31",
  location =     "Charleston, South Carolina, USA",
  month =        jan,
  priority =     "0",
  publisher =    "ACM",
  title =        "Modular set-based analysis from contracts",
  x-abstract =   "In {PLT} Scheme, programs consist of modules with
                 contracts. The latter describe the inputs and outputs
                 of functions and objects via predicates. A run-time
                 system enforces these predicates; if a predicate fails,
                 the enforcer raises an exception that blames a specific
                 module with an explanation of the {fault.In} this
                 paper, we show how to use such module contracts to turn
                 set-based analysis into a fully modular parameterized
                 analysis. Using this analysis, a static debugger can
                 indicate for any given contract check whether the
                 corresponding predicate is always satisfied, partially
                 satisfied, or (potentially) completely violated. The
                 static debugger can also predict the source of
                 potential errors, i.e., it is sound with respect to the
                 blame assignment of the contract system.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1111037.1111057",
  x-isbn =       "1-59593-027-2",
  x-series =     "POPL",
  x-url =        "http://dx.doi.org/10.1145/1111037.1111057",
  xpages =       "218--231",
  year =         "2006",
}

@PhdThesis{Klop1980Combinatory,
  author =       "Jan W. Klop",
  citeulike-article-id = "7333194",
  date-added =   "2010-06-17 03:34:30",
  priority =     "2",
  school =       "Utrecht University",
  title =        "Combinatory Reduction Systems",
  year =         "1980",
}

@InCollection{Mellies2005Axiomatic,
  author =       "Paul-Andre Mellies",
  booktitle =    "Processes, Terms and Cycles: Steps on the Road to
                 Infinity: Essays Dedicated to Jan Willem Klop on the
                 Occasion of his 60th Birthday",
  citeulike-article-id = "7333181",
  citeulike-linkout-0 = "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.59.2331",
  date-added =   "2010-06-17 03:06:11",
  priority =     "2",
  title =        "Axiomatic Rewriting Theory {I} - {A} Diagrammatic
                 Standardization Theorem",
  x-abstract =   "Machine translation \#\# -calculus interpretation \#\#
                 -calculus Formally, the -calculus contains two classes
                 of objects: terms and substitutions. Terms are written
                 in the de Bruijn notation.",
  x-url =        "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.59.2331",
  xpages =       "554--638",
  year =         "2005",
}

@InProceedings{Gonthier1992Abstract,
  author =       "Georges Gonthier and Jean-Jacques L\'{e}vy and
                 Paul-Andr\'{e} Melli\`{e}s",
  booktitle =    "Proceedings of the Seventh Annual IEEE Symposium on
                 Logic in Computer Science",
  citeulike-article-id = "7332923",
  date-added =   "2010-06-16 21:59:09",
  month =        jun,
  priority =     "0",
  title =        "An Abstract Standardisation Theorem",
  xpages =       "72--81",
  year =         "1992",
}

@Article{Takahashi1995Parallel,
  author =       "M. Takahashi",
  citeulike-article-id = "7018539",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=207191",
  citeulike-linkout-1 = "http://dx.doi.org/10.1006/inco.1995.1057",
  date-added =   "2010-06-16 20:55:21",
  journal =      "Information and Computation",
  month =        apr,
  number =       "1",
  priority =     "0",
  publisher =    "Academic Press, Inc.",
  title =        "Parallel Reductions in \(\{lambda\)-Calculus}",
  volume =       "118",
  x-abstract =   "The notion of parallel reduction is extracted from the
                 simple proof of the {Church-Rosser} theorem by Tait and
                 {Martin-L\"{o}f}. Intuitively, this means to reduce a
                 number of redexes (existing in a λ-term)
                 simultaneously. Thus in the case of β-reduction the
                 effect of a parallel reduction is same as that of a
                 {"}complete development{"} which is defined by using
                 {"}residuals{"} of β-redexes. A nice feature of
                 parallel reduction, however, is that it can be defined
                 directly by induction on the structure of λ-terms
                 (without referring to residuals or other auxiliary
                 notions), and the inductive definition provides us
                 exactly what we need in proving the theorem
                 inductively. Moreover, the notion can be easily
                 extended to other reduction systems such as Girard′s
                 second-order system F and G{\"{o}}del′s system T . In
                 this paper, after reevaluating the significance of the
                 notion of parallel reduction in
                 {Tait-and-Martin}-L{\"{o}}f type proofs of the
                 {Church-Rosser} theorems, we show that the notion of
                 parallel reduction is also useful in giving short and
                 direct proofs of some other fundamental theorems in
                 reduction theory of λ-calculus; among others, we give
                 such simple proofs of the standardization theorem for
                 β-reduction (a special case of which is known as the
                 leftmost reduction theorem for β-reduction), the
                 quasi-leftmost reduction theorem for β-reduction, the
                 postponement theorem of η-reduction (in
                 βη-reduction), and the leftmost reduction theorem for
                 βη-reduction.",
  x-address =    "Duluth, MN, USA",
  x-doi =        "10.1006/inco.1995.1057",
  x-issn =       "08905401",
  x-url =        "http://dx.doi.org/10.1006/inco.1995.1057",
  xpages =       "120--127",
  year =         "1995",
}

@TechReport{Crary2009Simple,
  author =       "Karl Crary",
  citeulike-article-id = "7332802",
  date-added =   "2010-06-16 20:42:43",
  institution =  "CMU-CS-09-137",
  month =        jun,
  priority =     "0",
  title =        "A Simple Proof of {Call-by-Value} Standardization",
  year =         "2009",
}

@Article{Plotkin1975Callbyname,
  author =       "Gordon Plotkin",
  citeulike-article-id = "467090",
  citeulike-linkout-0 = "http://dx.doi.org/10.1016/0304-3975(75)90017-1",
  citeulike-linkout-1 = "http://www.sciencedirect.com/science/article/B6V1G-46922HH-3/2/a20b91fda9c99ea8a205f1b1d03237ae",
  date-added =   "2010-06-16 20:04:14",
  journal =      "Theoretical Computer Science",
  month =        dec,
  number =       "2",
  priority =     "0",
  title =        "Call-by-name, call-by-value and the
                 \(\lambda\)-calculus",
  volume =       "1",
  x-abstract =   "This paper examines the old question of the
                 relationship between {ISWIM} and the \^{I}»-calculus,
                 using the distinction between call-by-value and
                 call-by-name. It is held that the relationship should
                 be mediated by a standardisation theorem. Since this
                 leads to difficulties, a new \^{I}»-calculus is
                 introduced whose standardisation theorem gives a good
                 correspondence with {ISWIM} as given by the {SECD}
                 machine, but without the letrec feature. Next a
                 call-by-name variant of {ISWIM} is introduced which is
                 in an analogous correspondence withthe usual
                 \^{I}»-calculus. The relation between call-by-value
                 and call-by-name is then studied by giving simulations
                 of each language by the other and interpretations of
                 each calculus in the other. These are obtained as
                 another application of the continuation technique. Some
                 emphasis is placed throughout on the notion of
                 operational equality (or contextual equality). If terms
                 can be proved equal in a calculus they are
                 operationally equal in the corresponding language.
                 Unfortunately, operational equality is not preserved by
                 either of the simulations.",
  x-doi =        "10.1016/0304-3975(75)90017-1",
  x-issn =       "03043975",
  x-url =        "http://dx.doi.org/10.1016/0304-3975(75)90017-1",
  xpages =       "125--159",
  year =         "1975",
}

@Book{Curry1958Combinatory,
  author =       "Haskell B. Curry and Robert Feys",
  citeulike-article-id = "7332754",
  date-added =   "2010-06-16 19:55:38",
  priority =     "2",
  publisher =    "North-Holland",
  title =        "Combinatory Logic",
  volume =       "1",
  year =         "1958",
}

@Article{Mitschke1979Standardization,
  author =       "Gerd Mitschke",
  citeulike-article-id = "7332725",
  date-added =   "2010-06-16 19:17:33",
  journal =      "Z. Math. Logik Grundlang. Math.",
  priority =     "2",
  title =        "The standardization theorem for the
                 \(\lambda\)-calculus",
  volume =       "25",
  xpages =       "29--31",
  year =         "1979",
}

@InCollection{Xi1997Upper,
  author =       "Hongwei Xi",
  booktitle =    "Computational Logic and Proof Theory",
  citeulike-article-id = "7331063",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/3-540-63385-5\_54",
  citeulike-linkout-1 = "http://www.springerlink.com/content/83889w8805530176",
  date-added =   "2010-06-16 18:07:11",
  priority =     "0",
  title =        "Upper bounds for standardizations and an application",
  x-abstract =   "We first present a new proof for the standardization
                 theorem, a fundamental theorem in -calculus. Since our
                 proof is largely built upon structural induction on
                 lambda terms, we can extract some bounds for the number
                 of -reduction steps in the standard -reduction
                 sequences obtained from transforming a given -reduction
                 sequences. This result sharpens the standardization
                 theorem. As an application, we establish a
                 super-exponential bound for the lengths of -reduction
                 sequences from any given simply typed -terms.",
  x-doi =        "10.1007/3-540-63385-5\_54",
  x-url =        "http://dx.doi.org/10.1007/3-540-63385-5\_54",
  xpages =       "335--348",
  year =         "1997",
}

@InProceedings{Might2010Resolving,
  author =       "Matthew Might and Yannis Smaragdakis and David Van{
                 }Horn",
  booktitle =    "PLDI '10: Proceedings of the 2010 ACM SIGPLAN
                 Conference on Programming Language Design and
                 Implementation",
  citeulike-article-id = "7329790",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1806596.1806631",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1806596.1806631",
  date-added =   "2010-06-16 15:16:45",
  location =     "Toronto, Ontario, Canada",
  priority =     "0",
  publisher =    "ACM",
  title =        "Resolving and exploiting the {\(k\)}-{CFA} paradox:
                 illuminating functional vs. object-oriented program
                 analysis",
  x-abstract =   "Low-level program analysis is a fundamental problem,
                 taking the shape of {"}flow analysis{"} in functional
                 languages and {"}points-to{"} analysis in imperative
                 and object-oriented languages. Despite the
                 similarities, the vocabulary and results in the two
                 communities remain largely distinct, with limited
                 cross-understanding. One of the few links is Shivers's
                 {k-CFA} work, which has advanced the concept of
                 {"}context-sensitive analysis{"} and is widely known in
                 both communities. Recent results indicate that the
                 relationship between the functional and object-oriented
                 incarnations of {k-CFA} is not as well understood as
                 thought. Van Horn and Mairson proved {k-CFA} for k ≥
                 1 to be {EXPTIME}-complete; hence, no polynomial-time
                 algorithm can exist. Yet, there are several
                 polynomial-time formulations of context-sensitive
                 points-to analyses in object-oriented languages. Thus,
                 it seems that functional {k-CFA} may actually be a
                 profoundly different analysis from object-oriented
                 {k-CFA}. We resolve this paradox by showing that the
                 exact same specification of {k-CFA} is polynomial-time
                 for object-oriented languages yet exponential-time for
                 functional ones: objects and closures are subtly
                 different, in a way that interacts crucially with
                 context-sensitivity and complexity. This illumination
                 leads to an immediate payoff: by projecting the
                 object-oriented treatment of objects onto closures, we
                 derive a polynomial-time hierarchy of context-sensitive
                 {CFAs} for functional programs.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1806596.1806631",
  x-isbn =       "978-1-4503-0019-3",
  x-series =     "",
  x-url =        "http://dx.doi.org/10.1145/1806596.1806631",
  xpages =       "305--315",
  year =         "2010",
}

@Article{ariola1997,
  author =       "Zena M. Ariola and Matthias Felleisen",
  citeulike-article-id = "6905427",
  citeulike-linkout-0 = "http://journals.cambridge.org/action/displayAbstract?fromPage=online\&aid=44089",
  citeulike-linkout-1 = "http://dx.doi.org/10.1017/s0956796897002724",
  date-added =   "2010-06-16 15:12:29",
  journal =      "Journal of Functional Programming",
  number =       "03",
  priority =     "0",
  title =        "The call-by-need lambda calculus",
  volume =       "7",
  x-abstract =   "Plotkin (1975) showed that the lambda calculus is a
                 good model of the evaluation process for call-by-name
                 functional programs. Reducing programs to constants or
                 lambda abstractions according to the leftmost-outermost
                 strategy exactly mirrors execution on an abstract
                 machine like Landin\&apos;s {SECD} machine. The
                 machine-based evaluator returns a constant or the token
                 closure if and only if the standard reduction sequence
                 starting at the same program will end in the same
                 constant or in some lambda abstraction. However, the
                 calculus does not capture the sharing of the evaluation
                 of arguments that lazy implementations use to speed up
                 the execution. More precisely, a lazy implementation
                 evaluates procedure arguments only when needed and then
                 only once. All other references to the formal procedure
                 parameter re-use the value of the first argument
                 evaluation. The mismatch between the operational
                 semantics of the lambda calculus and the actual
                 behavior of the prototypical implementation is a major
                 obstacle for compiler writers. Unlike implementors of
                 the leftmost-outermost strategy or of a call-by-value
                 language, implementors of lazy systems cannot easily
                 explain the behavior of their evaluator in terms of
                 source level syntax. Hence, they often cannot explain
                 why a certain syntactic transformation
                 \&lsquo;works\&rsquo; and why another doesn\&apos;t. In
                 this paper we develop an equational characterization of
                 the most popular lazy implementation technique \&ndash;
                 traditionally called \&lsquo;call-by-need\&rsquo;
                 \&ndash; and prove it correct with respect to the
                 original lambda calculus. The theory is a strictly
                 smaller theory than Plotkin\&apos;s call-by-name lambda
                 calculus. Immediate applications of the theory concern
                 the correctness proofs of a number of implementation
                 strategies, e.g. the call-by-need continuation passing
                 transformation and the realization of sharing via
                 assignments. Some of this material first appeared in a
                 paper presented at the 1995 {ACM} Conference on the
                 Principles of Programming Languages. The paper was a
                 joint effort with Maraist, Odersky and Wadler, who had
                 independently developed a different equational
                 characterization of call-by-need. We contrast our work
                 with that of Maraist et al. in the body of this paper
                 where appropriate.",
  x-doi =        "10.1017/s0956796897002724",
  x-url =        "http://dx.doi.org/10.1017/s0956796897002724",
  xpages =       "265--301",
  year =         "1997",
}

@Article{Alur2005Analysis,
  author =       "Rajeev Alur and Michael Benedikt and Kousha Etessami
                 and Patrice Godefroid and Thomas Reps and Mihalis
                 Yannakakis",
  citeulike-article-id = "902085",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1075382.1075387",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1075382.1075387",
  date-added =   "2010-06-10 20:43:44",
  journal =      "ACM Trans. Program. Lang. Syst.",
  month =        jul,
  number =       "4",
  priority =     "0",
  publisher =    "ACM",
  title =        "Analysis of recursive state machines",
  volume =       "27",
  x-abstract =   "Recursive state machines ({RSMs}) enhance the power of
                 ordinary state machines by allowing vertices to
                 correspond either to ordinary states or to potentially
                 recursive invocations of other state machines. {RSMs}
                 can model the control flow in sequential imperative
                 programs containing recursive procedure calls. They can
                 be viewed as a visual notation extending
                 Statecharts-like hierarchical state machines, where
                 concurrency is disallowed but recursion is allowed.
                 They are also related to various models of pushdown
                 systems studied in the verification and program
                 analysis {communities.After} introducing {RSMs} and
                 comparing their expressiveness with other models, we
                 focus on whether verification can be efficiently
                 performed for {RSMs}. Our first goal is to examine the
                 verification of linear time properties of {RSMs}. We
                 begin this study by dealing with two key components for
                 algorithmic analysis and model checking, namely,
                 reachability (Is a target state reachable from initial
                 states?) and cycle detection (Is there a reachable
                 cycle containing an accepting state?). We show that
                 both these problems can be solved in time O ( n
                 \&theta; 2 ) and space O ( n \&theta;), where n is the
                 size of the recursive machine and \&theta; is the
                 maximum, over all component state machines, of the
                 minimum of the number of entries and the number of
                 exits of each component. From this, we easily derive
                 algorithms for linear time temporal logic model
                 checking with the same complexity in the model. We then
                 turn to properties in the branching time logic {CTL}*,
                 and again demonstrate a bound linear in the size of the
                 state machine, but only for the case of {RSMs} with a
                 single exit node.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1075382.1075387",
  x-issn =       "0164-0925",
  x-url =        "http://dx.doi.org/10.1145/1075382.1075387",
  xpages =       "786--818",
  year =         "2005",
}

@Article{Besson2001Model,
  author =       "Fr\'{e}d\'{e}ric Besson and Thomas Jensen and Daniel
                 Le M\'{e}tayer and Tommy Thorn",
  citeulike-article-id = "801509",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=514705",
  date-added =   "2010-04-02 14:45:02",
  journal =      "J. Comput. Secur.",
  month =        jan,
  number =       "3",
  priority =     "2",
  publisher =    "IOS Press",
  title =        "Model checking security properties of control flow
                 graphs",
  volume =       "9",
  x-abstract =   "A fundamental problem in software-based security is
                 whether local security checks inserted into the code
                 are sufficient to implement a global security property.
                 This article introduces a formalism based on a
                 linear-time temporal logic for specifying global
                 security properties pertaining to the control flow of
                 the program, and illustrates its expressive power with
                 a number of existing properties. We define a
                 minimalistic, security-dedicated program model that
                 only contains procedure call and run-time security
                 checks and propose an automatic method for verifying
                 that an implementation using local security checks
                 satisfies a global security property. We then show how
                 to instantiate the framework to the security
                 architecture of Java 2 based on stack inspection and
                 privileged method calls.",
  x-address =    "Amsterdam, The Netherlands, The Netherlands",
  x-issn =       "0926-227X",
  x-url =        "http://portal.acm.org/citation.cfm?id=514705",
  xpages =       "217--250",
  year =         "2001",
}

@InProceedings{Bartoletti2001Static,
  author =       "Massimo Bartoletti and Pierpaolo Degano and Gianluigi
                 Ferrari",
  booktitle =    "In Proceedings of International Workshop on
                 Concurrency and Coordination, Electronic Notes in
                 Theoretical Computer Science",
  citeulike-article-id = "6938151",
  citeulike-linkout-0 = "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.105.7955",
  date-added =   "2010-04-01 04:26:45",
  priority =     "2",
  title =        "Static analysis for stack inspection",
  volume =       "54",
  x-abstract =   "We propose two control flow analyses for the Java
                 bytecode. They safely approximate the set of
                 permissions granted/denied to code at run-time. This
                 static information helps optimizing the implementation
                 of the stack inspection algorithm. 1",
  x-url =        "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.105.7955",
  year =         "2001",
}

@InProceedings{Besson2002Secure,
  author =       "Fr\'{e}d\'{e}ric Besson and Thomas de Grenier de
                 Latour and Thomas Jensen",
  booktitle =    "PPDP '02: Proceedings of the 4th ACM SIGPLAN
                 International Conference on Principles and Practice of
                 Declarative Programming",
  citeulike-article-id = "6938126",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=571157.571166",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/571157.571166",
  date-added =   "2010-04-01 03:58:03",
  location =     "Pittsburgh, PA, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "Secure calling contexts for stack inspection",
  x-abstract =   "Stack inspection is a mechanism for programming secure
                 applications by which a method can obtain information
                 from the call stack about the code that (directly or
                 indirectly) invoked it. This mechanism plays a
                 fundamental role in the security architecture of Java
                 and the .{NET} Common Language Runtime. A central
                 problem with stack inspection is to determine to what
                 extent the <i>local</i> checks inserted into the code
                 are sufficient to guarantee that a <i>global</i>
                 security property is enforced. In this paper, we
                 present a technique for inferring a <i>secure calling
                 context</i> for a method. By a secure calling context
                 we mean a pre-condition on the call stack sufficient
                 for guaranteeing that execution of the method will not
                 violate a given global property. This is particularly
                 useful for annotating library code in order to avoid
                 having to re-analyse libraries for every new
                 application. The technique is a constraint based static
                 program analysis implemented via fixed point iteration
                 over an abstract domain of linear temporal logic
                 properties.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/571157.571166",
  x-isbn =       "1-58113-528-9",
  x-url =        "http://dx.doi.org/10.1145/571157.571166",
  xpages =       "76--87",
  year =         "2002",
}

@InProceedings{Skalka2000Static,
  author =       "Christian Skalka and Scott Smith",
  booktitle =    "ICFP '00: Proceedings of the fifth ACM SIGPLAN
                 International Conference on Functional Programming",
  citeulike-article-id = "558733",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=351244",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/351240.351244",
  date-added =   "2010-04-01 03:56:28",
  month =        sep,
  number =       "",
  priority =     "2",
  publisher =    "ACM",
  title =        "Static enforcement of security with types",
  volume =       "",
  x-abstract =   "A number of security systems for programming languages
                 have recently appeared, including systems for enforcing
                 some form of access control . The Java {JDK} 1.2
                 security architecture is one such system that is widely
                 studied and used. While the architecture has many
                 appealing features, access control checks are all
                 implemented via dynamic method calls. This is a highly
                 non-declarative form of specification which is hard to
                 read, and which leads to additional run-time overhead.
                 In this paper, we present a novel security type system
                 that enforces the same security guarantees as Java
                 Stack Inspection, but via a static type system with no
                 additional run-time checks. The system allows security
                 properties of programs to be clearly expressed within
                 the types themselves. We also define and prove correct
                 an inference algorithm for security types, meaning that
                 the system has the potential to be layered on top of
                 the existing Java architecture, without requiring new
                 syntax.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/351240.351244",
  x-isbn =       "1-58113-202-6",
  x-issn =       "0362-1340",
  x-url =        "http://dx.doi.org/10.1145/351240.351244",
  xpages =       "34--45",
  year =         "2000",
}

@Article{Fournet2003Stack,
  author =       "C\'{e}dric Fournet and Andrew D. Gordon",
  citeulike-article-id = "6930267",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=641909.641912",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/641909.641912",
  date-added =   "2010-03-30 17:11:43",
  journal =      "ACM Trans. Program. Lang. Syst.",
  number =       "3",
  priority =     "2",
  publisher =    "ACM",
  title =        "Stack inspection: Theory and variants",
  volume =       "25",
  x-abstract =   "Stack inspection is a security mechanism implemented
                 in runtimes such as the {JVM} and the {CLR} to
                 accommodate components with diverse levels of trust.
                 Although stack inspection enables the fine-grained
                 expression of access control policies, it has rather a
                 complex and subtle semantics. We present a formal
                 semantics and an equational theory to explain how stack
                 inspection affects program behavior and code
                 optimisations. We discuss the security properties
                 enforced by stack inspection, and also consider
                 variants with stronger, simpler properties.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/641909.641912",
  x-issn =       "0164-0925",
  x-url =        "http://dx.doi.org/10.1145/641909.641912",
  xpages =       "360--399",
  year =         "2003",
}

@Book{1987Abstract,
  citeulike-article-id = "6900846",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=576316",
  date-added =   "2010-03-24 14:50:55",
  priority =     "2",
  publisher =    "Prentice Hall Professional Technical Reference",
  title =        "Abstract Interpretation of Declarative Languages",
  x-editor =     "Abramsky, Samson and Hankin, Chris",
  x-isbn =       "0470209712",
  x-url =        "http://portal.acm.org/citation.cfm?id=576316",
  year =         "1987",
}

@Article{Jones2007Flow,
  author =       "N. Jones and N. Andersen",
  citeulike-article-id = "6900845",
  citeulike-linkout-0 = "http://dx.doi.org/10.1016/j.tcs.2006.12.030",
  date-added =   "2010-03-24 14:49:36",
  day =          "01",
  journal =      "Theoretical Computer Science",
  month =        may,
  number =       "1-3",
  priority =     "2",
  title =        "Flow analysis of lazy higher-order functional
                 programs",
  volume =       "375",
  x-abstract =   "In recent years much interest has been shown in a
                 class of functional languages including {HASKELL}, lazy
                 {ML}, {SASL}/{KRC}/{MIRANDA}, {ALFL}, {ORWELL}, and
                 {PONDER}. It has been seen that their expressive power
                 is great, programs are compact, and program
                 manipulation and transformation is much easier than
                 with imperative languages or more traditional
                 applicative ones. Common characteristics: they are
                 purely applicative, manipulate trees as data objects,
                 use pattern matching both to determine control flow and
                 to decompose compound data structures, and use a ”
                 lazy” evaluation strategy. In this paper we describe
                 a technique for data flow analysis of programs in this
                 class by safely approximating the behavior of a certain
                 class of term rewriting systems. In particular we
                 obtain ” safe” descriptions of program inputs,
                 outputs and intermediate results by regular sets of
                 trees. Potential applications include optimization,
                 strictness analysis and partial evaluation. The
                 technique improves earlier work because of its
                 applicability to programs with higher-order functions,
                 and with either eager or lazy evaluation. The technique
                 addresses the call-by-name aspect of laziness, but not
                 memoization.",
  x-doi =        "10.1016/j.tcs.2006.12.030",
  x-issn =       "03043975",
  x-url =        "http://dx.doi.org/10.1016/j.tcs.2006.12.030",
  xpages =       "120--136",
  year =         "2007",
}

@InCollection{Faxen1995Optimizing,
  author =       "Karl Fax\'{e}n",
  booktitle =    "Static Analysis",
  citeulike-article-id = "6900824",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/3-540-60360-3\_37",
  citeulike-linkout-1 = "http://www.springerlink.com/content/p041749341578266",
  date-added =   "2010-03-24 14:45:10",
  priority =     "2",
  title =        "Optimizing lazy functional programs using flow
                 inference",
  x-abstract =   "Nonstrict higher order functional programming
                 languages are notorious for their low run time
                 efficiency. Optimizations based on flow analysis, which
                 determines for each variable x in a program which
                 expressions could have originated the value of x, can
                 improve the situation by removing redundant eval and
                 thunk operations, avoiding thunk updates, and allowing
                 the use of unboxed representations of some data. We
                 formulate flow analysis as an inference problem in a
                 type system built using type inclusion constraints and
                 an algorithm for solving these constraints is also
                 given.",
  x-doi =        "10.1007/3-540-60360-3\_37",
  x-url =        "http://dx.doi.org/10.1007/3-540-60360-3\_37",
  xpages =       "136--153",
  year =         "1995",
}

@InProceedings{Cardelli1984Compiling,
  author =       "Luca Cardelli",
  booktitle =    "LISP and Functional Programming",
  citeulike-article-id = "82599",
  citeulike-linkout-0 = "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.43.208",
  date-added =   "2010-03-22 19:32:22",
  priority =     "2",
  title =        "Compiling a Functional Language",
  x-abstract =   "Machine The Functional Abstract Machine (Fam) is a
                 stack machine designed to support functional languages
                 on large address space computers. It can be considered
                 an {SECD} machine [Landin 64] which has been optimized
                 to allow very fast function application and the use of
                 true stacks (as opposed to linked lists). This section
                 contains a brief overview of the Fam; which is fully
                 described in [Cardelli 83]. The machine supports
                 functional objects (closures, which are dynamically
                 allocated and garbage ...",
  x-url =        "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.43.208",
  xpages =       "208--217",
  year =         "1984",
}

@Book{Appel1991Compiling,
  author =       "Andrew W. Appel",
  citeulike-article-id = "2429806",
  citeulike-linkout-0 = "http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0521416957",
  citeulike-linkout-1 = "http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0521416957",
  citeulike-linkout-2 = "http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0521416957",
  citeulike-linkout-3 = "http://www.amazon.jp/exec/obidos/ASIN/0521416957",
  citeulike-linkout-4 = "http://www.amazon.co.uk/exec/obidos/ASIN/0521416957/citeulike00-21",
  citeulike-linkout-5 = "http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0521416957",
  citeulike-linkout-6 = "http://www.worldcat.org/isbn/0521416957",
  citeulike-linkout-7 = "http://books.google.com/books?vid=ISBN0521416957",
  citeulike-linkout-8 = "http://www.amazon.com/gp/search?keywords=0521416957\&index=books\&linkCode=qs",
  citeulike-linkout-9 = "http://www.librarything.com/isbn/0521416957",
  date-added =   "2010-03-22 15:12:48",
  day =          "29",
  howpublished = "Hardcover",
  month =        nov,
  priority =     "2",
  publisher =    "Cambridge University Press",
  title =        "Compiling with Continuations",
  x-abstract =   "{This book shows how continuation-passing style is
                 used as an intermediate representation to perform
                 optimizations and program transformations.
                 Continuations can be used to compile most programming
                 languages. The method is illustrated in a compiler for
                 the programming language Standard ML. Prior knowledge
                 of ML, however, is not necessary, as the author
                 carefully explains each concept as it arises. This is
                 the first book to show how concepts from the theory of
                 programming languages can be applied to the production
                 of practical optimizing compilers for modern languages
                 like ML. All the details of compiling are covered,
                 including the interface to a runtime system and garbage
                 collector.}",
  x-isbn =       "0521416957",
  x-url =        "http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0521416957",
  year =         "1991",
}

@InProceedings{Danvy-al:FLOPS10,
  author =       "Olivier Danvy and Kevin Millikin and Johan Munk and
                 Ian Zerny",
  booktitle =    "Functional and Logic Programming, 10th International
                 Symposium, FLOPS 2010",
  citeulike-article-id = "6857295",
  comment =      "To appear",
  date-added =   "2010-03-16 15:12:25",
  month =        apr,
  priority =     "2",
  publisher =    "Springer",
  title =        "Defunctionalized Interpreters for {Call-by-Need}
                 Evaluation",
  x-address =    "Sendai, Japan",
  x-editor =     "Blume, Matthias and Vidal, German",
  x-series =     "Lecture Notes in Computer Science",
  year =         "2010",
}

@Article{Krivine2007Callbyname,
  author =       "Jean-Louis Krivine",
  citeulike-article-id = "6400453",
  citeulike-linkout-0 = "http://dx.doi.org/10.1007/s10990-007-9018-9",
  citeulike-linkout-1 = "http://www.springerlink.com/content/1736u87071124110",
  date-added =   "2010-03-16 02:29:15",
  day =          "1",
  journal =      "Higher-Order and Symbolic Computation",
  month =        sep,
  number =       "3",
  priority =     "2",
  title =        "A call-by-name lambda-calculus machine",
  volume =       "20",
  x-abstract =   "Abstract\&nbsp;\&nbsp; We present a particularly
                 simple lazy lambda-calculus machine, which was
                 introduced twenty-five years ago. It has been, since,
                 used and implemented by several authors, but remained
                 unpublished. We also build an extension, with a control
                 instruction and continuations. This machine was
                 conceived in order to execute programs obtained from
                 mathematical proofs, by means of the {Curry-Howard}
                 (also known as ” proof-program”) correspondence.
                 The control instruction corresponds to the axiom of
                 excluded middle.",
  x-doi =        "10.1007/s10990-007-9018-9",
  x-issn =       "1388-3690",
  x-url =        "http://dx.doi.org/10.1007/s10990-007-9018-9",
  xpages =       "199--207",
  year =         "2007",
}

@Unpublished{Krivine1985Un,
  author =       "Jean-Louis Krivine",
  citeulike-article-id = "6855687",
  date-added =   "2010-03-16 02:27:50",
  priority =     "2",
  title =        "Un interpr\'{e}teur du lambda-calcul",
  year =         "1985",
}

@Article{Ager2004Functional,
  author =       "Mads S. Ager and Olivier Danvy and Jan Midtgaard",
  citeulike-article-id = "2917380",
  citeulike-linkout-0 = "http://dx.doi.org/10.1016/j.ipl.2004.02.012",
  citeulike-linkout-1 = "http://www.sciencedirect.com/science/article/B6V0F-4C47N5K-1/1/fc45ae0b61f9fcd63d1600e9061b28cb",
  date-added =   "2010-03-16 02:18:52",
  day =          "15",
  journal =      "Information Processing Letters",
  month =        jun,
  number =       "5",
  priority =     "2",
  title =        "A functional correspondence between call-by-need
                 evaluators and lazy abstract machines",
  volume =       "90",
  x-abstract =   "We bridge the gap between compositional evaluators and
                 abstract machines for the lambda-calculus, using
                 closure conversion, transformation into
                 continuation-passing style, and defunctionalization of
                 continuations. This article is a followup of our
                 article at {PPDP} 2003, where we consider call by name
                 and call by value. Here, however, we consider call by
                 need. We derive a lazy abstract machine from an
                 ordinary call-by-need evaluator that threads a heap of
                 updatable cells. In this resulting abstract machine,
                 the continuation fragment for updating a heap cell
                 naturally appears as an 'update marker', an
                 implementation technique that was invented for the
                 Three Instruction Machine and subsequently used to
                 construct lazy variants of Krivine's abstract machine.
                 Tuning the evaluator leads to other implementation
                 techniques such as unboxed values. The correctness of
                 the resulting abstract machines is a corollary of the
                 correctness of the original evaluators and of the
                 program transformations used in the derivation.",
  x-doi =        "10.1016/j.ipl.2004.02.012",
  x-issn =       "00200190",
  x-url =        "http://dx.doi.org/10.1016/j.ipl.2004.02.012",
  xpages =       "223--232",
  year =         "2004",
}

@Article{Pottier2005Systematic,
  author =       "Fran\c{c}ois Pottier and Christian Skalka and Scott
                 Smith",
  citeulike-article-id = "190447",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1057392",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1057387.1057392",
  date-added =   "2010-03-13 01:04:46",
  journal =      "ACM Trans. Program. Lang. Syst.",
  month =        mar,
  number =       "2",
  priority =     "2",
  publisher =    "ACM",
  title =        "A systematic approach to static access control",
  volume =       "27",
  x-abstract =   "The Java Security Architecture includes a dynamic
                 mechanism for enforcing access control checks, the
                 so-called stack inspection process. While the
                 architecture has several appealing features, access
                 control checks are all implemented via dynamic method
                 calls. This is a highly nondeclarative form of
                 specification that is hard to read, and that leads to
                 additional run-time overhead. This article develops
                 type systems that can statically guarantee the success
                 of these checks. Our systems allow security properties
                 of programs to be clearly expressed within the types
                 themselves, which thus serve as static declarations of
                 the security policy. We develop these systems using a
                 systematic methodology: we show that the
                 security-passing style translation, proposed by Wallach
                 et al. [2000] as a dynamic implementation technique,
                 also gives rise to static security-aware type systems,
                 by composition with conventional type systems. To
                 define the latter, we use the general {HM}( X )
                 framework, and easily construct several constraint- and
                 unification-based type systems.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1057387.1057392",
  x-issn =       "0164-0925",
  x-url =        "http://dx.doi.org/10.1145/1057387.1057392",
  xpages =       "344--382",
  year =         "2005",
}

@InProceedings{Hudak1986Semantic,
  author =       "Paul Hudak",
  booktitle =    "LFP '86: Proceedings of the 1986 ACM conference on
                 LISP and functional programming",
  citeulike-article-id = "350023",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=319838.319876",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/319838.319876",
  date-added =   "2010-03-12 02:10:48",
  location =     "Cambridge, Massachusetts, United States",
  priority =     "2",
  publisher =    "ACM",
  title =        "A semantic model of reference counting and its
                 abstraction (detailed summary)",
  x-abstract =   "Note: {OCR} errors may be found in this Reference List
                 extracted from the full text article. {ACM} has opted
                 to expose the complete List rather than only correct
                 and linked references.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/319838.319876",
  x-isbn =       "0-89791-200-4",
  x-url =        "http://dx.doi.org/10.1145/319838.319876",
  xpages =       "351--363",
  year =         "1986",
}

@InProceedings{Goldberg1992Polymorphic,
  author =       "Benjamin Goldberg and Michael Gloger",
  booktitle =    "LFP '92: Proceedings of the 1992 ACM conference on
                 LISP and functional programming",
  citeulike-article-id = "6784415",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=141471.141504",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/141471.141504",
  date-added =   "2010-03-09 23:09:58",
  location =     "San Francisco, California, United States",
  priority =     "2",
  publisher =    "ACM",
  title =        "Polymorphic type reconstruction for garbage collection
                 without tags",
  x-abstract =   "Several papers, have recently claimed that garbage
                 collection can be performed on untagged data in the
                 presence of {ML}-style type polymorphism. They rely on
                 the ability to reconstruct the type of any reachable
                 object during garbage collection. The bad news is that
                 this is false\&mdash;there can be reachable objects in
                 the program whose type cannot be determined by the
                 garbage collector. The good news is that tag-free
                 garbage collection can be performed anyway\&mdash;any
                 object whose type cannot be determined by the collector
                 is, in fact, garbage. Such objects can be discarded by
                 the collector. This is the key result of this paper. We
                 present a type reconstruction algorithm that can
                 determine the type of any non-garbage object.
                 Unfortunately, the implementation of the tag-free
                 collector for a polymorphically typed language is
                 difficult in ways that were not described in the
                 previous papers, and we address some implementation
                 issues as well. However, we mainly describe how to
                 perform type reconstruction during garbage collection
                 and do not attempt to address practical issues of the
                 garbage collection process.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/141471.141504",
  x-isbn =       "0-89791-481-3",
  x-url =        "http://dx.doi.org/10.1145/141471.141504",
  xpages =       "53--65",
  year =         "1992",
}

@Book{Danvy2006Analytical,
  author =       "Olivier Danvy",
  citeulike-article-id = "6778732",
  date-added =   "2010-03-09 00:51:56",
  month =        apr,
  priority =     "2",
  title =        "An Analytical Approach to Programs as Data Objects",
  year =         "2006",
}

@InProceedings{Midtgaard2009Controlflow,
  author =       "Jan Midtgaard and Thomas P. Jensen",
  booktitle =    "ICFP '09: Proceedings of the 14th ACM SIGPLAN
                 International Conference on Functional Programming",
  citeulike-article-id = "5904200",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1596550.1596592",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1596550.1596592",
  date-added =   "2010-03-09 00:36:16",
  location =     "Edinburgh, Scotland",
  priority =     "0",
  publisher =    "ACM",
  title =        "Control-flow Analysis of Function Calls and Returns by
                 Abstract Interpretation",
  x-abstract =   "We derive a control-flow analysis that approximates
                 the interprocedural control-flow of both function calls
                 and returns in the presence of first-class functions
                 and tail-call optimization. In addition to an abstract
                 environment, our analysis computes for each expression
                 an abstract control stack, effectively approximating
                 where function calls return across optimized tail
                 calls. The analysis is systematically calculated by
                 abstract interpretation of the stack-based {CaEK}
                 abstract machine of Flanagan et al. using a series of
                 Galois connections. Abstract interpretation provides a
                 unifying setting in which we 1) prove the analysis
                 equivalent to the composition of a continuation-passing
                 style ({CPS}) transformation followed by an abstract
                 interpretation of a stack-less {CPS} machine, and 2)
                 extract an equivalent constraint-based formulation,
                 thereby providing a rational reconstruction of a
                 constraint-based control-flow analysis from abstract
                 interpretation principles.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1596550.1596592",
  x-isbn =       "978-1-60558-332-7",
  x-series =     "ICFP '09",
  x-url =        "http://dx.doi.org/10.1145/1596550.1596592",
  xpages =       "287--298",
  year =         "2009",
}

@InProceedings{esop:kmf07,
  author =       "George Kuan and David MacQueen and Robert B. Findler",
  booktitle =    "Programming Languages and Systems, 16th European
                 Symposium on Programming",
  citeulike-article-id = "6778071",
  citeulike-linkout-0 = "http://www.cs.uchicago.edu/\~{}gkuan/pubs/esop07-kmf.pdf",
  comment =      "ESOP '07",
  date-added =   "2010-03-08 21:28:36",
  month =        mar,
  priority =     "2",
  title =        "A Rewriting Semantics for Type Inference",
  volume =       "4421",
  x-editor =     "Nicola, Rocco D.",
  x-url =        "http://www.cs.uchicago.edu/\~{}gkuan/pubs/esop07-kmf.pdf",
  year =         "2007",
}

@InCollection{sepr09,
  author =       "George Kuan",
  booktitle =    "Semantics Engineering with PLT Redex",
  citeulike-article-id = "6778064",
  date-added =   "2010-03-08 21:23:40",
  priority =     "2",
  publisher =    "MIT Press",
  title =        "Type Checking and Inference via Reductions",
  x-editor =     "Felleisen, Matthias and Findler, Robert B. and Flatt,
                 Matthew",
  year =         "2009",
}

@InProceedings{Flanagan1993Essence,
  author =       "Cormac Flanagan and Amr Sabry and Bruce F. Duba and
                 Matthias Felleisen",
  booktitle =    "PLDI '93: Proceedings of the ACM SIGPLAN 1993
                 Conference on Programming Language Design and
                 Implementation",
  citeulike-article-id = "190446",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=155113",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/155090.155113",
  date-added =   "2010-03-05 21:38:47",
  location =     "Albuquerque, New Mexico, USA",
  month =        jun,
  number =       "",
  priority =     "2",
  publisher =    "ACM",
  title =        "The Essence of Compiling with Continuations",
  volume =       "",
  x-abstract =   "In order to simplify the compilation process, many
                 compilers for higher-order languages use the
                 continuation-passing style ({CPS}) transformation in a
                 first phase to generate an intermediate representation
                 of the source program. The salient aspect of this
                 intermediate form is that all procedures take an
                 argument that represents the rest of the computation
                 (the ” continuation”). Since the nai¨ve {CPS}
                 transformation considerably increases the size of
                 programs, {CPS} compilers perform reductions to produce
                 a more compact intermediate representation. Although
                 often implemented as a part of the {CPS}
                 transformation, this step is conceptually a second
                 phase. Finally, code generators for typical {CPS}
                 compilers treat continuations specially in order to
                 optimize the interpretation of continuation parameters.
                 A thorough analysis of the abstract machine for {CPS}
                 terms show that the actions of the code generator
                 invert the nai¨ve {CPS} translation step. Put
                 differently, the combined effect of the three phases is
                 equivalent to a source-to-source transformation that
                 simulates the compaction phase. Thus, fully developed
                 {CPS} compilers do not need to employ the {CPS}
                 transformation but can achieve the same results with a
                 simple source-level transformation.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/155090.155113",
  x-isbn =       "0-89791-598-4",
  x-series =     "PLDI '93",
  x-url =        "http://dx.doi.org/10.1145/155090.155113",
  xpages =       "237--247",
  year =         "1993",
}

@InCollection{Cousot98-5,
  author =       "Patrick Cousot",
  booktitle =    "Calculational System Design",
  citeulike-article-id = "6768482",
  date-added =   "2010-03-05 21:29:37",
  priority =     "2",
  publisher =    "NATO ASI Series F. IOS Press, Amsterdam",
  title =        "The Calculational Design of a Generic Abstract
                 Interpreter",
  x-editor =     "Broy, M. and Steinbr{\"{u}}ggen, R.",
  year =         "1999",
}

@Book{Felleisen2009Semantics,
  author =       "Matthias Felleisen and Robert B. Findler and Matthew
                 Flatt",
  citeulike-article-id = "6749381",
  date-added =   "2010-03-02 16:18:29",
  month =        aug,
  priority =     "2",
  publisher =    "MIT Press",
  title =        "Semantics Engineering with {PLT} Redex",
  x-isbn =       "0-262-06275-5",
  year =         "2009",
}

@Article{Clements2004Tailrecursive,
  author =       "John Clements and Matthias Felleisen",
  citeulike-article-id = "1394",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1034778",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1034774.1034778",
  date-added =   "2010-03-01 20:51:33",
  journal =      "ACM Trans. Program. Lang. Syst.",
  month =        nov,
  number =       "6",
  priority =     "2",
  publisher =    "ACM",
  title =        "A Tail-recursive Machine with Stack Inspection",
  volume =       "26",
  x-abstract =   "Security folklore holds that a security mechanism
                 based on stack inspection is incompatible with a global
                 tail call optimization policy; that an implementation
                 of such a language must allocate memory for a
                 source-code tail call, and a program that uses only
                 tail calls (and no other memory-allocating construct)
                 may nevertheless exhaust the available memory. In this
                 article, we prove this widely held belief wrong. We
                 exhibit an abstract machine for a language with
                 security stack inspection whose space consumption
                 function is equivalent to that of the canonical tail
                 call optimizing abstract machine. Our machine is
                 surprisingly simple and suggests that tail calls are as
                 easy to implement in a security setting as they are in
                 a conventional one.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1034774.1034778",
  x-issn =       "0164-0925",
  x-url =        "http://dx.doi.org/10.1145/1034774.1034778",
  xpages =       "1029--1052",
  year =         "2004",
}

@Article{Ager2005Functional,
  author =       "Mads S. Ager and Olivier Danvy and Jan Midtgaard",
  citeulike-article-id = "6745807",
  citeulike-linkout-0 = "http://dx.doi.org/10.1016/j.tcs.2005.06.008",
  date-added =   "2010-03-01 18:17:40",
  day =          "06",
  journal =      "Theoretical Computer Science",
  month =        sep,
  number =       "1",
  priority =     "0",
  title =        "A functional correspondence between monadic evaluators
                 and abstract machines for languages with computational
                 effects",
  volume =       "342",
  x-abstract =   "We extend our correspondence between evaluators and
                 abstract machines from the pure setting of the λ
                 -calculus to the impure setting of the computational λ
                 -calculus. We show how to derive new abstract machines
                 from monadic evaluators for the computational λ
                 -calculus. Starting from (1) a generic evaluator
                 parameterized by a monad and (2) a monad specifying a
                 computational effect, we inline the components of the
                 monad in the generic evaluator to obtain an evaluator
                 written in a style that is specific to this
                 computational effect. We then derive the corresponding
                 abstract machine by closure-converting,
                 {CPS}-transforming, and defunctionalizing this specific
                 evaluator. We illustrate the construction with the
                 identity monad, obtaining the {CEK} machine, and with a
                 lifted state monad, obtaining a variant of the {CEK}
                 machine with error and state. In addition, we
                 characterize the tail-recursive stack inspection
                 presented by Clements and Felleisen as a lifted state
                 monad. This enables us to combine this stack-inspection
                 monad with other monads and to construct abstract
                 machines for languages with properly tail-recursive
                 stack inspection and other computational effects. The
                 construction scales to other monads—including one
                 more properly dedicated to stack inspection than the
                 lifted state monad—and other monadic evaluators.",
  x-doi =        "10.1016/j.tcs.2005.06.008",
  x-issn =       "03043975",
  x-url =        "http://dx.doi.org/10.1016/j.tcs.2005.06.008",
  xpages =       "149--172",
  year =         "2005",
}

@InProceedings{Felleisen1987Calculus,
  author =       "Matthias Felleisen and D. P. Friedman",
  booktitle =    "POPL '87: Proceedings of the 14th ACM SIGACT-SIGPLAN
                 Symposium on Principles of Programming Languages",
  citeulike-article-id = "6745776",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=41625.41654",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/41625.41654",
  comment =      "POPL'87",
  date-added =   "2010-03-01 17:51:15",
  location =     "Munich, West Germany",
  priority =     "0",
  publisher =    "ACM",
  title =        "A Calculus for Assignments in Higher-order Languages",
  x-abstract =   "Imperative assignments are abstractions of recurring
                 programming patterns in purely functional programming
                 languages. When added to higher-order functional
                 languages, they provide a higher-level of modularity
                 and security but invalidate the simple substitution
                 semantics. We show that, given an operational
                 interpretation of a denotational semantics for such a
                 language, it is possible to design a two-level
                 extension of the \&lgr;u-calculus. This calculus
                 provides a location-free rewriting semantics of the
                 language and offers new possibilities for reasoning
                 with assignments. The upper level of the calculus
                 factors out all the steps in a reduction sequence which
                 must be in a linear order; the lower level allows a
                 partial ordering of reduction steps.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/41625.41654",
  x-isbn =       "0-89791-215-2",
  x-series =     "POPL '87",
  x-url =        "http://dx.doi.org/10.1145/41625.41654",
  xpages =       "314--325",
  year =         "1987",
}

@InProceedings{Might:2006:DeltaCFA,
  author =       "Matthew Might and Olin Shivers",
  booktitle =    "POPL '06: Conference record of the 33rd ACM
                 SIGPLAN-SIGACT Symposium on Principles of Programming
                 Languages",
  citeulike-article-id = "4837404",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1111037.1111049",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1111037.1111049",
  date-added =   "2009-11-20 04:00:25",
  location =     "Charleston, South Carolina, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "Environment analysis via \(\{Delta\)-CFA}",
  x-abstract =   "We describe a new program-analysis framework, based on
                 {CPS} and procedure-string abstractions, that can
                 handle critical analyses which the {k-CFA} framework
                 cannot. We present the main theorems concerning
                 correctness, show an application analysis, and describe
                 a running implementation.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1111037.1111049",
  x-isbn =       "1-59593-027-2",
  x-series =     "POPL '06",
  x-url =        "http://dx.doi.org/10.1145/1111037.1111049",
  xpages =       "127--140",
  year =         "2006",
}

@InProceedings{Gustavsson:PADO01,
  author =       "J{\"{o}}rgen Gustavsson and Josef Svenningsson",
  booktitle =    "PADO '01: Proceedings of the Second Symposium on
                 Programs as Data Objects",
  citeulike-article-id = "6171563",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=668111",
  date-added =   "2009-11-20 03:15:26",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "Constraint Abstractions",
  x-address =    "London, UK",
  x-isbn =       "3-540-42068-1",
  x-url =        "http://portal.acm.org/citation.cfm?id=668111",
  xpages =       "63--83",
  year =         "2001",
}

@InProceedings{Rehof:POPL01,
  author =       "Jakob Rehof and Manuel F{\"{a}}hndrich",
  booktitle =    "POPL '01: Proceedings of the 28th ACM SIGPLAN-SIGACT
                 Symposium on Principles of Programming Languages",
  citeulike-article-id = "5442196",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=360204.360208",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/360204.360208",
  date-added =   "2009-11-20 02:56:17",
  location =     "London, United Kingdom",
  priority =     "2",
  publisher =    "ACM",
  title =        "Type-base flow analysis: from polymorphic subtyping to
                 {CFL}-reachability",
  x-abstract =   "We present a novel approach to scalable implementation
                 of type-based flow analysis with polymorphic subtyping.
                 Using a new presentation of polymorphic subytping with
                 instantiation constraints, we are able to apply
                 context-free language ({CFL}) reachability techniques
                 to type-based flow analysis. We develop a {CFL}-based
                 algorithm for computing flow-information in time O( n
                 \&sup3;), where n is the size of the typed program. The
                 algorithm substantially improves upon the best
                 previously known algorithm for flow analysis based on
                 polymorphic subtyping with complexity O( n 8 ). Our
                 technique also yields the first demand-driven algorithm
                 for polymorphic subtype-based flow-computation. It
                 works directly on higher-order programs with structured
                 data of finite type (unbounded data structures are
                 incorporated via finite approximations), supports
                 context-sensitive, global flow summariztion and
                 includes polymorphic recursion.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/360204.360208",
  x-isbn =       "1-58113-336-7",
  x-url =        "http://dx.doi.org/10.1145/360204.360208",
  xpages =       "54--66",
  year =         "2001",
}

@PhdThesis{Lhotak:PhD:2006,
  author =       "Ond\v{r}ej Lhot\'{a}k",
  citeulike-article-id = "6127600",
  date-added =   "2009-11-16 20:21:44",
  month =        jan,
  priority =     "2",
  school =       "McGill University",
  title =        "Program Analysis using Binary Decision Diagrams",
  year =         "2006",
}

@InBook{Sharir:Interprocedural,
  author =       "Micha Sharir and Amir Pnueli",
  booktitle =    "Program Flow Analysis",
  chapter =      "7",
  citeulike-article-id = "6057102",
  date-added =   "2009-11-02 18:56:32",
  priority =     "2",
  publisher =    "Prentice-Hall, Inc.",
  title =        "Two Approaches to Interprocedural Data Flow Analysis",
  x-address =    "Englewood Cliffs, NJ",
  x-editor =     "Muchnick, Steven S. and Jones, Neil D.",
  x-isbn =       "0137296819",
  xpages =       "189--233",
  year =         "1981",
}

@Article{Igarashi:TOPLAS:2001,
  author =       "Atsushi Igarashi and Benjamin C. Pierce and Philip
                 Wadler",
  citeulike-article-id = "3425305",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=503505",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/503502.503505",
  date-added =   "2009-10-26 15:00:29",
  journal =      "ACM Trans. Program. Lang. Syst.",
  keywords =     "java",
  month =        may,
  number =       "3",
  priority =     "2",
  publisher =    "ACM",
  title =        "Featherweight {J}ava: a minimal core calculus for
                 {J}ava and {GJ}",
  volume =       "23",
  x-abstract =   "Several recent studies have introduced lightweight
                 versions of Java: reduced languages in which complex
                 features like threads and reflection are dropped to
                 enable rigorous arguments about key properties such as
                 type safety. We carry this process a step further,
                 omitting almost all features of the full language
                 (including interfaces and even assignment) to obtain a
                 small calculus, Featherweight Java, for which rigorous
                 proofs are not only possible but easy. Featherweight
                 Java bears a similar relation to Java as the
                 lambda-calculus does to languages such as {ML} and
                 Haskell. It offers a similar computational {"}feel,{"}
                 providing classes, methods, fields, inheritance, and
                 dynamic typecasts with a semantics closely following
                 Java's. A proof of type safety for Featherweight Java
                 thus illustrates many of the interesting features of a
                 safety proof for the full language, while remaining
                 pleasingly compact. The minimal syntax, typing rules,
                 and operational semantics of Featherweight Java make it
                 a handy tool for studying the consequences of
                 extensions and variations. As an illustration of its
                 utility in this regard, we extend Featherweight Java
                 with generic classes in the style of {GJ} (Bracha,
                 Odersky, Stoutamire, and Wadler) and give a detailed
                 proof of type safety. The extended system formalizes
                 for the first time some of the key features of {GJ}.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/503502.503505",
  x-issn =       "0164-0925",
  x-url =        "http://dx.doi.org/10.1145/503502.503505",
  xpages =       "396--450",
  year =         "2001",
}

@Article{Skalka-Smith-VanHorn:AIOOL05,
  author =       "Christian Skalka and Scott Smith and David Van Horn",
  citeulike-article-id = "5395202",
  citeulike-linkout-0 = "http://dx.doi.org/10.1016/j.entcs.2005.01.027",
  date-added =   "2009-08-07 21:51:31",
  day =          "24",
  journal =      "Electronic Notes in Theoretical Computer Science",
  month =        may,
  priority =     "0",
  title =        "A Type and Effect System for Flexible Abstract
                 Interpretation of {J}ava (Extended Abstract)",
  volume =       "131",
  x-abstract =   "This paper describes a flexible type and effect
                 inference system for Featherweight Java ({FJ}). The
                 effect terms generated by static type and effect
                 inference embody the abstract interpretation of pro-
                 gram event sequences. Flexibility in the analysis is
                 obtained by post-processing of inferred effects,
                 allowing a modular adaptation to extensions of the
                 language. Several example transformations are
                 discussed, including how inferred effects can be
                 transformed to reflect the impact of exceptions on {FJ}
                 control flow.",
  x-doi =        "10.1016/j.entcs.2005.01.027",
  x-issn =       "15710661",
  x-url =        "http://dx.doi.org/10.1016/j.entcs.2005.01.027",
  xpages =       "111--124",
  year =         "2005",
}

@Article{Skalka-Smith-VanHorn:JFP08,
  author =       "Christian Skalka and Scott Smith and David Van{
                 }Horn",
  citeulike-article-id = "5395173",
  citeulike-linkout-0 = "http://journals.cambridge.org/action/displayAbstract?fromPage=online\&aid=1695700",
  citeulike-linkout-1 = "http://dx.doi.org/10.1017/s0956796807006466",
  date-added =   "2009-08-07 21:46:03",
  journal =      "Journal of Functional Programming",
  number =       "02",
  priority =     "0",
  title =        "Types and trace effects of higher order programs",
  volume =       "18",
  x-abstract =   "This paper shows how type effect systems can be
                 combined with model-checking techniques to produce
                 powerful, automatically verifiable program logics for
                 higher order programs. The properties verified are
                 based on the ordered sequence of events that occur
                 during program execution, so-called event traces. Our
                 type and effect systems infer conservative
                 approximations of the event traces arising at run-time,
                 and model-checking techniques are used to verify
                 logical properties of these histories. Our language
                 model is based on the λ-calculus. Technical results
                 include a type inference algorithm for a polymorphic
                 type effect system, and a method for applying known
                 model-checking techniques to the trace effects inferred
                 by the type inference algorithm, allowing static
                 enforcement of history- and stack-based security
                 mechanisms. A type safety result is proven for both
                 unification and subtyping constraint versions of the
                 type system, ensuring that statically well-typed
                 programs do not contain trace event checks that can
                 fail at run-time.",
  x-doi =        "10.1017/s0956796807006466",
  x-url =        "http://dx.doi.org/10.1017/s0956796807006466",
  xpages =       "179--249",
  year =         "2008",
}

@InProceedings{VanHorn-Mairson:ICFP07,
  author =       "David Van{ }Horn and Harry G. Mairson",
  booktitle =    "ICFP '07: Proceedings of the 12th ACM SIGPLAN
                 International Conference on Functional Programming",
  citeulike-article-id = "2784124",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1291151.1291166",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1291151.1291166",
  date-added =   "2009-08-07 21:42:15",
  location =     "Freiburg, Germany",
  priority =     "0",
  publisher =    "ACM",
  title =        "Relating Complexity and Precision in Control Flow
                 Analysis",
  x-abstract =   "We analyze the computational complexity of {kCFA}, a
                 hierarchy of control flow analyses that determine which
                 functions may be applied at a given call-site. This
                 hierarchy specifies related decision problems, quite
                 apart from any algorithms that may implement their
                 solutions. We identify a simple decision problem
                 answered by this analysis and prove that in the {0CFA}
                 case, the problem is complete for polynomial time. The
                 proof is based on a nonstandard, symmetric
                 implementation of Boolean logic within multiplicative
                 linear logic ({MLL}). We also identify a simpler
                 version of {0CFA} related to η-expansion, and prove
                 that it is complete for logarithmic space, using
                 arguments based on computing paths and permutations.
                 For any fixed k>0, it is known that {kCFA} (and the
                 analogous decision problem) can be computed in time
                 exponential in the program size. For k=1, we show that
                 the decision problem is {NP}-hard, and sketch why this
                 remains true for larger fixed values of k. The proof
                 technique depends on using the approximation of {CFA}
                 as an essentially nondeterministic computing mechanism,
                 as distinct from the exactness of normalization. When
                 k=n, so that the {"}depth{"} of the control flow
                 analysis grows linearly in the program length, we show
                 that the decision problem is complete for exponential
                 time. In addition, we sketch how the analysis presented
                 here may be extended naturally to languages with
                 control operators. All of the insights presented give
                 clear examples of how straightforward observations
                 about linearity, and linear logic, may in turn be used
                 to give a greater understanding of functional
                 programming and program analysis.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1291151.1291166",
  x-isbn =       "978-1-59593-815-2",
  x-series =     "ICFP '07",
  x-url =        "http://dx.doi.org/10.1145/1291151.1291166",
  xpages =       "85--96",
  year =         "2007",
}

@Proceedings{DBLP:conf/rta/2006,
  booktitle =    "RTA",
  citeulike-article-id = "5395154",
  date-added =   "2009-08-07 21:29:29",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Springer",
  title =        "Term Rewriting and Applications, 17th International
                 Conference, {RTA} 2006, Seattle, {WA}, {USA}, August
                 12-14, 2006, Proceedings",
  volume =       "4098",
  x-editor =     "Pfenning, Frank",
  x-series =     "Lecture Notes in Computer Science",
  year =         "2006",
}

@InProceedings{giesl-etal-rta06,
  author =       "J{\"{u}}rgen Giesl and Stephan Swiderski and Peter S.
                 Kamp and Ren{\'{e}} Thiemann",
  booktitle =    "RTA",
  citeulike-article-id = "5395153",
  date-added =   "2009-08-07 21:29:28",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Springer",
  title =        "Automated Termination Analysis for Haskell: From Term
                 Rewriting to Programming Languages",
  volume =       "4098",
  x-editor =     "Pfenning, Frank",
  x-series =     "Lecture Notes in Computer Science",
  xpages =       "297--312",
  year =         "2006",
}

@InProceedings{biswas-popl97,
  author =       "Sandip K. Biswas",
  booktitle =    "POPL '97: Proceedings of the 24th ACM SIGPLAN-SIGACT
                 symposium on Principles of programming languages",
  citeulike-article-id = "5395152",
  date-added =   "2009-08-07 21:29:28",
  key =          "POPL 1997",
  keywords =     "file-import-09-08-07",
  location =     "Paris, France",
  priority =     "2",
  publisher =    "ACM",
  title =        "A demand-driven set-based analysis",
  x-address =    "New York, NY, USA",
  xpages =       "372--385",
  year =         "1997",
}

@Article{palsberg-schwarzbach-ic95,
  author =       "Jens Palsberg and Michael I. Schwartzbach",
  citeulike-article-id = "5395151",
  date-added =   "2009-08-07 21:29:28",
  journal =      "Inf. Comput.",
  keywords =     "file-import-09-08-07",
  number =       "1",
  priority =     "2",
  publisher =    "Academic Press, Inc.",
  title =        "Safety analysis versus type inference",
  volume =       "118",
  x-address =    "Duluth, MN, USA",
  xpages =       "128--141",
  year =         "1995",
}

@PhdThesis{ayers-phd93,
  author =       "Andrew E. Ayers",
  citeulike-article-id = "5395150",
  date-added =   "2009-08-07 21:29:28",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  school =       "Massachusetts Institute of Technology",
  title =        "Abstract analysis and optimization of Scheme",
  x-address =    "Cambridge, MA, USA",
  year =         "1993",
}

@InProceedings{diwan-etal-oopsla96,
  author =       "Amer Diwan and Eliot and Kathryn S. Mckinley",
  booktitle =    "OOPSLA '96: Proceedings of the 11th ACM SIGPLAN
                 conference on Object-oriented programming, systems,
                 languages, and applications",
  citeulike-article-id = "5395149",
  date-added =   "2009-08-07 21:29:28",
  keywords =     "file-import-09-08-07",
  location =     "San Jose, California, United States",
  priority =     "2",
  publisher =    "ACM",
  title =        "Simple and effective analysis of statically-typed
                 object-oriented programs",
  x-address =    "New York, NY, USA",
  xpages =       "292--305",
  year =         "1996",
}

@InProceedings{graver-johnson-popl90,
  author =       "Justin O. Graver and Ralph E. Johnson",
  booktitle =    "POPL '90: Proceedings of the 17th ACM SIGPLAN-SIGACT
                 symposium on Principles of programming languages",
  citeulike-article-id = "5395148",
  date-added =   "2009-08-07 21:29:28",
  key =          "POPL 1990",
  keywords =     "file-import-09-08-07",
  location =     "San Francisco, California, United States",
  priority =     "2",
  publisher =    "ACM",
  title =        "A type system for Smalltalk",
  x-address =    "New York, NY, USA",
  xpages =       "136--150",
  year =         "1990",
}

@InProceedings{johnson-etal-oopsla88,
  author =       "Ralph E. Johnson and Justin O. Graver and Laurance W.
                 Zurawski",
  booktitle =    "OOPSLA '88: Conference proceedings on Object-oriented
                 programming systems, languages and applications",
  citeulike-article-id = "5395147",
  date-added =   "2009-08-07 21:29:28",
  keywords =     "file-import-09-08-07",
  location =     "San Diego, California, United States",
  priority =     "2",
  publisher =    "ACM",
  title =        "{TS}: An optimizing compiler for {S}malltalk",
  x-address =    "New York, NY, USA",
  xpages =       "18--26",
  year =         "1988",
}

@InProceedings{bacon-sweeney-oopsla96,
  author =       "David F. Bacon and Peter F. Sweeney",
  booktitle =    "OOPSLA '96: Proceedings of the 11th ACM SIGPLAN
                 conference on Object-oriented programming, systems,
                 languages, and applications",
  citeulike-article-id = "5395146",
  date-added =   "2009-08-07 21:29:28",
  keywords =     "file-import-09-08-07",
  location =     "San Jose, California, United States",
  priority =     "2",
  publisher =    "ACM",
  title =        "Fast static analysis of {C}++ virtual function calls",
  x-address =    "New York, NY, USA",
  xpages =       "324--341",
  year =         "1996",
}

@InProceedings{chambers-ungar-pldi90,
  author =       "Craig Chambers and David Ungar",
  booktitle =    "PLDI '90: Proceedings of the ACM SIGPLAN 1990
                 conference on Programming language design and
                 implementation",
  citeulike-article-id = "5395145",
  date-added =   "2009-08-07 21:29:28",
  keywords =     "file-import-09-08-07",
  location =     "White Plains, New York, United States",
  priority =     "2",
  publisher =    "ACM",
  title =        "Interactive type analysis and extended message
                 splitting; optimizing dynamically-typed object-oriented
                 programs",
  x-address =    "New York, NY, USA",
  xpages =       "150--164",
  year =         "1990",
}

@Article{spoto-jensen-toplas03,
  author =       "Fausto Spoto and Thomas Jensen",
  citeulike-article-id = "5395144",
  date-added =   "2009-08-07 21:29:27",
  journal =      "ACM Trans. Program. Lang. Syst.",
  keywords =     "file-import-09-08-07",
  number =       "5",
  priority =     "2",
  publisher =    "ACM",
  title =        "Class analyses as abstract interpretations of trace
                 semantics",
  volume =       "25",
  x-address =    "New York, NY, USA",
  xpages =       "578--630",
  year =         "2003",
}

@InProceedings{jagannathan-wright-pldi96,
  author =       "Suresh Jagannathan and Andrew Wright",
  booktitle =    "PLDI '96: Proceedings of the ACM SIGPLAN 1996
                 conference on Programming language design and
                 implementation",
  citeulike-article-id = "5395143",
  date-added =   "2009-08-07 21:29:27",
  keywords =     "file-import-09-08-07",
  location =     "Philadelphia, Pennsylvania, United States",
  priority =     "2",
  publisher =    "ACM",
  title =        "Flow-directed inlining",
  x-address =    "New York, NY, USA",
  xpages =       "193--205",
  year =         "1996",
}

@InProceedings{palsberg-schwartzbach-oopsla91,
  author =       "Jens Palsberg and Michael I. Schwartzbach",
  booktitle =    "OOPSLA '91: Conference proceedings on Object-oriented
                 programming systems, languages, and applications",
  citeulike-article-id = "5395142",
  date-added =   "2009-08-07 21:29:27",
  keywords =     "file-import-09-08-07",
  location =     "Phoenix, Arizona, United States",
  priority =     "2",
  publisher =    "ACM",
  title =        "Object-oriented type inference",
  x-address =    "New York, NY, USA",
  xpages =       "146--161",
  year =         "1991",
}

@Article{chakaravarthy-horwitz-ai02,
  author =       "Venkatesan T. Chakaravarthy and Susan Horwitz",
  citeulike-article-id = "5395141",
  date-added =   "2009-08-07 21:29:27",
  journal =      "Acta Informatica",
  keywords =     "file-import-09-08-07",
  month =        jul,
  number =       "8",
  priority =     "2",
  title =        "On the {Non-Approximability} of Points-to Analysis",
  volume =       "38",
  xpages =       "587--598",
  year =         "2002",
}

@InProceedings{vitek-etal-cc92,
  author =       "Jan Vitek and R. Nigel Horspool and James S. Uhl",
  booktitle =    "CC '92: Proceedings of the 4th International
                 Conference on Compiler Construction",
  citeulike-article-id = "5395140",
  date-added =   "2009-08-07 21:29:27",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "{Compile-Time} Analysis of {Object-Oriented}
                 Programs",
  x-address =    "London, UK",
  xpages =       "236--250",
  year =         "1992",
}

@InProceedings{oxhoj-etal-ecoop92,
  author =       "Nicholas {.} {J} and Jens Palsberg and Michael I.
                 Schwartzbach",
  booktitle =    "ECOOP '92: Proceedings of the European Conference on
                 Object-Oriented Programming",
  citeulike-article-id = "5395139",
  date-added =   "2009-08-07 21:29:27",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "Making Type Inference Practical",
  x-address =    "London, UK",
  xpages =       "329--349",
  year =         "1992",
}

@PhdThesis{hofmann-hab98,
  author =       "Martin Hofmann",
  citeulike-article-id = "5395138",
  comment =      "Habilitation Thesis",
  date-added =   "2009-08-07 21:29:27",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  school =       "TU Darmstadt",
  title =        "Type Systems for {Polynomial-Time} Computation",
  year =         "1998",
}

@Article{kristiansen-tcs04,
  author =       "L. Kristiansen and K. H. Niggl",
  citeulike-article-id = "5395137",
  date-added =   "2009-08-07 21:29:27",
  journal =      "Theor. Comput. Sci.",
  keywords =     "file-import-09-08-07",
  number =       "1-2",
  priority =     "2",
  publisher =    "Elsevier Science Publishers Ltd.",
  title =        "On the computational complexity of imperative
                 programming languages",
  volume =       "318",
  x-address =    "Essex, UK",
  xpages =       "139--161",
  year =         "2004",
}

@InProceedings{leivant-popl93,
  author =       "Daniel Leivant",
  booktitle =    "POPL '93: Proceedings of the 20th ACM SIGPLAN-SIGACT
                 symposium on Principles of programming languages",
  citeulike-article-id = "5395136",
  date-added =   "2009-08-07 21:29:27",
  key =          "POPL 1993",
  keywords =     "file-import-09-08-07",
  location =     "Charleston, South Carolina, United States",
  priority =     "2",
  publisher =    "ACM",
  title =        "Stratified functional programs and computational
                 complexity",
  x-address =    "New York, NY, USA",
  xpages =       "325--333",
  year =         "1993",
}

@Article{hofmann-ic03,
  author =       "Martin Hofmann",
  citeulike-article-id = "5395135",
  date-added =   "2009-08-07 21:29:27",
  journal =      "Inf. Comput.",
  keywords =     "file-import-09-08-07",
  number =       "1",
  priority =     "2",
  publisher =    "Academic Press, Inc.",
  title =        "Linear types and non-size-increasing polynomial time
                 computation",
  volume =       "183",
  x-address =    "Duluth, MN, USA",
  xpages =       "57--85",
  year =         "2003",
}

@Article{wells-etal-jfp02,
  author =       "J. B. Wells and Allyn Dimock and Robert Muller and
                 Franklyn Turbak",
  citeulike-article-id = "5395134",
  date-added =   "2009-08-07 21:29:26",
  journal =      "J. Funct. Program.",
  keywords =     "file-import-09-08-07",
  number =       "3",
  priority =     "2",
  publisher =    "Cambridge University Press",
  title =        "A calculus with polymorphic and polyvariant flow
                 types",
  volume =       "12",
  x-address =    "New York, NY, USA",
  xpages =       "183--227",
  year =         "2002",
}

@InProceedings{amtoft-turbak-esop00,
  author =       "Torben Amtoft and Franklyn A. Turbak",
  booktitle =    "ESOP '00: Proceedings of the 9th European Symposium on
                 Programming Languages and Systems",
  citeulike-article-id = "5395133",
  date-added =   "2009-08-07 21:29:26",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "Faithful Translations between Polyvariant Flows and
                 Polymorphic Types",
  x-address =    "London, UK",
  xpages =       "26--40",
  year =         "2000",
}

@InProceedings{bravenboer-smaragdakis-oopsla09,
  author =       "Martin Bravenboer and Yannis Smaragdakis",
  booktitle =    "OOPSLA '09: Proceedings of the 24th annual ACM SIGPLAN
                 Conference on Object-Oriented Programming, Systems,
                 Languages, and Applications",
  citeulike-article-id = "5395132",
  comment =      "To appear.",
  date-added =   "2009-08-07 21:29:26",
  keywords =     "file-import-09-08-07",
  month =        oct,
  priority =     "2",
  title =        "Strictly Declarative Specification of Sophisticated
                 Points-to Analyses",
  year =         "2009",
}

@Article{damiani-toplas03,
  author =       "Ferruccio Damiani",
  citeulike-article-id = "5395131",
  date-added =   "2009-08-07 21:29:26",
  journal =      "ACM Trans. Program. Lang. Syst.",
  keywords =     "file-import-09-08-07",
  number =       "4",
  priority =     "2",
  publisher =    "ACM",
  title =        "Rank 2 intersection types for local definitions and
                 conditional expressions",
  volume =       "25",
  x-address =    "New York, NY, USA",
  xpages =       "401--451",
  year =         "2003",
}

@Article{damiani-fi07,
  author =       "Ferruccio Damiani",
  citeulike-article-id = "5395130",
  date-added =   "2009-08-07 21:29:26",
  journal =      "Fundam. Inf.",
  keywords =     "file-import-09-08-07",
  number =       "4",
  priority =     "2",
  publisher =    "IOS Press",
  title =        "Rank 2 Intersection for Recursive Definitions",
  volume =       "77",
  x-address =    "Amsterdam, The Netherlands, The Netherlands",
  xpages =       "451--488",
  year =         "2007",
}

@InProceedings{damiani-prost-types96,
  author =       "Ferruccio Damiani and Fr\'{e}d\'{e}ric Prost",
  booktitle =    "TYPES '96: Selected papers from the International
                 Workshop on Types for Proofs and Programs",
  citeulike-article-id = "5395129",
  date-added =   "2009-08-07 21:29:26",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "Detecting and Removing {Dead-Code} using Rank 2
                 Intersection",
  x-address =    "London, UK",
  xpages =       "66--87",
  year =         "1998",
}

@Article{vanbakel-tcs92,
  author =       "Steffen van Bakel",
  citeulike-article-id = "5395128",
  date-added =   "2009-08-07 21:29:26",
  journal =      "Theor. Comput. Sci.",
  keywords =     "file-import-09-08-07",
  number =       "1",
  priority =     "2",
  publisher =    "Elsevier Science Publishers Ltd.",
  title =        "Complete restrictions of the intersection type
                 discipline",
  volume =       "102",
  x-address =    "Essex, UK",
  xpages =       "135--163",
  year =         "1992",
}

@Article{zwick-alg06,
  author =       "Uri Zwick",
  citeulike-article-id = "5395127",
  date-added =   "2009-08-07 21:29:26",
  journal =      "Algorithmica",
  keywords =     "file-import-09-08-07",
  number =       "2",
  priority =     "2",
  publisher =    "Springer-Verlag New York, Inc.",
  title =        "A Slightly Improved {Sub-Cubic} Algorithm for the All
                 Pairs Shortest Paths Problem with Real Edge Lengths",
  volume =       "46",
  x-address =    "Secaucus, NJ, USA",
  xpages =       "181--192",
  year =         "2006",
}

@InProceedings{chan-stoc07,
  author =       "Timothy M. Chan",
  booktitle =    "STOC '07: Proceedings of the thirty-ninth annual ACM
                 symposium on Theory of computing",
  citeulike-article-id = "5395126",
  date-added =   "2009-08-07 21:29:26",
  keywords =     "file-import-09-08-07",
  location =     "San Diego, California, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "More algorithms for all-pairs shortest paths in
                 weighted graphs",
  x-address =    "New York, NY, USA",
  xpages =       "590--598",
  year =         "2007",
}

@Article{vassilevska-ipl09,
  author =       "Virginia Vassilevska",
  citeulike-article-id = "5395125",
  date-added =   "2009-08-07 21:29:26",
  journal =      "Inf. Process. Lett.",
  keywords =     "file-import-09-08-07",
  number =       "4",
  priority =     "2",
  publisher =    "Elsevier North-Holland, Inc.",
  title =        "Efficient algorithms for clique problems",
  volume =       "109",
  x-address =    "Amsterdam, The Netherlands, The Netherlands",
  xpages =       "254--257",
  year =         "2009",
}

@TechReport{basch-etal-95,
  author =       "Julien Basch and Sanjeev Khanna and Rajeev Motwani",
  citeulike-article-id = "5395124",
  date-added =   "2009-08-07 21:29:25",
  institution =  "Stanford University",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  title =        "On diameter verification and boolean matrix
                 multiplication",
  x-address =    "Stanford, CA, USA",
  year =         "1995",
}

@Article{rytter-ic85,
  author =       "Wojciech Rytter",
  citeulike-article-id = "5395123",
  date-added =   "2009-08-07 21:29:25",
  journal =      "Inf. Control",
  keywords =     "file-import-09-08-07",
  number =       "1-3",
  priority =     "2",
  publisher =    "Academic Press Professional, Inc.",
  title =        "Fast recognition of pushdown automaton and
                 context-free languages",
  volume =       "67",
  x-address =    "San Diego, CA, USA",
  xpages =       "12--22",
  year =         "1985",
}

@Article{aho-hopcroft-ullman-ic68,
  author =       "Alfred V. Aho and John E. Hopcroft and Jeffrey D.
                 Ullmana",
  citeulike-article-id = "5395122",
  date-added =   "2009-08-07 21:29:25",
  journal =      "Information and Control",
  keywords =     "file-import-09-08-07",
  number =       "3",
  priority =     "2",
  title =        "Time and Tape Complexity of Pushdown Automaton
                 Languages",
  volume =       "13",
  xpages =       "186--206",
  year =         "1968",
}

@Misc{neal-89,
  author =       "Radford Neal",
  citeulike-article-id = "5395121",
  comment =      "Unpublished manuscript.
                 \url{ftp://ftp.cs.utoronto.ca/pub/radford/taxc.ps}",
  date-added =   "2009-08-07 21:29:25",
  keywords =     "file-import-09-08-07",
  month =        dec,
  priority =     "2",
  title =        "The computational complexity of taxonomic inference",
  year =         "1989",
}

@Book{martin-97,
  author =       "John C. Martin",
  citeulike-article-id = "5395120",
  date-added =   "2009-08-07 21:29:25",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "McGraw-Hill Higher Education",
  title =        "Introduction to Languages and the Theory of
                 Computation",
  year =         "1997",
}

@InProceedings{lee-etal-popl01,
  author =       "Chin S. Lee and Neil D. Jones and Amir M. Ben Amram",
  booktitle =    "POPL '01: Proceedings of the 28th ACM SIGPLAN-SIGACT
                 symposium on Principles of programming languages",
  citeulike-article-id = "5395119",
  date-added =   "2009-08-07 21:29:25",
  keywords =     "file-import-09-08-07",
  location =     "London, United Kingdom",
  priority =     "2",
  publisher =    "ACM",
  title =        "The size-change principle for program termination",
  x-address =    "New York, NY, USA",
  xpages =       "81--92",
  year =         "2001",
}

@Article{palsberg-wand-jfp03,
  author =       "Jens Palsberg and Mitchell Wand",
  citeulike-article-id = "5395118",
  date-added =   "2009-08-07 21:29:25",
  journal =      "J. Funct. Program.",
  keywords =     "file-import-09-08-07",
  number =       "5",
  priority =     "2",
  publisher =    "Cambridge University Press",
  title =        "{CPS} transformation of flow information",
  volume =       "13",
  x-address =    "New York, NY, USA",
  xpages =       "905--923",
  year =         "2003",
}

@InProceedings{wand-williamson-esop02,
  author =       "Mitchell Wand and Galen B. Williamson",
  booktitle =    "ESOP '02: Proceedings of the 11th European Symposium
                 on Programming Languages and Systems",
  citeulike-article-id = "5395117",
  date-added =   "2009-08-07 21:29:25",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "A Modular, Extensible Proof Method for {Small-Step}
                 Flow Analyses",
  x-address =    "London, UK",
  xpages =       "213--227",
  year =         "2002",
}

@Article{meunier-etal-hosc05,
  author =       "Philippe Meunier and Robert B. Findler and Paul
                 Steckler and Mitchell Wand",
  citeulike-article-id = "5395116",
  date-added =   "2009-08-07 21:29:25",
  journal =      "Higher Order Symbol. Comput.",
  keywords =     "file-import-09-08-07",
  number =       "3-4",
  priority =     "2",
  publisher =    "Kluwer Academic Publishers",
  title =        "Selectors Make {Set-Based} Analysis Too Hard",
  volume =       "18",
  x-address =    "Hingham, MA, USA",
  xpages =       "245--269",
  year =         "2005",
}

@Article{montenyohl-wand-scp91,
  author =       "Margaret Montenyohl and Mitchell Wand",
  citeulike-article-id = "5395115",
  date-added =   "2009-08-07 21:29:25",
  journal =      "Sci. Comput. Program.",
  keywords =     "file-import-09-08-07",
  number =       "1",
  priority =     "2",
  publisher =    "Elsevier North-Holland, Inc.",
  title =        "Correctness of static flow analysis in continuation
                 semantics",
  volume =       "16",
  x-address =    "Amsterdam, The Netherlands, The Netherlands",
  xpages =       "1--18",
  year =         "1991",
}

@Article{steckler-wand-toplas97,
  author =       "Paul A. Steckler and Mitchell Wand",
  citeulike-article-id = "5395114",
  date-added =   "2009-08-07 21:29:25",
  journal =      "ACM Trans. Program. Lang. Syst.",
  keywords =     "file-import-09-08-07",
  number =       "1",
  priority =     "2",
  publisher =    "ACM",
  title =        "Lightweight closure conversion",
  volume =       "19",
  x-address =    "New York, NY, USA",
  xpages =       "48--86",
  year =         "1997",
}

@Misc{wand-02,
  author =       "Mitchell Wand",
  citeulike-article-id = "5395113",
  comment =      "Unpublished manuscript.
                 \url{ftp://ftp.ccs.neu.edu/pub/people/wand/papers/order-sensitive-cfa.ps}",
  date-added =   "2009-08-07 21:29:25",
  keywords =     "file-import-09-08-07",
  month =        jul,
  priority =     "2",
  title =        "Analyses that distinguish different evaluation orders,
                 or, unsoundness results in control-flow analysis",
  year =         "2002",
}

@Proceedings{popl08,
  citeulike-article-id = "5395112",
  date-added =   "2009-08-07 21:29:25",
  key =          "POPL 2008",
  keywords =     "file-import-09-08-07",
  location =     "San Francisco, California, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "Proceedings of the 35th annual {ACM}
                 {SIGPLAN}-{SIGACT} Symposium on Principles of
                 Programming Languages",
  x-address =    "New York, NY, USA",
  year =         "2008",
}

@Proceedings{popl98,
  citeulike-article-id = "5395111",
  date-added =   "2009-08-07 21:29:25",
  key =          "POPL 1998",
  keywords =     "file-import-09-08-07",
  location =     "San Diego, California, United States",
  priority =     "2",
  publisher =    "ACM",
  title =        "Proceedings of the 25th {ACM} {SIGPLAN}-{SIGACT}
                 Symposium on Principles of Programming Languages",
  x-address =    "New York, NY, USA",
  year =         "1998",
}

@Proceedings{popl97,
  citeulike-article-id = "5395110",
  date-added =   "2009-08-07 21:29:25",
  key =          "POPL 1997",
  keywords =     "file-import-09-08-07",
  location =     "Paris, France",
  priority =     "2",
  publisher =    "ACM",
  title =        "Proceedings of the 24th {ACM} {SIGPLAN}-{SIGACT}
                 Symposium on Principles of Programming Languages",
  x-address =    "New York, NY, USA",
  year =         "1997",
}

@Proceedings{popl95,
  citeulike-article-id = "5395109",
  date-added =   "2009-08-07 21:29:25",
  key =          "POPL 1995",
  keywords =     "file-import-09-08-07",
  location =     "San Francisco, California, United States",
  priority =     "2",
  publisher =    "ACM",
  title =        "Proceedings of the 22nd {ACM} {SIGPLAN}-{SIGACT}
                 Symposium on Principles of Programming Languages",
  x-address =    "New York, NY, USA",
  year =         "1995",
}

@Proceedings{popl93,
  citeulike-article-id = "5395108",
  date-added =   "2009-08-07 21:29:25",
  key =          "POPL 1993",
  keywords =     "file-import-09-08-07",
  location =     "Charleston, South Carolina, United States",
  priority =     "2",
  publisher =    "ACM",
  title =        "Proceedings of the 20th {ACM} {SIGPLAN}-{SIGACT}
                 Symposium on Principles of Programming Languages",
  x-address =    "New York, NY, USA",
  year =         "1993",
}

@Proceedings{popl91,
  citeulike-article-id = "5395107",
  date-added =   "2009-08-07 21:29:25",
  key =          "POPL 1991",
  keywords =     "file-import-09-08-07",
  location =     "Orlando, Florida, United States",
  priority =     "2",
  publisher =    "ACM",
  title =        "Proceedings of the 18th {ACM} {SIGPLAN}-{SIGACT}
                 Symposium on Principles of Programming Languages",
  x-address =    "New York, NY, USA",
  year =         "1991",
}

@Proceedings{popl90,
  citeulike-article-id = "5395106",
  date-added =   "2009-08-07 21:29:25",
  key =          "POPL 1990",
  keywords =     "file-import-09-08-07",
  location =     "San Francisco, California, United States",
  priority =     "2",
  publisher =    "ACM",
  title =        "Proceedings of the 17th {ACM} {SIGPLAN}-{SIGACT}
                 Symposium on Principles of Programming Languages",
  x-address =    "New York, NY, USA",
  year =         "1990",
}

@InProceedings{hoang-mitchell-popl95,
  author =       "My Hoang and John C. Mitchell",
  booktitle =    "POPL '95: Proceedings of the 22nd ACM SIGPLAN-SIGACT
                 symposium on Principles of programming languages",
  citeulike-article-id = "5395105",
  date-added =   "2009-08-07 21:29:25",
  key =          "POPL 1995",
  keywords =     "file-import-09-08-07",
  location =     "San Francisco, California, United States",
  priority =     "2",
  publisher =    "ACM",
  title =        "Lower bounds on type inference with subtypes",
  x-address =    "New York, NY, USA",
  xpages =       "176--185",
  year =         "1995",
}

@Article{ben-amram-etal-toplas07,
  author =       "Amir M. Ben Amram and Chin S. Lee",
  citeulike-article-id = "5395104",
  date-added =   "2009-08-07 21:29:24",
  journal =      "ACM Trans. Program. Lang. Syst.",
  keywords =     "file-import-09-08-07",
  number =       "1",
  priority =     "2",
  publisher =    "ACM",
  title =        "Program termination analysis in polynomial time",
  volume =       "29",
  x-address =    "New York, NY, USA",
  xpages =       "5",
  year =         "2007",
}

@Proceedings{icfp97,
  citeulike-article-id = "5395103",
  date-added =   "2009-08-07 21:29:24",
  keywords =     "file-import-09-08-07",
  location =     "Amsterdam, The Netherlands",
  priority =     "2",
  publisher =    "ACM",
  title =        "{ICFP} '97: Proceedings of the second {ACM} {SIGPLAN}
                 international conference on Functional programming",
  x-address =    "New York, NY, USA",
  x-editor =     "Berman, A. Michael",
  year =         "1997",
}

@InProceedings{tobin-hochstadt-felleisen-popl08,
  author =       "Sam Tobin-Hochstadt and Matthias Felleisen",
  booktitle =    "POPL '08: Proceedings of the 35th annual ACM
                 SIGPLAN-SIGACT Symposium on Principles of Programming
                 Languages",
  citeulike-article-id = "5395102",
  comment =      "POPL '08",
  date-added =   "2009-08-07 21:29:24",
  key =          "POPL 2008",
  keywords =     "file-import-09-08-07",
  location =     "San Francisco, California, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "The design and implementation of {T}yped {S}cheme",
  x-address =    "New York, NY, USA",
  xpages =       "395--406",
  year =         "2008",
}

@Article{damian-danvy-jfp03,
  author =       "Daniel Damian and Olivier Danvy",
  citeulike-article-id = "5395101",
  date-added =   "2009-08-07 21:29:24",
  journal =      "J. Funct. Program.",
  keywords =     "file-import-09-08-07",
  number =       "5",
  priority =     "2",
  publisher =    "Cambridge University Press",
  title =        "{CPS} transformation of flow information, {P}art {II}:
                 administrative reductions",
  volume =       "13",
  x-address =    "New York, NY, USA",
  xpages =       "925--933",
  year =         "2003",
}

@InProceedings{tip-palsberg-oopsla00,
  author =       "Frank Tip and Jens Palsberg",
  booktitle =    "OOPSLA '00: Proceedings of the 15th ACM SIGPLAN
                 conference on Object-oriented programming, systems,
                 languages, and applications",
  citeulike-article-id = "5395100",
  date-added =   "2009-08-07 21:29:24",
  keywords =     "file-import-09-08-07",
  location =     "Minneapolis, Minnesota, United States",
  priority =     "2",
  publisher =    "ACM",
  title =        "Scalable propagation-based call graph construction
                 algorithms",
  x-address =    "New York, NY, USA",
  xpages =       "281--293",
  year =         "2000",
}

@Article{grove-chambers-toplas01,
  author =       "David Grove and Craig Chambers",
  citeulike-article-id = "5395099",
  date-added =   "2009-08-07 21:29:24",
  journal =      "ACM Trans. Program. Lang. Syst.",
  keywords =     "file-import-09-08-07",
  number =       "6",
  priority =     "2",
  publisher =    "ACM",
  title =        "A framework for call graph construction algorithms",
  volume =       "23",
  x-address =    "New York, NY, USA",
  xpages =       "685--746",
  year =         "2001",
}

@Article{milanova-etal-tosem05,
  author =       "Ana Milanova and Atanas Rountev and Barbara G. Ryder",
  citeulike-article-id = "5395098",
  date-added =   "2009-08-07 21:29:24",
  journal =      "ACM Trans. Softw. Eng. Methodol.",
  keywords =     "file-import-09-08-07",
  number =       "1",
  priority =     "2",
  publisher =    "ACM",
  title =        "Parameterized object sensitivity for points-to
                 analysis for {J}ava",
  volume =       "14",
  x-address =    "New York, NY, USA",
  xpages =       "1--41",
  year =         "2005",
}

@Article{rinetzky-etal-toplas08,
  author =       "N. Rinetzky and G. Ramalingam and M. Sagiv and E.
                 Yahav",
  citeulike-article-id = "5395097",
  date-added =   "2009-08-07 21:29:24",
  journal =      "ACM Trans. Program. Lang. Syst.",
  keywords =     "file-import-09-08-07",
  number =       "3",
  priority =     "2",
  publisher =    "ACM",
  title =        "On the complexity of partially-flow-sensitive alias
                 analysis",
  volume =       "30",
  x-address =    "New York, NY, USA",
  xpages =       "1--28",
  year =         "2008",
}

@InProceedings{emami-etal-pldi94,
  author =       "Maryam Emami and Rakesh Ghiya and Laurie J. Hendren",
  booktitle =    "PLDI '94: Proceedings of the ACM SIGPLAN 1994
                 conference on Programming language design and
                 implementation",
  citeulike-article-id = "5395096",
  date-added =   "2009-08-07 21:29:24",
  keywords =     "file-import-09-08-07",
  location =     "Orlando, Florida, United States",
  priority =     "2",
  publisher =    "ACM",
  title =        "Context-sensitive interprocedural points-to analysis
                 in the presence of function pointers",
  x-address =    "New York, NY, USA",
  xpages =       "242--256",
  year =         "1994",
}

@InProceedings{wilson-lam-pldi95,
  author =       "Robert P. Wilson and Monica S. Lam",
  booktitle =    "PLDI '95: Proceedings of the ACM SIGPLAN 1995
                 conference on Programming language design and
                 implementation",
  citeulike-article-id = "5395095",
  date-added =   "2009-08-07 21:29:24",
  keywords =     "file-import-09-08-07",
  location =     "La Jolla, California, United States",
  priority =     "2",
  publisher =    "ACM",
  title =        "Efficient context-sensitive pointer analysis for {C}
                 programs",
  x-address =    "New York, NY, USA",
  xpages =       "1--12",
  year =         "1995",
}

@PhdThesis{landi-phd92,
  author =       "William Landi",
  citeulike-article-id = "5395094",
  date-added =   "2009-08-07 21:29:24",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  school =       "Rutgers University",
  title =        "Interprocedural Aliasing in the Presence of Pointers",
  year =         "1992",
}

@InProceedings{choi-etal-popl93,
  author =       "Jong D. Choi and Michael Burke and Paul Carini",
  booktitle =    "POPL '93: Proceedings of the 20th ACM SIGPLAN-SIGACT
                 symposium on Principles of programming languages",
  citeulike-article-id = "5395093",
  date-added =   "2009-08-07 21:29:24",
  key =          "POPL 1993",
  keywords =     "file-import-09-08-07",
  location =     "Charleston, South Carolina, United States",
  priority =     "2",
  publisher =    "ACM",
  title =        "Efficient flow-sensitive interprocedural computation
                 of pointer-induced aliases and side effects",
  x-address =    "New York, NY, USA",
  xpages =       "232--245",
  year =         "1993",
}

@Article{ramalingam-toplas94,
  author =       "G. Ramalingam",
  citeulike-article-id = "5395092",
  date-added =   "2009-08-07 21:29:24",
  journal =      "ACM Trans. Program. Lang. Syst.",
  keywords =     "file-import-09-08-07",
  number =       "5",
  priority =     "2",
  publisher =    "ACM",
  title =        "The undecidability of aliasing",
  volume =       "16",
  x-address =    "New York, NY, USA",
  xpages =       "1467--1471",
  year =         "1994",
}

@InProceedings{chakaravarthy-popl03,
  author =       "Venkatesan T. Chakaravarthy",
  booktitle =    "POPL '03: Proceedings of the 30th ACM SIGPLAN-SIGACT
                 symposium on Principles of programming languages",
  citeulike-article-id = "5395091",
  date-added =   "2009-08-07 21:29:24",
  keywords =     "file-import-09-08-07",
  location =     "New Orleans, Louisiana, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "New results on the computability and complexity of
                 points--to analysis",
  x-address =    "New York, NY, USA",
  xpages =       "115--125",
  year =         "2003",
}

@InProceedings{meyers-popl81,
  author =       "Eugene M. Myers",
  booktitle =    "POPL '81: Proceedings of the 8th ACM SIGPLAN-SIGACT
                 symposium on Principles of programming languages",
  citeulike-article-id = "5395090",
  date-added =   "2009-08-07 21:29:24",
  keywords =     "file-import-09-08-07",
  location =     "Williamsburg, Virginia",
  priority =     "2",
  publisher =    "ACM",
  title =        "A precise inter-procedural data flow algorithm",
  x-address =    "New York, NY, USA",
  xpages =       "219--230",
  year =         "1981",
}

@Article{landi-loplas92,
  author =       "William Landi",
  citeulike-article-id = "5395089",
  date-added =   "2009-08-07 21:29:24",
  journal =      "ACM Lett. Program. Lang. Syst.",
  keywords =     "file-import-09-08-07",
  number =       "4",
  priority =     "2",
  publisher =    "ACM",
  title =        "Undecidability of static analysis",
  volume =       "1",
  x-address =    "New York, NY, USA",
  xpages =       "323--337",
  year =         "1992",
}

@InProceedings{defouw-etal-popl98,
  author =       "Greg Defouw and David Grove and Craig Chambers",
  booktitle =    "POPL '98: Proceedings of the 25th ACM SIGPLAN-SIGACT
                 symposium on Principles of programming languages",
  citeulike-article-id = "5395088",
  date-added =   "2009-08-07 21:29:23",
  key =          "POPL 1998",
  keywords =     "file-import-09-08-07",
  location =     "San Diego, California, United States",
  priority =     "2",
  publisher =    "ACM",
  title =        "Fast interprocedural class analysis",
  x-address =    "New York, NY, USA",
  xpages =       "222--236",
  year =         "1998",
}

@Article{chaterjee-etal-tse01,
  author =       "Ramkrishna Chatterjee and Barbara G. Ryder and William
                 A. Landi",
  citeulike-article-id = "5395087",
  date-added =   "2009-08-07 21:29:23",
  journal =      "IEEE Trans. Softw. Eng.",
  keywords =     "file-import-09-08-07",
  number =       "6",
  priority =     "2",
  publisher =    "IEEE Press",
  title =        "Complexity of Points-To Analysis of {J}ava in the
                 Presence of Exceptions",
  volume =       "27",
  x-address =    "Piscataway, NJ, USA",
  xpages =       "481--512",
  year =         "2001",
}

@Article{jones-bohr-lmcs08,
  author =       "Neil D. Jones and Nina Bohr",
  citeulike-article-id = "5395086",
  date-added =   "2009-08-07 21:29:23",
  journal =      "Logical Methods in Computer Science",
  keywords =     "file-import-09-08-07",
  number =       "1",
  priority =     "2",
  title =        "Call-by-value Termination in the Untyped
                 \$\\lambda\$-calculus",
  volume =       "4",
  xpages =       "1--39",
  year =         "2008",
}

@Article{mcallester-jacm02,
  author =       "David Mcallester",
  citeulike-article-id = "5395085",
  date-added =   "2009-08-07 21:29:23",
  journal =      "J. ACM",
  keywords =     "file-import-09-08-07",
  number =       "4",
  priority =     "2",
  publisher =    "ACM",
  title =        "On the complexity analysis of static analyses",
  volume =       "49",
  x-address =    "New York, NY, USA",
  xpages =       "512--537",
  year =         "2002",
}

@TechReport{midtgaard-vanhorn-tr09,
  author =       "Jan Midtgaard and David Van{ }Horn",
  citeulike-article-id = "5395084",
  date-added =   "2009-08-07 21:29:23",
  institution =  "Roskilde University, Denmark",
  keywords =     "file-import-09-08-07",
  month =        may,
  number =       "125",
  priority =     "2",
  title =        "Subcubic Control Flow Analysis Algorithms",
  year =         "2009",
}

@InProceedings{landi-ryder-popl91,
  author =       "William Landi and Barbara G. Ryder",
  booktitle =    "POPL '91: Proceedings of the 18th ACM SIGPLAN-SIGACT
                 symposium on Principles of programming languages",
  citeulike-article-id = "5395083",
  date-added =   "2009-08-07 21:29:23",
  key =          "POPL 1991",
  keywords =     "file-import-09-08-07",
  location =     "Orlando, Florida, United States",
  priority =     "2",
  publisher =    "ACM",
  title =        "Pointer-induced aliasing: a problem taxonomy",
  x-address =    "New York, NY, USA",
  xpages =       "93--103",
  year =         "1991",
}

@InProceedings{landi-ryder-pldi92retro,
  author =       "William Landi and Barbara G. Ryder",
  citeulike-article-id = "5395082",
  date-added =   "2009-08-07 21:29:23",
  keywords =     "file-import-09-08-07",
  number =       "4",
  priority =     "2",
  publisher =    "ACM",
  title =        "A safe approximate algorithm for interprocedural
                 pointer aliasing",
  volume =       "39",
  x-address =    "New York, NY, USA",
  x-editor =     "Mckinley, Kathryn S.",
  xpages =       "473--489",
  year =         "2004",
}

@Book{pldi-best04,
  citeulike-article-id = "5395081",
  date-added =   "2009-08-07 21:29:23",
  keywords =     "file-import-09-08-07",
  number =       "4",
  priority =     "2",
  publisher =    "ACM",
  title =        "{SIGPLAN} Not., Special Issue: 20 Years of {PLDI}
                 (1979 - 1999): {A} Selection",
  volume =       "39",
  x-address =    "New York, NY, USA",
  x-editor =     "Mckinley, Kathryn S.",
  year =         "2004",
}

@PhdThesis{andersen-phd94,
  author =       "Lars O. Andersen",
  citeulike-article-id = "5395080",
  date-added =   "2009-08-07 21:29:23",
  keywords =     "file-import-09-08-07",
  month =        may,
  priority =     "2",
  school =       "DIKU, University of Copenhagen",
  title =        "Program Analysis and Specialization for the {C}
                 Programming Language",
  year =         "1994",
}

@InProceedings{henglein-fplca91,
  author =       "Fritz Henglein",
  booktitle =    "Proceedings of the 5th ACM Conference on Functional
                 Programming Languages and Computer Architecture",
  citeulike-article-id = "5395079",
  date-added =   "2009-08-07 21:29:23",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "Efficient Type Inference for {Higher-Order}
                 {Binding-Time} Analysis",
  x-address =    "London, UK",
  xpages =       "448--472",
  year =         "1991",
}

@InProceedings{hind-paste01,
  author =       "Michael Hind",
  booktitle =    "PASTE '01: Proceedings of the 2001 ACM SIGPLAN-SIGSOFT
                 Workshop on Program Analysis for Software Tools and
                 Engineering",
  citeulike-article-id = "5395078",
  date-added =   "2009-08-07 21:29:23",
  keywords =     "file-import-09-08-07",
  location =     "Snowbird, Utah, United States",
  priority =     "2",
  publisher =    "ACM",
  title =        "Pointer analysis: haven't we solved this problem
                 yet?",
  x-address =    "New York, NY, USA",
  xpages =       "54--61",
  year =         "2001",
}

@InProceedings{steensgaard-popl96,
  author =       "Bjarne Steensgaard",
  booktitle =    "POPL '96: Proceedings of the 23rd ACM SIGPLAN-SIGACT
                 Symposium on Principles of Programming Languages",
  citeulike-article-id = "5395077",
  date-added =   "2009-08-07 21:29:23",
  keywords =     "file-import-09-08-07",
  location =     "St. Petersburg Beach, Florida, United States",
  priority =     "2",
  publisher =    "ACM",
  title =        "Points-to analysis in almost linear time",
  x-address =    "New York, NY, USA",
  xpages =       "32--41",
  year =         "1996",
}

@Article{horwitz-toplas97,
  author =       "Susan Horwitz",
  citeulike-article-id = "5395076",
  date-added =   "2009-08-07 21:29:23",
  journal =      "ACM Trans. Program. Lang. Syst.",
  keywords =     "file-import-09-08-07",
  number =       "1",
  priority =     "2",
  publisher =    "ACM",
  title =        "Precise flow-insensitive may-alias analysis is
                 {NP}-hard",
  volume =       "19",
  x-address =    "New York, NY, USA",
  xpages =       "1--6",
  year =         "1997",
}

@InProceedings{landi-ryder-pldi92,
  author =       "William Landi and Barbara G. Ryder",
  booktitle =    "PLDI '92: Proceedings of the ACM SIGPLAN 1992
                 conference on Programming language design and
                 implementation",
  citeulike-article-id = "5395075",
  date-added =   "2009-08-07 21:29:23",
  keywords =     "file-import-09-08-07",
  location =     "San Francisco, California, United States",
  priority =     "2",
  publisher =    "ACM",
  title =        "A safe approximate algorithm for interprocedural
                 aliasing",
  x-address =    "New York, NY, USA",
  xpages =       "235--248",
  year =         "1992",
}

@InProceedings{muth-debray-popl00,
  author =       "Robert Muth and Saumya Debray",
  booktitle =    "POPL '00: Proceedings of the 27th ACM SIGPLAN-SIGACT
                 symposium on Principles of programming languages",
  citeulike-article-id = "5395074",
  date-added =   "2009-08-07 21:29:23",
  keywords =     "file-import-09-08-07",
  location =     "Boston, MA, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "On the complexity of flow-sensitive dataflow
                 analyses",
  x-address =    "New York, NY, USA",
  xpages =       "67--80",
  year =         "2000",
}

@InProceedings{ullman-allen-sfcs86,
  author =       "Jeffrey D. Ullman and Allen {.} {Gelder}",
  booktitle =    "SFCS '86: Proceedings of the 27th Annual Symposium on
                 Foundations of Computer Science (sfcs 1986)",
  citeulike-article-id = "5395073",
  date-added =   "2009-08-07 21:29:23",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "IEEE Computer Society",
  title =        "Parallel complexity of logical query programs",
  x-address =    "Washington, DC, USA",
  xpages =       "438--454",
  year =         "1986",
}

@InProceedings{tiuryn-mfcs90,
  author =       "Jerzy Tiuryn",
  booktitle =    "MFCS '90: Proceedings on Mathematical foundations of
                 computer science 1990",
  citeulike-article-id = "5395072",
  date-added =   "2009-08-07 21:29:23",
  keywords =     "file-import-09-08-07",
  location =     "Banska\\'{} Bystrica, Czechoslovakia",
  priority =     "2",
  publisher =    "Springer-Verlag New York, Inc.",
  title =        "Type inference problems: a survey",
  x-address =    "New York, NY, USA",
  xpages =       "105--120",
  year =         "1990",
}

@Article{curry-dialectica69,
  author =       "Haskell B. Curry",
  citeulike-article-id = "5395071",
  date-added =   "2009-08-07 21:29:23",
  journal =      "Dialectica",
  keywords =     "file-import-09-08-07",
  number =       "2",
  priority =     "2",
  title =        "Modified basic functionality in combinatory logic",
  volume =       "23",
  xpages =       "83--92",
  year =         "1969",
}

@InProceedings{kfoury-etal-icfp99,
  author =       "Assaf J. Kfoury and Harry G. Mairson and Franklyn A.
                 Turbak and J. B. Wells",
  booktitle =    "ICFP '99: Proceedings of the fourth ACM SIGPLAN
                 international conference on Functional programming",
  citeulike-article-id = "5395070",
  date-added =   "2009-08-07 21:29:23",
  keywords =     "file-import-09-08-07",
  location =     "Paris, France",
  priority =     "2",
  publisher =    "ACM",
  title =        "Relating typability and expressiveness in finite-rank
                 intersection type systems (extended abstract)",
  x-address =    "New York, NY, USA",
  xpages =       "90--101",
  year =         "1999",
}

@Article{hindley-tcs89,
  author =       "J. Roger Hindley",
  citeulike-article-id = "5395069",
  date-added =   "2009-08-07 21:29:23",
  journal =      "Theor. Comput. Sci.",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  title =        "{BCK}-combinators and linear \$\\lambda\$-terms have
                 types",
  volume =       "64",
  xpages =       "97--105",
  year =         "1989",
}

@InProceedings{hirokawa-tacs91,
  author =       "Sachio Hirokawa",
  booktitle =    "TACS '91: Proceedings of the International Conference
                 on Theoretical Aspects of Computer Software",
  citeulike-article-id = "5395068",
  date-added =   "2009-08-07 21:29:23",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "Principal Type-Schemes of {BCI}-Lambda-Terms",
  x-address =    "London, UK",
  xpages =       "633--650",
  year =         "1991",
}

@InProceedings{kanellakis-etal-robinson,
  author =       "Paris C. Kanellakis and Harry G. Mairson and John C.
                 Mitchell",
  booktitle =    "Computational Logic: Essays in Honor of Alan
                 Robinson",
  citeulike-article-id = "5395067",
  date-added =   "2009-08-07 21:29:23",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "MIT Press",
  title =        "Unification and {ML}-Type Reconstruction",
  xpages =       "444--478",
  year =         "1991",
}

@InProceedings{barendregt-volb,
  author =       "Henk P. Barendregt",
  citeulike-article-id = "5395066",
  date-added =   "2009-08-07 21:29:22",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "MIT Press",
  title =        "Functional programming and lambda calculus",
  x-address =    "Cambridge, MA, USA",
  x-editor =     "van Leeuwen, J.",
  xpages =       "321--363",
  year =         "1990",
}

@Book{volb,
  citeulike-article-id = "5395065",
  date-added =   "2009-08-07 21:29:22",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "MIT Press",
  title =        "Handbook of Theoretical Computer Science (Vol. {B}):
                 Formal Models and Semantics",
  x-address =    "Cambridge, MA, USA",
  x-editor =     "van Leeuwen, J.",
  year =         "1990",
}

@InProceedings{mitchell-volb,
  author =       "John C. Mitchell",
  citeulike-article-id = "5395064",
  date-added =   "2009-08-07 21:29:22",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "MIT Press",
  title =        "Type systems for programming languages",
  x-address =    "Cambridge, MA, USA",
  x-editor =     "van Leeuwen, J.",
  xpages =       "365--458",
  year =         "1990",
}

@Book{garey-johnson,
  author =       "Michael R. Garey and David S. Johnson",
  citeulike-article-id = "5395063",
  date-added =   "2009-08-07 21:29:22",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "W. H. Freeman \& Co.",
  title =        "Computers and Intractability: {A} Guide to the Theory
                 of {NP}-Completeness",
  x-address =    "New York, NY, USA",
  year =         "1979",
}

@Book{paulson,
  author =       "Lawrence C. Paulson",
  citeulike-article-id = "5395062",
  date-added =   "2009-08-07 21:29:22",
  edition =      "Second",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Cambridge University Press",
  title =        "{ML} for the Working Programmer",
  year =         "1996",
}

@InProceedings{jagannathan-etal-popl98,
  author =       "Suresh Jagannathan and Peter Thiemann and Stephen
                 Weeks and Andrew Wright",
  booktitle =    "POPL '98: Proceedings of the 25th ACM SIGPLAN-SIGACT
                 Symposium on Principles of Programming Languages",
  citeulike-article-id = "5395061",
  date-added =   "2009-08-07 21:29:22",
  key =          "POPL 1998",
  keywords =     "file-import-09-08-07",
  location =     "San Diego, California, United States",
  priority =     "2",
  publisher =    "ACM",
  title =        "Single and loving it: must-alias analysis for
                 higher-order languages",
  x-address =    "New York, NY, USA",
  xpages =       "329--341",
  year =         "1998",
}

@TechReport{cardone-hindley-06,
  author =       "Felice Cardone and J. Roger Hindley",
  citeulike-article-id = "5395060",
  comment =      "To appear in {\em Handbook of the History of Logic,
                 Volume 5}, D. M. Gabbay and J. Woods, editors.",
  date-added =   "2009-08-07 21:29:22",
  institution =  "Swansea University Mathematics Department Research
                 Report",
  keywords =     "file-import-09-08-07",
  number =       "MRRS-05-06",
  priority =     "2",
  title =        "History of Lambda-calculus and Combinatory Logic",
  year =         "2006",
}

@Article{hindley-ams69,
  author =       "J. Roger Hindley",
  citeulike-article-id = "5395059",
  date-added =   "2009-08-07 21:29:22",
  journal =      "Transactions of the American Mathematical Society",
  keywords =     "file-import-09-08-07",
  month =        dec,
  priority =     "2",
  title =        "The Principal {Type-Scheme} of an Object in
                 Combinatory Logic",
  xpages =       "29--60",
  year =         "1969",
}

@Book{jones97,
  author =       "Neil D. Jones",
  citeulike-article-id = "5395058",
  date-added =   "2009-08-07 21:29:22",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "MIT Press",
  title =        "Computability and Complexity: From a Programming
                 Perspective",
  x-address =    "Cambridge, MA, USA",
  year =         "1997",
}

@InProceedings{kanellakis-mitchell-popl89,
  author =       "P. C. Kanellakis and J. C. Mitchell",
  booktitle =    "POPL '89: Proceedings of the 16th ACM SIGPLAN-SIGACT
                 symposium on Principles of programming languages",
  citeulike-article-id = "5395057",
  date-added =   "2009-08-07 21:29:22",
  keywords =     "file-import-09-08-07",
  location =     "Austin, Texas, United States",
  priority =     "2",
  publisher =    "ACM",
  title =        "Polymorphic unification and {ML} typing",
  x-address =    "New York, NY, USA",
  xpages =       "105--115",
  year =         "1989",
}

@Article{melski-reps00,
  author =       "David Melski and Thomas Reps",
  citeulike-article-id = "5395056",
  date-added =   "2009-08-07 21:29:22",
  journal =      "Theor. Comput. Sci.",
  keywords =     "file-import-09-08-07",
  number =       "1-2",
  priority =     "2",
  publisher =    "Elsevier Science Publishers Ltd.",
  title =        "Interconvertibility of a class of set constraints and
                 context-free-language reachability",
  volume =       "248",
  x-address =    "Essex, UK",
  xpages =       "29--98",
  year =         "2000",
}

@Article{urzyczyn-mscs97,
  author =       "Pawe{l} Urzyczyn",
  citeulike-article-id = "5395055",
  date-added =   "2009-08-07 21:29:22",
  journal =      "Mathematical. Structures in Comp. Sci.",
  keywords =     "file-import-09-08-07",
  number =       "4",
  priority =     "2",
  publisher =    "Cambridge University Press",
  title =        "Type reconstruction in {F\$\_\\omega\$}",
  volume =       "7",
  x-address =    "New York, NY, USA",
  xpages =       "329--358",
  year =         "1997",
}

@InProceedings{reynolds-pcp74,
  author =       "John C. Reynolds",
  booktitle =    "Programming Symposium, Proceedings Colloque sur la
                 Programmation",
  citeulike-article-id = "5395054",
  date-added =   "2009-08-07 21:29:22",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "Towards a theory of type structure",
  x-address =    "London, UK",
  xpages =       "408--423",
  year =         "1974",
}

@InProceedings{boehm-sfcs85,
  author =       "Hans J. Boehm",
  booktitle =    "SFCS '85: Proceedings of the 26th Annual Symposium on
                 Foundations of Computer Science (sfcs 1985)",
  citeulike-article-id = "5395053",
  date-added =   "2009-08-07 21:29:22",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "IEEE Computer Society",
  title =        "Partial polymorphic type inference is undecidable",
  x-address =    "Washington, DC, USA",
  xpages =       "339--345",
  year =         "1985",
}

@Article{wand-fi87,
  author =       "Mitchell Wand",
  citeulike-article-id = "5395052",
  date-added =   "2009-08-07 21:29:22",
  journal =      "Fundam. Inform.",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  title =        "A simple algorithm and proof for type inference.",
  volume =       "10",
  xpages =       "115--122",
  year =         "1987",
}

@Article{pfenning-fi93,
  author =       "Frank Pfenning",
  citeulike-article-id = "5395051",
  date-added =   "2009-08-07 21:29:22",
  journal =      "Fundam. Inf.",
  keywords =     "file-import-09-08-07",
  number =       "1-2",
  priority =     "2",
  publisher =    "IOS Press",
  title =        "On the undecidability of partial polymorphic type
                 reconstruction",
  volume =       "19",
  x-address =    "Amsterdam, The Netherlands, The Netherlands",
  xpages =       "185--199",
  year =         "1993",
}

@InProceedings{leivant-popl83,
  author =       "Daniel Leivant",
  booktitle =    "POPL '83: Proceedings of the 10th ACM SIGACT-SIGPLAN
                 symposium on Principles of programming languages",
  citeulike-article-id = "5395050",
  date-added =   "2009-08-07 21:29:22",
  keywords =     "file-import-09-08-07",
  location =     "Austin, Texas",
  priority =     "2",
  publisher =    "ACM",
  title =        "Polymorphic type inference",
  x-address =    "New York, NY, USA",
  xpages =       "88--98",
  year =         "1983",
}

@InBook{herbrand,
  author =       "Jacques Herbrand",
  citeulike-article-id = "5395049",
  comment =      "Chapter 5 of Herbrand's PhD, {\it Recherches sur la
                 th\'{e}orie de la de\'{e}monstration}",
  date-added =   "2009-08-07 21:29:22",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Harvard University Press",
  title =        "Investigations in proof theory: The properties of true
                 propositions",
  x-editor =     "{Heijenoort}, Jean {.}",
  xpages =       "525--581",
  year =         "1930",
}

@Book{frege-to-godel,
  citeulike-article-id = "5395048",
  date-added =   "2009-08-07 21:29:22",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Harvard University Press",
  title =        "From Frege to {G}{\"{o}}del: {A} Source Book in
                 Mathematical Logic, 1879--1931",
  x-editor =     "{Heijenoort}, Jean {.}",
  year =         "1967",
}

@Article{robinson-jacm65,
  author =       "J. Alan Robinson",
  citeulike-article-id = "5395047",
  date-added =   "2009-08-07 21:29:22",
  journal =      "J. ACM",
  keywords =     "file-import-09-08-07",
  number =       "1",
  priority =     "2",
  publisher =    "ACM",
  title =        "A {Machine-Oriented} Logic Based on the Resolution
                 Principle",
  volume =       "12",
  x-address =    "New York, NY, USA",
  xpages =       "23--41",
  year =         "1965",
}

@Book{muchnick-jones-81,
  citeulike-article-id = "5395046",
  date-added =   "2009-08-07 21:29:22",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Prentice Hall",
  title =        "Program Flow Analysis: Theory and Applications",
  x-editor =     "Muchnick, Steven S. and Jones, Neil D.",
  year =         "1981",
}

@InProceedings{jones-muchnick-pfa81,
  author =       "Neil D. Jones and Steven S. Muchnick",
  chapter =      "12",
  citeulike-article-id = "5395045",
  date-added =   "2009-08-07 21:29:22",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Prentice Hall",
  title =        "Complexity of flow analysis, inductive assertion
                 synthesis, and a language due to {Dijkstra}",
  x-editor =     "Muchnick, Steven S. and Jones, Neil D.",
  xpages =       "380--393",
  year =         "1981",
}

@InProceedings{jones-muchnick-popl79,
  author =       "Neil D. Jones and Steven S. Muchnick",
  booktitle =    "POPL '79: Proceedings of the 6th ACM SIGACT-SIGPLAN
                 symposium on Principles of programming languages",
  citeulike-article-id = "5395044",
  date-added =   "2009-08-07 21:29:22",
  keywords =     "file-import-09-08-07",
  location =     "San Antonio, Texas",
  priority =     "2",
  publisher =    "ACM",
  title =        "Flow analysis and optimization of {LISP}-like
                 structures",
  x-address =    "New York, NY, USA",
  xpages =       "244--256",
  year =         "1979",
}

@InProceedings{heintze-mcallester-icfp97,
  author =       "Nevin Heintze and David Mcallester",
  booktitle =    "ICFP '97: Proceedings of the second ACM SIGPLAN
                 international conference on Functional programming",
  citeulike-article-id = "5395043",
  date-added =   "2009-08-07 21:29:22",
  keywords =     "file-import-09-08-07",
  location =     "Amsterdam, The Netherlands",
  priority =     "2",
  publisher =    "ACM",
  title =        "On the complexity of set-based analysis",
  x-address =    "New York, NY, USA",
  x-editor =     "Berman, A. Michael",
  xpages =       "150--163",
  year =         "1997",
}

@Article{reps-ai96,
  author =       "Thomas W. Reps",
  citeulike-article-id = "5395042",
  citeulike-linkout-0 = "\#",
  date-added =   "2009-08-07 21:29:22",
  journal =      "Acta Informatica",
  keywords =     "file-import-09-08-07",
  number =       "8",
  priority =     "2",
  title =        "On the Sequential Nature of Interprocedural
                 {Program-Analysis} Problems",
  volume =       "33",
  x-url =        "citeseer.ist.psu.edu/reps95sequential.html",
  xpages =       "739--757",
  year =         "1996",
}

@Article{dwork-et-al-jlp84,
  author =       "Cynthia Dwork and Paris C. Kanellakis and John C.
                 Mitchell",
  citeulike-article-id = "5395041",
  date-added =   "2009-08-07 21:29:22",
  journal =      "J. Log. Program.",
  keywords =     "file-import-09-08-07",
  number =       "1",
  priority =     "2",
  publisher =    "Elsevier Science Inc.",
  title =        "On the sequential nature of unification",
  volume =       "1",
  x-address =    "New York, NY, USA",
  xpages =       "35--50",
  year =         "1984",
}

@Proceedings{DBLP:conf/sas/2008,
  booktitle =    "SAS",
  citeulike-article-id = "5395040",
  date-added =   "2009-08-07 21:29:22",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Springer",
  title =        "Static Analysis, 15th International Symposium, {SAS}
                 2008, Valencia, Spain, July 16-18, 2008. Proceedings",
  volume =       "5079",
  x-editor =     "Alpuente, Mar'{i}a and Vidal, Germ{\'{a}}n",
  x-series =     "Lecture Notes in Computer Science",
  year =         "2008",
}

@InProceedings{comini-etal-sas08,
  author =       "Marco Comini and Ferruccio Damiani and Samuel Vrech",
  booktitle =    "SAS",
  citeulike-article-id = "5395039",
  date-added =   "2009-08-07 21:29:21",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Springer",
  title =        "On Polymorphic Recursion, Type Systems, and Abstract
                 Interpretation",
  volume =       "5079",
  x-editor =     "Alpuente, Mar'{i}a and Vidal, Germ{\'{a}}n",
  x-series =     "Lecture Notes in Computer Science",
  xpages =       "144--158",
  year =         "2008",
}

@InProceedings{midtgaard-jensen-sas-08,
  author =       "Jan Midtgaard and Thomas Jensen",
  booktitle =    "Static Analysis Symposium",
  citeulike-article-id = "5395038",
  date-added =   "2009-08-07 21:29:21",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Springer",
  title =        "A Calculational Approach to {Control-Flow} Analysis by
                 Abstract Interpretation",
  volume =       "5079",
  x-editor =     "Alpuente, Mar\'{\i}a and Vidal, Germ\'{a}n",
  x-series =     "LNCS",
  xpages =       "347--362",
  year =         "2008",
}

@InProceedings{blanc-levy-klop-05,
  author =       "Tomasz Blanc and Jean J. L{\'{e}}vy and Luc Maranget",
  booktitle =    "Processes, Terms and Cycles",
  citeulike-article-id = "5395037",
  date-added =   "2009-08-07 21:29:21",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Springer",
  title =        "Sharing in the Weak {Lambda-Calculus}",
  volume =       "3838",
  x-editor =     "Middeldorp, Aart and van Oostrom, Vincent and van
                 Raamsdonk, Femke and de Vrijer, Roel C.",
  x-series =     "Lecture Notes in Computer Science",
  xpages =       "70--87",
  year =         "2005",
}

@Proceedings{DBLP:conf/birthday/2005klop,
  booktitle =    "Processes, Terms and Cycles",
  citeulike-article-id = "5395036",
  date-added =   "2009-08-07 21:29:21",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Springer",
  title =        "Processes, Terms and Cycles: Steps on the Road to
                 Infinity, Essays Dedicated to Jan Willem Klop, on the
                 Occasion of His 60th Birthday",
  volume =       "3838",
  x-editor =     "Middeldorp, Aart and van Oostrom, Vincent and van
                 Raamsdonk, Femke and de Vrijer, Roel C.",
  x-series =     "Lecture Notes in Computer Science",
  year =         "2005",
}

@InProceedings{kuan-macqueen-ml-07,
  author =       "George Kuan and David Macqueen",
  booktitle =    "ML '07: Proceedings of the 2007 workshop on Workshop
                 on ML",
  citeulike-article-id = "5395035",
  date-added =   "2009-08-07 21:29:21",
  keywords =     "file-import-09-08-07",
  location =     "Freiburg, Germany",
  priority =     "2",
  publisher =    "ACM",
  title =        "Efficient type inference using ranked type variables",
  x-address =    "New York, NY, USA",
  xpages =       "3--14",
  year =         "2007",
}

@InProceedings{chaudhuri-popl08,
  author =       "Swarat Chaudhuri",
  booktitle =    "POPL '08: Proceedings of the 35th annual ACM
                 SIGPLAN-SIGACT symposium on Principles of programming
                 languages",
  citeulike-article-id = "5395034",
  date-added =   "2009-08-07 21:29:21",
  key =          "POPL 2008",
  keywords =     "file-import-09-08-07",
  location =     "San Francisco, California, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "Subcubic algorithms for recursive state machines",
  x-address =    "New York, NY, USA",
  xpages =       "159--169",
  year =         "2008",
}

@Misc{henglein-unpub90,
  author =       "Fritz Henglein",
  citeulike-article-id = "5395033",
  comment =      "Unpublished manuscript",
  date-added =   "2009-08-07 21:29:21",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  title =        "Type Invariant Simulation: {A} Lower Bound Technique
                 for Type Inference",
  year =         "1990",
}

@Article{landin-64,
  author =       "Peter J. Landin",
  citeulike-article-id = "5395032",
  date-added =   "2009-08-07 21:29:21",
  journal =      "The Computer Journal",
  keywords =     "file-import-09-08-07",
  number =       "4",
  priority =     "2",
  title =        "The mechanical evaluation of expressions",
  volume =       "6",
  xpages =       "308--320",
  year =         "1964",
}

@Book{hankin-lambda,
  author =       "Chris Hankin",
  citeulike-article-id = "5395031",
  date-added =   "2009-08-07 21:29:21",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "King's College",
  title =        "An Introduction to Lambda Calculi for Computer
                 Scientists",
  year =         "2004",
}

@PhdThesis{might-phd,
  author =       "Matthew Might",
  citeulike-article-id = "5395030",
  comment =      "Adviser-Olin G. Shivers",
  date-added =   "2009-08-07 21:29:20",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  school =       "Georgia Institute of Technology",
  title =        "Environment analysis of higher-order languages",
  x-address =    "Atlanta, GA, USA",
  year =         "2007",
}

@InProceedings{might-shivers-popl06,
  author =       "Matthew Might and Olin Shivers",
  booktitle =    "POPL '06: Conference record of the 33rd ACM
                 SIGPLAN-SIGACT symposium on Principles of programming
                 languages",
  citeulike-article-id = "5395029",
  date-added =   "2009-08-07 21:29:20",
  keywords =     "file-import-09-08-07",
  location =     "Charleston, South Carolina, USA",
  priority =     "2",
  publisher =    "ACM",
  title =        "Environment analysis via {\$\\Delta\$}{CFA}",
  x-address =    "New York, NY, USA",
  xpages =       "127--140",
  year =         "2006",
}

@Article{cosmo-etal-mscs03,
  author =       "Roberto Di Cosmo and Delia Kesner and Emmanuel
                 Polonovski",
  citeulike-article-id = "5395028",
  date-added =   "2009-08-07 21:29:20",
  journal =      "Mathematical. Structures in Comp. Sci.",
  keywords =     "file-import-09-08-07",
  number =       "3",
  priority =     "2",
  publisher =    "Cambridge University Press",
  title =        "Proof nets and explicit substitutions",
  volume =       "13",
  x-address =    "New York, NY, USA",
  xpages =       "409--450",
  year =         "2003",
}

@Article{girard-tcs87,
  author =       "Jean Y. Girard",
  citeulike-article-id = "5395027",
  date-added =   "2009-08-07 21:29:20",
  journal =      "Theor. Comput. Sci.",
  keywords =     "file-import-09-08-07",
  number =       "1",
  priority =     "2",
  publisher =    "Elsevier Science Publishers Ltd.",
  title =        "Linear logic",
  volume =       "50",
  x-address =    "Essex, UK",
  xpages =       "1--102",
  year =         "1987",
}

@Article{rice,
  author =       "Henry G. Rice",
  citeulike-article-id = "5395026",
  date-added =   "2009-08-07 21:29:20",
  journal =      "Trans. Amer. Math. Soc.",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  title =        "Classes of Recursively Enumerable Sets and Their
                 Decision Problems",
  volume =       "74",
  xpages =       "358--366",
  year =         "1953",
}

@Misc{pllc,
  author =       "Matthias Felleisen and Matthew Flatt",
  citeulike-article-id = "5395025",
  comment =      "Soon to be published manuscript, in development since
                 1989",
  date-added =   "2009-08-07 21:29:20",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  title =        "Programming Languages and Lambda Calculi",
  year =         "2009",
}

@Book{barendregt,
  author =       "Henk P. Barendregt",
  citeulike-article-id = "5395024",
  date-added =   "2009-08-07 21:29:20",
  edition =      "revised",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "North-Holland",
  title =        "The Lambda Calculus: Its Syntax and Semantics",
  volume =       "103",
  x-series =     "Studies in Logic and the Foundations of Mathematics",
  year =         "1984",
}

@Book{eopl1,
  author =       "Daniel P. Friedman and Mitchell Wand and Christopher
                 T. Haynes",
  citeulike-article-id = "5395023",
  date-added =   "2009-08-07 21:29:20",
  edition =      "first",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "MIT Press",
  title =        "Essentials of Programming Languages",
  year =         "1992",
}

@Book{eopl3,
  author =       "Daniel P. Friedman and Mitchell Wand",
  citeulike-article-id = "5395022",
  date-added =   "2009-08-07 21:29:20",
  edition =      "third",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "MIT Press",
  title =        "Essentials of Programming Languages",
  year =         "2008",
}

@Article{reynolds-hosc98,
  author =       "John C. Reynolds",
  citeulike-article-id = "5395021",
  comment =      "Originally published in \emph{ACM'72: Proceedings of
                 the ACM Annual Conference}.",
  date-added =   "2009-08-07 21:29:20",
  journal =      "Higher-Order and Symbolic Computation",
  keywords =     "file-import-09-08-07",
  number =       "4",
  priority =     "2",
  title =        "Definitional Interpreters for {Higher-Order}
                 Programming Languages",
  volume =       "11",
  xpages =       "363--397",
  year =         "1998",
}

@InProceedings{reynolds-acm72,
  author =       "John C. Reynolds",
  booktitle =    "ACM '72: Proceedings of the ACM Annual Conference",
  citeulike-article-id = "5395020",
  comment =      "",
  date-added =   "2009-08-07 21:29:20",
  keywords =     "file-import-09-08-07",
  location =     "Boston, Massachusetts, United States",
  priority =     "2",
  publisher =    "ACM",
  title =        "Definitional interpreters for higher-order programming
                 languages",
  x-address =    "New York, NY, USA",
  xpages =       "717--740",
  year =         "1972",
}

@Book{harper-sml,
  author =       "Robert Harper",
  citeulike-article-id = "5395019",
  comment =      "Published online only:
                 \url{http://www.cs.cmu.edu/\~{}rwh/smlbook/}, Working
                 draft of December 6, 2007.",
  date-added =   "2009-08-07 21:29:20",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  title =        "Programming in Standard {ML}",
  year =         "2005",
}

@Book{sitaram-tyscheme,
  author =       "Dorai Sitaram",
  citeulike-article-id = "5395018",
  comment =      "Published online:
                 \url{http://www.ccs.neu.edu/home/dorai/t-y-scheme/t-y-scheme.html}",
  date-added =   "2009-08-07 21:29:20",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  title =        "Teach Yourself Scheme in Fixnum Days",
  year =         "2004",
}

@Book{dybvig-tspl,
  annote =       "Introduction and reference manual for ANSI Standard
                 Scheme with numerous short and extended examples and
                 exercises.",
  author =       "R. Kent Dybvig",
  citeulike-article-id = "5395017",
  comment =      "Published online: \url{http://www.scheme.com/tspl3/}",
  date-added =   "2009-08-07 21:29:20",
  edition =      "Third",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "{MIT} Press",
  title =        "The {Scheme} Programming Language",
  year =         "2002",
}

@PhdThesis{sampath-phd,
  author =       "Prahladavaradan Sampath",
  citeulike-article-id = "5395016",
  date-added =   "2009-08-07 21:29:20",
  keywords =     "file-import-09-08-07",
  month =        jan,
  priority =     "2",
  school =       "Imperial College, University of London",
  title =        "Program Analysis using Game Semantics",
  year =         "2000",
}

@Article{hankin-malacaria-cs99,
  author =       "Chris Hankin and Pasquale Malacaria",
  citeulike-article-id = "5395015",
  date-added =   "2009-08-07 21:29:20",
  journal =      "ACM Comput. Surv.",
  keywords =     "file-import-09-08-07",
  number =       "3",
  priority =     "2",
  publisher =    "ACM",
  title =        "Program analysis games",
  volume =       "31",
  x-address =    "New York, NY, USA",
  year =         "1999",
}

@InProceedings{jones-nielson,
  author =       "Neil D. Jones and Flemming Nielson",
  citeulike-article-id = "5395014",
  date-added =   "2009-08-07 21:29:19",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Oxford University Press",
  title =        "Abstract interpretation: a semantics-based tool for
                 program analysis",
  x-address =    "Oxford, UK",
  x-editor =     "Abramsky, S. and Gabbay, Dov M. and Maibaum, T. S.
                 E.",
  xpages =       "527--636",
  year =         "1995",
}

@Book{handbook-of-logic,
  citeulike-article-id = "5395013",
  date-added =   "2009-08-07 21:29:19",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Oxford University Press",
  title =        "Handbook of logic in computer science (vol. 4):
                 semantic modelling",
  x-address =    "Oxford, UK",
  x-editor =     "Abramsky, S. and Gabbay, Dov M. and Maibaum, T. S.
                 E.",
  year =         "1995",
}

@InProceedings{Cousot:1977:AI,
  author =       "Patrick Cousot and Radhia Cousot",
  booktitle =    "Proceedings of the 4th ACM SIGACT-SIGPLAN Symposium on
                 Principles of Programming Languages",
  citeulike-article-id = "5395012",
  date-added =   "2009-08-07 21:29:19",
  keywords =     "file-import-09-08-07",
  location =     "Los Angeles, California",
  priority =     "2",
  publisher =    "ACM",
  title =        "Abstract interpretation: a unified lattice model for
                 static analysis of programs by construction or
                 approximation of fixpoints",
  x-address =    "New York, NY, USA",
  xpages =       "238--252",
  year =         "1977",
}

@Article{cousot-cousot-jlc92,
  author =       "Patrick Cousot and Radhia Cousot",
  citeulike-article-id = "5395011",
  date-added =   "2009-08-07 21:29:19",
  journal =      "Journal of Logic and Computation",
  keywords =     "file-import-09-08-07",
  month =        aug,
  number =       "4",
  priority =     "2",
  publisher =    "Oxford University Press, Oxford, UK",
  title =        "Abstract Interpretation Frameworks",
  volume =       "2",
  xpages =       "511--547",
  year =         "1992",
}

@Book{curry-fest,
  citeulike-article-id = "5395010",
  date-added =   "2009-08-07 21:29:19",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Academic Press",
  title =        "To {H}. {B}. Curry: Essays on Combinatory Logic,
                 Lambda Calculus and Formalism",
  x-address =    "London",
  x-editor =     "Seldin, Jonathan P. and Hindley, J. Roger",
  year =         "1980",
}

@InProceedings{howard,
  author =       "William A. Howard",
  citeulike-article-id = "5395009",
  date-added =   "2009-08-07 21:29:19",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Academic Press",
  title =        "The formulae-as-types notion of construction",
  x-address =    "London",
  x-editor =     "Seldin, Jonathan P. and Hindley, J. Roger",
  xpages =       "479--490",
  year =         "1980",
}

@Book{sorensen-urzyczyn,
  author =       "Morten H. S{o}rensen and Pawel Urzyczyn",
  citeulike-article-id = "5395008",
  date-added =   "2009-08-07 21:29:19",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Elsevier Science Inc.",
  title =        "Lectures on the {Curry-Howard} Isomorphism",
  volume =       "149",
  x-address =    "New York, NY, USA",
  x-series =     "Studies in Logic and the Foundations of Mathematics",
  year =         "2006",
}

@Article{wells-apal99,
  author =       "J. B. Wells",
  citeulike-article-id = "5395007",
  date-added =   "2009-08-07 21:29:19",
  journal =      "Annals of Pure and Applied Logic",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  title =        "Typability and type checking in {S}ystem {F} are
                 equivalent and undecidable",
  volume =       "98",
  xpages =       "111--156",
  year =         "1999",
}

@Book{Papadimitriou94,
  author =       "Christos H. Papadimitriou",
  citeulike-article-id = "5395006",
  date-added =   "2009-08-07 21:29:19",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Addison-Wesley",
  title =        "Computational Complexity",
  x-address =    "Reading, MA",
  year =         "1994",
}

@InProceedings{sereni-jones-aplas05,
  author =       "Damien Sereni and Neil D. Jones",
  booktitle =    "Programming Languages and Systems, Third Asian
                 Symposium, APLAS 2005, Tsukuba, Japan, November 2-5,
                 2005, Proceedings",
  citeulike-article-id = "5395005",
  date-added =   "2009-08-07 21:29:19",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Springer",
  title =        "Termination Analysis of {Higher-Order} Functional
                 Programs",
  volume =       "3780",
  x-editor =     "Yi, Kwangkeun",
  x-series =     "Lecture Notes in Computer Science",
  xpages =       "281--297",
  year =         "2005",
}

@InProceedings{sereni-icfp07,
  author =       "Damien Sereni",
  booktitle =    "ICFP '07: Proceedings of the 12th ACM SIGPLAN
                 International Conference on Functional Programming,
                 Freiburg, Germany, October 1--3, 2007",
  citeulike-article-id = "5395004",
  date-added =   "2009-08-07 21:29:19",
  key =          "ICFP'07",
  keywords =     "file-import-09-08-07",
  location =     "Freiburg, Germany",
  priority =     "2",
  publisher =    "ACM",
  title =        "Termination analysis and call graph construction for
                 higher-order functional programs",
  x-address =    "New York, NY, USA",
  x-editor =     "Hinze, Ralf and Ramsey, Norman",
  xpages =       "71--84",
  year =         "2007",
}

@Book{sicp,
  author =       "Harold Abelson and Gerald J. Sussman",
  citeulike-article-id = "5395003",
  date-added =   "2009-08-07 21:29:19",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "MIT Press",
  title =        "Structure and Interpretation of Computer Programs",
  x-address =    "Cambridge, MA, USA",
  year =         "1996",
}

@InProceedings{Might:2006:GammaCFA,
  author =       "Matthew Might and Olin Shivers",
  booktitle =    "Proceedings of the 11th ACM SIGPLAN International
                 Conference on Functional Programming",
  citeulike-article-id = "5395002",
  comment =      "ICFP'06",
  date-added =   "2009-08-07 21:29:19",
  keywords =     "file-import-09-08-07",
  month =        sep,
  priority =     "2",
  title =        "Improving Flow Analyses via \({\Gamma}\){CFA}:
                 Abstract Garbage Collection and Counting",
  x-address =    "Portland, Oregon",
  xpages =       "13--25",
  year =         "2006",
}

@InBook{hankin-games,
  author =       "Chris Hankin and Rajagopal Nagarajan and
                 Prahladavaradan Sampath",
  chapter =      "Flow analysis: games and nets",
  citeulike-article-id = "5395001",
  date-added =   "2009-08-07 21:29:18",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Springer-Verlag New York, Inc.",
  title =        "The essence of computation: complexity, analysis,
                 transformation",
  x-address =    "New York, NY, USA",
  xpages =       "135--156",
  year =         "2002",
}

@Article{mossin-njc98,
  author =       "Christian Mossin",
  citeulike-article-id = "5395000",
  date-added =   "2009-08-07 21:29:18",
  journal =      "Nordic J. of Computing",
  keywords =     "file-import-09-08-07",
  number =       "3",
  priority =     "2",
  publisher =    "Publishing Association Nordic Journal of Computing",
  title =        "Higher-order value flow graphs",
  volume =       "5",
  x-address =    "Finland",
  xpages =       "214--234",
  year =         "1998",
}

@PhdThesis{neergaard-phd,
  author =       "Peter {{Mo Ller} Neergaard}",
  citeulike-article-id = "5394999",
  date-added =   "2009-08-07 21:29:18",
  keywords =     "file-import-09-08-07",
  month =        oct,
  priority =     "2",
  school =       "Brandeis University",
  title =        "Complexity Aspects of Programming Language Design:
                 From Logspace to Elementary Time via Proofnets and
                 Intersection Types",
  x-address =    "Waltham, Massachusetts",
  year =         "2004",
}

@Article{ashley-dybvig-toplas98,
  author =       "J. Michael Ashley and R. Kent Dybvig",
  citeulike-article-id = "5394998",
  date-added =   "2009-08-07 21:29:18",
  journal =      "ACM Trans. Program. Lang. Syst.",
  keywords =     "file-import-09-08-07",
  number =       "4",
  priority =     "2",
  publisher =    "ACM",
  title =        "A practical and flexible flow analysis for
                 higher-order languages",
  volume =       "20",
  x-address =    "New York, NY, USA",
  xpages =       "845--868",
  year =         "1998",
}

@InProceedings{burn-hankin-abramsky,
  author =       "G. L. Burn and C. L. Hankin and S. Abramsky",
  booktitle =    "Programs as data objects",
  citeulike-article-id = "5394997",
  date-added =   "2009-08-07 21:29:18",
  keywords =     "file-import-09-08-07",
  location =     "Copenhagen, Denmark",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "The theory of strictness analysis for higher order
                 functions",
  x-address =    "New York, NY, USA",
  x-editor =     "Ganzinger, H. and Jones, N.",
  xpages =       "42--62",
  year =         "1985",
}

@Article{gmsv,
  author =       "Haim Gaifman and Harry Mairson and Yehoshua Sagiv and
                 Moshe Y. Vardi",
  citeulike-article-id = "5394996",
  date-added =   "2009-08-07 21:29:18",
  journal =      "J. ACM",
  keywords =     "file-import-09-08-07",
  number =       "3",
  priority =     "2",
  publisher =    "ACM",
  title =        "Undecidable optimization problems for database logic
                 programs",
  volume =       "40",
  x-address =    "New York, NY, USA",
  xpages =       "683--713",
  year =         "1993",
}

@Article{hkmv,
  author =       "Gerd G. Hillebrand and Paris C. Kanellakis and Harry
                 G. Mairson and Moshe Y. Vardi",
  citeulike-article-id = "5394995",
  date-added =   "2009-08-07 21:29:18",
  journal =      "J. Logic Program.",
  keywords =     "file-import-09-08-07",
  number =       "2",
  priority =     "2",
  title =        "Undecidable Boundedness Problems for Datalog
                 Programs",
  volume =       "25",
  xpages =       "163--190",
  year =         "1995",
}

@InProceedings{schubert-tcla01,
  author =       "Aleksy Schubert",
  booktitle =    "Typed Lambda Calculi and Applications, 5th
                 International Conference, TLCA 2001, Krakow, Poland,
                 May 2-5, 2001, Proceedings",
  citeulike-article-id = "5394994",
  date-added =   "2009-08-07 21:29:18",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Springer",
  title =        "The Complexity of {beta-Reduction} in Low Orders.",
  volume =       "2044",
  x-series =     "Lecture Notes in Computer Science",
  xpages =       "400--414",
  year =         "2001",
}

@Article{Midtgaard2011Controlflow,
  author =       "Jan Midtgaard",
  citeulike-article-id = "5394993",
  comment =      "To appear.",
  date-added =   "2009-08-07 21:29:18",
  journal =      "ACM Computing Surveys",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  title =        "Control-flow analysis of functional programs",
  year =         "2011",
}

@PhdThesis{kam-76,
  author =       "John B. Kam",
  citeulike-article-id = "5394992",
  date-added =   "2009-08-07 21:29:18",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  school =       "Princeton University",
  title =        "Monotone data flow analysis frameworks: a formal
                 theory of global computer program optimization.",
  x-address =    "Princeton, NJ, USA",
  year =         "1976",
}

@Article{kam-ullman-76,
  author =       "John B. Kam and Jeffrey D. Ullman",
  citeulike-article-id = "5394991",
  date-added =   "2009-08-07 21:29:18",
  journal =      "J. ACM",
  keywords =     "file-import-09-08-07",
  number =       "1",
  priority =     "2",
  publisher =    "ACM",
  title =        "Global Data Flow Analysis and Iterative Algorithms",
  volume =       "23",
  x-address =    "New York, NY, USA",
  xpages =       "158--171",
  year =         "1976",
}

@Book{hecht,
  author =       "Matthew S. Hecht",
  citeulike-article-id = "5394990",
  date-added =   "2009-08-07 21:29:18",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Elsevier Science Inc.",
  title =        "Flow Analysis of Computer Programs",
  x-address =    "New York, NY, USA",
  year =         "1977",
}

@Book{mackay,
  author =       "David J. C. Mackay",
  citeulike-article-id = "5394989",
  date-added =   "2009-08-07 21:29:18",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Cambridge University Press",
  title =        "Information Theory, Inference \& Learning Algorithms",
  x-address =    "New York, NY, USA",
  year =         "2002",
}

@Article{shannon,
  author =       "Claude E. Shannon",
  citeulike-article-id = "5394988",
  date-added =   "2009-08-07 21:29:18",
  journal =      "Bell System Technical Journal",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  title =        "A mathematical theory of communication",
  volume =       "27",
  year =         "1948",
}

@TechReport{henglein92d,
  author =       "Fritz Henglein",
  citeulike-article-id = "5394987",
  comment =      "DIKU Semantics Report D-193",
  date-added =   "2009-08-07 21:29:17",
  keywords =     "file-import-09-08-07",
  month =        mar,
  priority =     "2",
  title =        "Simple Closure Analysis",
  year =         "1992",
}

@InProceedings{lafont-ll95,
  author =       "Yves Lafont",
  booktitle =    "Proceedings of the workshop on Advances in linear
                 logic",
  citeulike-article-id = "5394986",
  date-added =   "2009-08-07 21:29:17",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Cambridge University Press",
  title =        "From proof-nets to interaction nets",
  x-address =    "New York, NY, USA",
  xpages =       "225--247",
  year =         "1995",
}

@InProceedings{mossin-sas97,
  author =       "Christian Mossin",
  booktitle =    "SAS '97: Proceedings of the 4th International
                 Symposium on Static Analysis",
  citeulike-article-id = "5394985",
  date-added =   "2009-08-07 21:29:17",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "Exact Flow Analysis",
  x-address =    "London, UK",
  xpages =       "250--264",
  year =         "1997",
}

@Book{jones-et-al-93,
  author =       "Neil D. Jones and Carsten K. Gomard and Peter
                 Sestoft",
  citeulike-article-id = "5394984",
  date-added =   "2009-08-07 21:29:17",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Prentice-Hall, Inc.",
  title =        "Partial evaluation and automatic program generation",
  x-address =    "Upper Saddle River, NJ, USA",
  year =         "1993",
}

@Article{danvy-et-al-toplas96,
  author =       "Olivier Danvy and Karoline Malmkjae and Jens
                 Palsberg",
  citeulike-article-id = "5394983",
  date-added =   "2009-08-07 21:29:17",
  journal =      "ACM Trans. Program. Lang. Syst.",
  keywords =     "file-import-09-08-07",
  number =       "6",
  priority =     "2",
  publisher =    "ACM Press",
  title =        "Eta-expansion does The Trick",
  volume =       "18",
  x-address =    "New York, NY, USA",
  xpages =       "730--751",
  year =         "1996",
}

@Article{banerjee-jensen-mscs03,
  author =       "Anindya Banerjee and Thomas Jensen",
  citeulike-article-id = "5394982",
  date-added =   "2009-08-07 21:29:17",
  journal =      "Mathematical. Structures in Comp. Sci.",
  keywords =     "file-import-09-08-07",
  number =       "1",
  priority =     "2",
  publisher =    "Cambridge University Press",
  title =        "Modular control-flow analysis with rank 2 intersection
                 types",
  volume =       "13",
  x-address =    "New York, NY, USA",
  xpages =       "87--124",
  year =         "2003",
}

@InProceedings{DBLP:conf/ictcs/MairsonT03,
  author =       "Harry G. Mairson and Kazushige Terui",
  booktitle =    "Theoretical Computer Science, 8th Italian Conference,
                 ICTCS 2003, Bertinoro, Italy, October 13-15, 2003,
                 Proceedings",
  citeulike-article-id = "5394981",
  date-added =   "2009-08-07 21:29:16",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Springer",
  title =        "On the Computational Complexity of {Cut-Elimination}
                 in Linear Logic",
  volume =       "2841",
  x-editor =     "Blundo, Carlo and Laneve, Cosimo",
  x-series =     "Lecture Notes in Computer Science",
  xpages =       "23--36",
  year =         "2003",
}

@InProceedings{danvy-filinksi-lfp90,
  author =       "Olivier Danvy and Andrzej Filinski",
  booktitle =    "Proceedings of the 1990 ACM Conference on LISP and
                 Functional Programming",
  citeulike-article-id = "5394980",
  date-added =   "2009-08-07 21:29:16",
  keywords =     "file-import-09-08-07",
  location =     "Nice, France",
  priority =     "2",
  publisher =    "ACM Press",
  title =        "Abstracting control",
  x-address =    "New York, NY, USA",
  xpages =       "151--160",
  year =         "1990",
}

@InProceedings{parigot-lpar92,
  author =       "Michel Parigot",
  booktitle =    "Logic Programming and Automated
                 Reasoning,International Conference LPAR'92, St.
                 Petersburg, Russia, July 15-20, 1992, Proceedings",
  citeulike-article-id = "5394979",
  date-added =   "2009-08-07 21:29:16",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Springer",
  title =        "\$\\{lambda\\mu\$-Calculus}: An Algorithmic
                 Interpretation of Classical Natural Deduction",
  volume =       "624",
  x-series =     "Lecture Notes in Computer Science",
  xpages =       "190--201",
  year =         "1992",
}

@InProceedings{filinski-ctcs89,
  author =       "Andrzej Filinski",
  booktitle =    "Category Theory and Computer Science",
  citeulike-article-id = "5394978",
  date-added =   "2009-08-07 21:29:16",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "Declarative Continuations: an Investigation of Duality
                 in Programming Language Semantics",
  x-address =    "London, UK",
  xpages =       "224--249",
  year =         "1989",
}

@InProceedings{lafont-proofs-and-types,
  author =       "Yves Lafont",
  citeulike-article-id = "5394977",
  comment =      "Reprinted with corrections 1990",
  date-added =   "2009-08-07 21:29:16",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Cambridge University Press",
  title =        "What is Linear Logic?",
  x-address =    "New York, NY, USA",
  xpages =       "149--160",
  year =         "1989",
}

@Book{girard-proofs-and-types,
  author =       "Jean Y. Girard and Paul Taylor and Yves Lafont",
  citeulike-article-id = "5394976",
  comment =      "Reprinted with corrections 1990",
  date-added =   "2009-08-07 21:29:16",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Cambridge University Press",
  title =        "Proofs and types",
  x-address =    "New York, NY, USA",
  year =         "1989",
}

@Article{asperti-laneve-tcs95,
  author =       "Andrea Asperti and Cosimo Laneve",
  citeulike-article-id = "5394975",
  date-added =   "2009-08-07 21:29:16",
  journal =      "Theor. Comput. Sci.",
  keywords =     "file-import-09-08-07",
  number =       "2",
  priority =     "2",
  publisher =    "Elsevier Science Publishers Ltd.",
  title =        "Paths, computations and labels in the
                 \$\\lambda\$-calculus",
  volume =       "142",
  x-address =    "Essex, UK",
  xpages =       "277--297",
  year =         "1995",
}

@PhdThesis{Mossin:97:FlowAnalysis,
  author =       "Christian Mossin",
  citeulike-article-id = "5394974",
  date-added =   "2009-08-07 21:29:16",
  keywords =     "analysis, data, file-import-09-08-07, flow, types",
  month =        jan,
  priority =     "2",
  school =       "DIKU, University of Copenhagen",
  title =        "Flow Analysis of Typed {Higher-Order} Programs",
  year =         "1997",
}

@Misc{mairson-unpub06,
  author =       "Harry G. Mairson",
  citeulike-article-id = "5394973",
  comment =      "Unpublished manuscript",
  date-added =   "2009-08-07 21:29:16",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  title =        "Axiom-sensitive normalization bounds for
                 multiplicative linear logic",
  year =         "2006",
}

@InProceedings{mairson-popl90,
  author =       "Harry G. Mairson",
  booktitle =    "POPL '90: Proceedings of the 17th ACM SIGPLAN-SIGACT
                 Symposium on Principles of Programming Languages",
  citeulike-article-id = "5394972",
  date-added =   "2009-08-07 21:29:16",
  key =          "POPL 1990",
  keywords =     "file-import-09-08-07",
  location =     "San Francisco, California, United States",
  priority =     "2",
  publisher =    "ACM Press",
  title =        "Deciding {ML} typability is complete for deterministic
                 exponential time",
  x-address =    "New York, NY, USA",
  xpages =       "382--401",
  year =         "1990",
}

@InProceedings{girard-goi89,
  author =       "Jean Y. Girard",
  booktitle =    "Logic Colloquium '88",
  citeulike-article-id = "5394971",
  date-added =   "2009-08-07 21:29:16",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "North Holland",
  title =        "Geometry of interaction {I}: Interpretation of
                 {S}ystem {F}",
  x-editor =     "Bonotto, C.",
  xpages =       "221--260",
  year =         "1989",
}

@InProceedings{mairson-icfp03,
  author =       "Harry G. Mairson",
  booktitle =    "ICFP '03: Proceedings of the eighth ACM SIGPLAN
                 International Conference on Functional Programming",
  citeulike-article-id = "5394970",
  comment =      "Invited talk",
  date-added =   "2009-08-07 21:29:16",
  keywords =     "file-import-09-08-07",
  location =     "Uppsala, Sweden",
  priority =     "2",
  publisher =    "ACM Press",
  title =        "From {H}ilbert space to {D}ilbert space: context
                 semantics as a language for games and flow analysis",
  x-address =    "New York, NY, USA",
  xpages =       "125",
  year =         "2003",
}

@InProceedings{banerjee-icfp97,
  author =       "Anindya Banerjee",
  booktitle =    "ICFP '97: Proceedings of the second ACM SIGPLAN
                 International Conference on Functional Programming",
  citeulike-article-id = "5394969",
  comment =      "ICFP '97",
  date-added =   "2009-08-07 21:29:16",
  keywords =     "file-import-09-08-07",
  location =     "Amsterdam, The Netherlands",
  priority =     "2",
  publisher =    "ACM",
  title =        "A modular, polyvariant and type-based closure
                 analysis",
  x-address =    "New York, NY, USA",
  x-editor =     "Berman, A. Michael",
  xpages =       "1--10",
  year =         "1997",
}

@InProceedings{faxen-lomaps97,
  author =       "Karl F. Fax\'{e}n",
  booktitle =    "Selected papers from the 5th LOMAPS Workshop on
                 Analysis and Verification of Multiple-Agent Languages",
  citeulike-article-id = "5394968",
  date-added =   "2009-08-07 21:29:16",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "Polyvariance, Polymorphism and Flow Analysis",
  x-address =    "London, UK",
  xpages =       "260--278",
  year =         "1997",
}

@InProceedings{faxen-sas95,
  author =       "Karl F. Fax{\'{e}}n",
  booktitle =    "SAS",
  citeulike-article-id = "5394967",
  date-added =   "2009-08-07 21:29:16",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Springer",
  title =        "Optimizing Lazy Functional Programs Using Flow
                 Inference",
  volume =       "983",
  x-editor =     "Mycroft, Alan",
  x-series =     "Lecture Notes in Computer Science",
  xpages =       "136--153",
  year =         "1995",
}

@InProceedings{tang-jouvelot-tacs94,
  author =       "Yan M. Tang and Pierre Jouvelot",
  booktitle =    "TACS '94: Proceedings of the International Conference
                 on Theoretical Aspects of Computer Software",
  citeulike-article-id = "5394966",
  date-added =   "2009-08-07 21:29:16",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "Separate Abstract Interpretation for {Control-Flow}
                 Analysis",
  x-address =    "London, UK",
  xpages =       "224--243",
  year =         "1994",
}

@InProceedings{sestoft-fpca89,
  author =       "Peter Sestoft",
  booktitle =    "FPCA '89: Proceedings of the fourth International
                 Conference on Functional Programming Languages and
                 Computer Architecture",
  citeulike-article-id = "5394965",
  date-added =   "2009-08-07 21:29:16",
  keywords =     "file-import-09-08-07",
  location =     "Imperial College, London, United Kingdom",
  priority =     "2",
  publisher =    "ACM Press",
  title =        "Replacing function parameters by global variables",
  x-address =    "New York, NY, USA",
  xpages =       "39--53",
  year =         "1989",
}

@MastersThesis{sestoft-ms,
  author =       "Peter Sestoft",
  citeulike-article-id = "5394964",
  comment =      "Master's thesis no.\~{}254",
  date-added =   "2009-08-07 21:29:15",
  keywords =     "file-import-09-08-07",
  month =        oct,
  priority =     "2",
  school =       "DIKU",
  title =        "Replacing function parameters by global variables",
  x-address =    "University of Copenhagen, Denmark",
  year =         "1988",
}

@InProceedings{heintze-lfp94,
  author =       "Nevin Heintze",
  booktitle =    "LFP '94: Proceedings of the 1994 ACM Conference on
                 LISP and Functional Programming",
  citeulike-article-id = "5394963",
  date-added =   "2009-08-07 21:29:15",
  keywords =     "file-import-09-08-07",
  location =     "Orlando, Florida, United States",
  priority =     "2",
  publisher =    "ACM Press",
  title =        "Set-based analysis of {ML} programs",
  x-address =    "New York, NY, USA",
  xpages =       "306--317",
  year =         "1994",
}

@InProceedings{nielson-nielson-popl97,
  author =       "Flemming Nielson and Hanne R. Nielson",
  booktitle =    "POPL '97: Proceedings of the 24th ACM SIGPLAN-SIGACT
                 Symposium on Principles of Programming Languages",
  citeulike-article-id = "5394962",
  date-added =   "2009-08-07 21:29:15",
  key =          "POPL 1997",
  keywords =     "file-import-09-08-07",
  location =     "Paris, France",
  priority =     "2",
  publisher =    "ACM Press",
  title =        "Infinitary control flow analysis: a collecting
                 semantics for closure analysis",
  x-address =    "New York, NY, USA",
  xpages =       "332--345",
  year =         "1997",
}

@Article{palsberg-pavlopoulou-jfp01,
  author =       "Jens Palsberg and Christina Pavlopoulou",
  citeulike-article-id = "5394961",
  date-added =   "2009-08-07 21:29:15",
  journal =      "J. Funct. Program.",
  keywords =     "file-import-09-08-07",
  number =       "3",
  priority =     "2",
  publisher =    "Cambridge University Press",
  title =        "From Polyvariant flow information to intersection and
                 union types",
  volume =       "11",
  x-address =    "New York, NY, USA",
  xpages =       "263--317",
  year =         "2001",
}

@Proceedings{DBLP:conf/sas/95,
  citeulike-article-id = "5394960",
  date-added =   "2009-08-07 21:29:15",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Springer",
  title =        "Static Analysis, Second International Symposium,
                 {SAS}'95, Glasgow, {UK}, September 25-27, 1995,
                 Proceedings",
  volume =       "983",
  x-editor =     "Mycroft, Alan",
  x-series =     "Lecture Notes in Computer Science",
  year =         "1995",
}

@InProceedings{heintze-sas95,
  author =       "Nevin Heintze",
  booktitle =    "SAS",
  citeulike-article-id = "5394959",
  date-added =   "2009-08-07 21:29:15",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Springer",
  title =        "{Control-Flow} Analysis and Type Systems",
  volume =       "983",
  x-editor =     "Mycroft, Alan",
  x-series =     "Lecture Notes in Computer Science",
  xpages =       "189--206",
  year =         "1995",
}

@Article{palsberg-okeefe-toplas95,
  author =       "Jens Palsberg and Patrick O'Keefe",
  citeulike-article-id = "5394958",
  date-added =   "2009-08-07 21:29:15",
  journal =      "ACM Trans. Program. Lang. Syst.",
  keywords =     "file-import-09-08-07",
  number =       "4",
  priority =     "2",
  publisher =    "ACM Press",
  title =        "A type system equivalent to flow analysis",
  volume =       "17",
  x-address =    "New York, NY, USA",
  xpages =       "576--599",
  year =         "1995",
}

@Article{wright-jagannathan-toplas98,
  author =       "Andrew K. Wright and Suresh Jagannathan",
  citeulike-article-id = "5394957",
  date-added =   "2009-08-07 21:29:15",
  journal =      "ACM Trans. Program. Lang. Syst.",
  keywords =     "file-import-09-08-07",
  number =       "1",
  priority =     "2",
  publisher =    "ACM Press",
  title =        "Polymorphic splitting: an effective polyvariant flow
                 analysis",
  volume =       "20",
  x-address =    "New York, NY, USA",
  x-issn =       "0164-0925",
  xpages =       "166--207",
  year =         "1998",
}

@InProceedings{griffin-popl90,
  author =       "Timothy G. Griffin",
  booktitle =    "POPL '90: Proceedings of the 17th ACM SIGPLAN-SIGACT
                 Symposium on Principles of Programming Languages",
  citeulike-article-id = "5394956",
  date-added =   "2009-08-07 21:29:15",
  key =          "POPL 1990",
  keywords =     "file-import-09-08-07",
  location =     "San Francisco, California, United States",
  priority =     "2",
  publisher =    "ACM Press",
  title =        "A formulae-as-type notion of control",
  x-address =    "New York, NY, USA",
  xpages =       "47--58",
  year =         "1990",
}

@Misc{terui-ll2002,
  author =       "Kazushige Terui",
  citeulike-article-id = "5394955",
  comment =      "Invited talk at LL2002 (LICS2002 affiliated workshop),
                 Copenhagen",
  date-added =   "2009-08-07 21:29:15",
  keywords =     "file-import-09-08-07",
  month =        jul,
  priority =     "2",
  title =        "On the complexity of {Cut-Elimination} in Linear
                 Logic",
  year =         "2002",
}

@InProceedings{Jones:1981:LambdaFlow,
  author =       "Neil D. Jones",
  booktitle =    "Proceedings of the 8th Colloquium on Automata,
                 Languages and Programming",
  citeulike-article-id = "5394954",
  date-added =   "2009-08-07 21:29:15",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "Flow Analysis of Lambda Expressions (Preliminary
                 Version)",
  x-address =    "London, UK",
  xpages =       "114--128",
  year =         "1981",
}

@Article{palsberg-toplas95,
  author =       "Jens Palsberg",
  citeulike-article-id = "5394953",
  date-added =   "2009-08-07 21:29:15",
  journal =      "ACM Trans.\\ Program.\\ Lang.\\ Syst.",
  keywords =     "file-import-09-08-07",
  number =       "1",
  priority =     "2",
  publisher =    "ACM Press",
  title =        "Closure analysis in constraint form",
  volume =       "17",
  x-address =    "New York, NY, USA",
  xpages =       "47--62",
  year =         "1995",
}

@InProceedings{heintze-mcallester-pldi97,
  author =       "Nevin Heintze and David Mcallester",
  booktitle =    "PLDI '97: Proceedings of the ACM SIGPLAN 1997
                 conference on Programming language design and
                 implementation",
  citeulike-article-id = "5394952",
  date-added =   "2009-08-07 21:29:15",
  keywords =     "file-import-09-08-07",
  location =     "Las Vegas, Nevada, United States",
  priority =     "2",
  publisher =    "ACM Press",
  title =        "Linear-time subtransitive control flow analysis",
  x-address =    "New York, NY, USA",
  xpages =       "261--272",
  year =         "1997",
}

@InProceedings{heintze-mcallester-lics97,
  author =       "Nevin Heintze and David Mcallester",
  booktitle =    "LICS '97: Proceedings of the 12th Annual IEEE
                 Symposium on Logic in Computer Science",
  citeulike-article-id = "5394951",
  date-added =   "2009-08-07 21:29:15",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "IEEE Computer Society",
  title =        "On the Cubic Bottleneck in Subtyping and Flow
                 Analysis",
  x-address =    "Washington, DC, USA",
  xpages =       "342",
  year =         "1997",
}

@Article{ladner-75,
  author =       "Richard E. Ladner",
  citeulike-article-id = "5394950",
  date-added =   "2009-08-07 21:29:14",
  journal =      "SIGACT News",
  keywords =     "file-import-09-08-07",
  number =       "1",
  priority =     "2",
  publisher =    "ACM Press",
  title =        "The circuit value problem is log space complete for
                 \${P}\$",
  volume =       "7",
  x-address =    "New York, NY, USA",
  xpages =       "18--20",
  year =         "1975",
}

@InProceedings{mairson-fsttcs02,
  author =       "Harry G. Mairson",
  booktitle =    "FST TCS '02: Proceedings of the 22nd Conference Kanpur
                 on Foundations of Software Technology and Theoretical
                 Computer Science",
  citeulike-article-id = "5394949",
  date-added =   "2009-08-07 21:29:14",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "From {H}ilbert Spaces to {D}ilbert Spaces: {C}ontext
                 Semantics Made Simple",
  x-address =    "London, UK",
  xpages =       "2--17",
  year =         "2002",
}

@Article{mairson-jfp04,
  author =       "Harry G. Mairson",
  citeulike-article-id = "5394947",
  date-added =   "2009-08-07 21:29:14",
  journal =      "J. Functional Program.",
  keywords =     "file-import-09-08-07",
  number =       "6",
  priority =     "2",
  publisher =    "Cambridge University Press",
  title =        "Linear lambda calculus and {PTIME}-completeness",
  volume =       "14",
  x-address =    "New York, NY, USA",
  xpages =       "623--633",
  year =         "2004",
}

@InProceedings{henglein-mairson-popl91,
  author =       "Fritz Henglein and Harry G. Mairson",
  booktitle =    "POPL '91: Proceedings of the 18th ACM SIGPLAN-SIGACT
                 Symposium on Principles of Programming Languages",
  citeulike-article-id = "5394946",
  date-added =   "2009-08-07 21:29:14",
  key =          "POPL 1991",
  keywords =     "file-import-09-08-07",
  location =     "Orlando, Florida, United States",
  priority =     "2",
  publisher =    "ACM Press",
  title =        "The complexity of type inference for higher-order
                 lambda calculi",
  x-address =    "New York, NY, USA",
  xpages =       "119--130",
  year =         "1991",
}

@InProceedings{neergaard-mairson-icfp04,
  author =       "Peter {{Mo Ller} Neergaard} and Harry G. Mairson",
  booktitle =    "ICFP '04: Proceedings of the ninth ACM SIGPLAN
                 International Conference on Functional Programming",
  citeulike-article-id = "5394945",
  date-added =   "2009-08-07 21:29:14",
  keywords =     "file-import-09-08-07",
  location =     "Snow Bird, UT, USA",
  priority =     "2",
  publisher =    "ACM Press",
  title =        "Types, potency, and idempotency: why nonlinearity and
                 amnesia make a type system work",
  x-address =    "New York, NY, USA",
  xpages =       "138--149",
  year =         "2004",
}

@InProceedings{jagannathan-weeks-popl95,
  author =       "Suresh Jagannathan and Stephen Weeks",
  booktitle =    "POPL '95: Proceedings of the 22nd ACM SIGPLAN-SIGACT
                 Symposium on Principles of Programming Languages",
  citeulike-article-id = "5394944",
  date-added =   "2009-08-07 21:29:14",
  key =          "POPL 1995",
  keywords =     "file-import-09-08-07",
  location =     "San Francisco, California, United States",
  priority =     "2",
  publisher =    "ACM Press",
  title =        "A unified treatment of flow analysis in higher-order
                 languages",
  x-address =    "New York, NY, USA",
  xpages =       "393--407",
  year =         "1995",
}

@InProceedings{lawall-mairson-esop00,
  author =       "Julia L. Lawall and Harry G. Mairson",
  booktitle =    "ESOP '00: Proceedings of the 9th European Symposium on
                 Programming Languages and Systems",
  citeulike-article-id = "5394943",
  date-added =   "2009-08-07 21:29:14",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Springer-Verlag",
  title =        "Sharing Continuations: Proofnets for Languages with
                 Explicit Control",
  x-address =    "London, UK",
  xpages =       "245--259",
  year =         "2000",
}

@InProceedings{shivers-sigplan04,
  author =       "Olin Shivers",
  booktitle =    "Best of PLDI 1988",
  citeulike-article-id = "5394942",
  date-added =   "2009-08-07 21:29:14",
  keywords =     "file-import-09-08-07",
  number =       "4",
  priority =     "2",
  publisher =    "ACM",
  title =        "Higher-order control-flow analysis in retrospect:
                 lessons learned, lessons abandoned",
  volume =       "39",
  x-address =    "New York, NY, USA",
  x-editor =     "McKinley, Kathryn S.",
  xpages =       "257--269",
  year =         "2004",
}

@PhdThesis{Shivers:1991:CFA,
  author =       "Olin Shivers",
  citeulike-article-id = "5394941",
  date-added =   "2009-08-07 21:29:14",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Carnegie Mellon University",
  school =       "Carnegie Mellon University",
  title =        "Control-flow analysis of higher-order languages",
  x-address =    "Pittsburgh, PA, USA",
  year =         "1991",
}

@InProceedings{shivers-88,
  author =       "Olin Shivers",
  booktitle =    "PLDI '88: Proceedings of the ACM SIGPLAN 1988
                 Conference on Programming Language Design and
                 Implementation",
  citeulike-article-id = "5394940",
  date-added =   "2009-08-07 21:29:14",
  keywords =     "file-import-09-08-07",
  location =     "Atlanta, Georgia, United States",
  priority =     "2",
  publisher =    "ACM",
  title =        "Control flow analysis in {S}cheme",
  x-address =    "New York, NY, USA",
  x-series =     "PLDI",
  xpages =       "164--174",
  year =         "1988",
}

@InProceedings{levy-80,
  author =       "Jean J. L\'{e}vy",
  citeulike-article-id = "5394939",
  date-added =   "2009-08-07 21:29:14",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  publisher =    "Academic Press",
  title =        "Optimal reductions in the lambda-calculus",
  x-address =    "London",
  x-editor =     "Seldin, Jonathan P. and Hindley, J. Roger",
  xpages =       "159--191",
  year =         "1980",
}

@PhdThesis{levy-phd,
  author =       "Jean J. L\'{e}vy",
  citeulike-article-id = "5394938",
  comment =      "th\'{e}se d'Etat",
  date-added =   "2009-08-07 21:29:14",
  keywords =     "file-import-09-08-07",
  month =        jan,
  priority =     "2",
  school =       "Paris 7",
  title =        "{R}\'{e}ductions correctes et optimales dans le
                 lambda-calcul",
  year =         "1978",
}

@InProceedings{gonthier-abadi-levy-popl92,
  author =       "Georges Gonthier and Mart\'{\i}n Abadi and Jean J.
                 L\'{e}vy",
  booktitle =    "POPL '92: Proceedings of the 19th ACM SIGPLAN-SIGACT
                 Symposium on Principles of Programming Languages",
  citeulike-article-id = "5394937",
  date-added =   "2009-08-07 21:29:14",
  keywords =     "file-import-09-08-07",
  location =     "Albuquerque, New Mexico, United States",
  priority =     "2",
  publisher =    "ACM Press",
  title =        "The geometry of optimal lambda reduction",
  x-address =    "New York, NY, USA",
  xpages =       "15--26",
  year =         "1992",
}

@Article{mairson92,
  author =       "Harry G. Mairson",
  citeulike-article-id = "5394936",
  date-added =   "2009-08-07 21:29:14",
  journal =      "Theoretical Computer Science",
  keywords =     "file-import-09-08-07",
  number =       "2",
  priority =     "2",
  publisher =    "Elsevier Science Publishers Ltd.",
  title =        "A simple proof of a theorem of {Statman}",
  volume =       "103",
  x-address =    "Essex, UK",
  xpages =       "387--394",
  year =         "1992",
}

@InProceedings{asperti-mairson,
  author =       "Andrea Asperti and Harry G. Mairson",
  booktitle =    "POPL '98: Proceedings of the 25th ACM SIGPLAN-SIGACT
                 Symposium on Principles of Programming Languages, San
                 Diego, CA, USA, January 19--21, 1998",
  citeulike-article-id = "5394935",
  date-added =   "2009-08-07 21:29:14",
  key =          "POPL 1998",
  keywords =     "file-import-09-08-07",
  location =     "San Diego, California, United States",
  priority =     "2",
  publisher =    "ACM Press",
  title =        "Parallel beta reduction is not elementary recursive",
  x-address =    "New York, NY, USA",
  x-editor =     "Macqueen, David B. and Cardelli, Luca",
  xpages =       "303--315",
  year =         "1998",
}

@Article{statman79,
  author =       "Richard Statman",
  citeulike-article-id = "5394934",
  date-added =   "2009-08-07 21:29:14",
  journal =      "Theor.\\ Comput.\\ Sci.",
  keywords =     "file-import-09-08-07",
  priority =     "2",
  title =        "The typed \$\\lambda\$-calculus is not elementary
                 recursive",
  volume =       "9",
  xpages =       "73--81",
  year =         "1979",
}

@Proceedings{icfp07,
  citeulike-article-id = "5394932",
  date-added =   "2009-08-07 21:29:13",
  key =          "ICFP'07",
  keywords =     "file-import-09-08-07",
  location =     "Freiburg, Germany",
  priority =     "2",
  publisher =    "ACM",
  title =        "Proceedings of the 2007 {ACM} {SIGPLAN} International
                 Conference on Functional Programming, Freiburg,
                 Germany, October 1--3",
  x-address =    "New York, NY, USA",
  year =         "2007",
}

@InProceedings{vanhorn-mairson-icfp07,
  author =       "David {.} {Horn} and Harry G. Mairson",
  citeulike-article-id = "5394930",
  date-added =   "2009-08-07 21:29:13",
  key =          "ICFP'07",
  keywords =     "file-import-09-08-07",
  location =     "Freiburg, Germany",
  priority =     "2",
  publisher =    "ACM",
  title =        "Relating complexity and precision in control flow
                 analysis",
  x-address =    "New York, NY, USA",
  xpages =       "85--96",
  year =         "2007",
}

@InProceedings{VanHorn-Mairson:ICFP08,
  author =       "David Van Horn and Harry G. Mairson",
  booktitle =    "ICFP '08: Proceeding of the 13th ACM SIGPLAN
                 International Conference on Functional Programming",
  citeulike-article-id = "5152280",
  citeulike-linkout-0 = "http://portal.acm.org/citation.cfm?id=1411243",
  citeulike-linkout-1 = "http://dx.doi.org/10.1145/1411204.1411243",
  date-added =   "2009-08-07 21:02:02",
  location =     "Victoria, BC, Canada",
  priority =     "0",
  publisher =    "ACM",
  title =        "Deciding \(k\){CFA} is complete for {EXPTIME}",
  x-abstract =   "We give an exact characterization of the computational
                 complexity of the \({k\)CFA} hierarchy. For any \(k >
                 0\), we prove that the control flow decision problem is
                 complete for deterministic exponential time. This
                 theorem validates empirical observations that such
                 control flow analysis is intractable. It also provides
                 more general insight into the complexity of abstract
                 interpretation.",
  x-address =    "New York, NY, USA",
  x-doi =        "10.1145/1411204.1411243",
  x-isbn =       "978-1-59593-919-7",
  x-series =     "ICFP '08",
  x-url =        "http://dx.doi.org/10.1145/1411204.1411243",
  xpages =       "275--282",
  year =         "2008",
}
